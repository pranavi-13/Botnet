{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=pd.read_csv(\"Doorbell/benign_traffic.csv\")\n",
    "x_train, x_opt, x_test = np.split(benign.sample(frac=1, random_state=20), [int(1/3*len(benign)), int(2/3*len(benign))])\n",
    "\n",
    "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('Doorbell/mirai/*.csv', recursive=False)), ignore_index=True)\n",
    "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('Doorbell/gafgyt/*.csv', recursive=False)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 'malicious'\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 'benign'\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting samples of benign and malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n = 2000\n",
    "atk = df_attack.sample(n=plot_n, random_state=76)\n",
    "nrm = x_train.sample(n=plot_n, random_state=42)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
    "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
    "\n",
    "plt.xlabel('MI_dir_L0.1_weight')\n",
    "plt.ylabel('MI_dir_L1_weight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'MI_dir_L1_weight', 'score': 1.2812281390780917},\n",
       " {'feature': 'H_L1_weight', 'score': 1.2812280965525344},\n",
       " {'feature': 'MI_dir_L3_weight', 'score': 1.2804935428770359},\n",
       " {'feature': 'H_L3_weight', 'score': 1.280493542758028},\n",
       " {'feature': 'MI_dir_L0.1_weight', 'score': 1.279751003162228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['benign','malicious']\n",
    "scored = []\n",
    "indices = {}\n",
    "shps = {}\n",
    "\n",
    "#classifying benign as true and attack as false\n",
    "for cl in classes:\n",
    "    indices[cl] = df_ben['class'] == cl    \n",
    "    shps[cl] =  df_ben[indices[cl]].shape[0]\n",
    "        \n",
    "for col in df_ben.columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "    num = 0\n",
    "    den = 0\n",
    "    m = df_ben[col].mean()\n",
    "    \n",
    "    for cl in classes:\n",
    "        num += (shps[cl] / df_ben.shape[0]) * (m - df_ben[indices[cl]][col].mean())**2\n",
    "        den += (shps[cl] / df_ben.shape[0]) * df_ben[indices[cl]][col].var()\n",
    "    score = {'feature': col, 'score': num / den}\n",
    "    scored.append(score)\n",
    "    #print(score)\n",
    "scored.sort(key=lambda x: x['score'], reverse=True)\n",
    "scored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    #initialize model\n",
    "    def __init__(self, model, threshold, scaler):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #predict the outcome using treshold\n",
    "    def predict(self, x):\n",
    "        x_pred = self.model.predict(x)\n",
    "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
    "        y_pred = mse > self.threshold\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    #scale the classes\n",
    "    def scale_predict_classes(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.predict(x)\n",
    "        classes_arr = []\n",
    "        for e in y_pred:\n",
    "            el = [0,0]\n",
    "            el[e] = 1\n",
    "            classes_arr.append(el)\n",
    "        print(classes_arr)\n",
    "\n",
    "        return np.array(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation - Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
    "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    return Model(inp, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 4s 7ms/step - loss: 0.5222 - val_loss: 1.3694\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3245 - val_loss: 1.2888\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3900 - val_loss: 1.2319\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.2576 - val_loss: 1.1895\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3240 - val_loss: 1.1552\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 1.1232\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.2519 - val_loss: 1.0968\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3294 - val_loss: 1.0751\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1259 - val_loss: 1.0611\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.2267 - val_loss: 1.0341\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1468 - val_loss: 1.0242\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1450 - val_loss: 1.0166\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1424 - val_loss: 0.9996\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1678 - val_loss: 0.9815\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1249 - val_loss: 0.9738\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1709 - val_loss: 0.9670\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1501 - val_loss: 0.9609\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.2164 - val_loss: 0.9505\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1405 - val_loss: 0.9497\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1688 - val_loss: 0.9375\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3359 - val_loss: 0.9194\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1955 - val_loss: 0.9164\n",
      "Epoch 23/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1496 - val_loss: 0.9058\n",
      "Epoch 24/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1753 - val_loss: 0.8986\n",
      "Epoch 25/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1179 - val_loss: 0.9011\n",
      "Epoch 26/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1285 - val_loss: 0.8878\n",
      "Epoch 27/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1039 - val_loss: 0.8801\n",
      "Epoch 28/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0890 - val_loss: 0.8691\n",
      "Epoch 29/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0878 - val_loss: 0.8603\n",
      "Epoch 30/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1343 - val_loss: 0.8568\n",
      "Epoch 31/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0522 - val_loss: 0.8588\n",
      "Epoch 32/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.2086 - val_loss: 0.8477\n",
      "Epoch 33/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0748 - val_loss: 0.8342\n",
      "Epoch 34/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1080 - val_loss: 0.8266\n",
      "Epoch 35/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0850 - val_loss: 0.8172\n",
      "Epoch 36/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1044 - val_loss: 0.8370\n",
      "Epoch 37/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1196 - val_loss: 0.8012\n",
      "Epoch 38/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0618 - val_loss: 0.7937\n",
      "Epoch 39/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0788 - val_loss: 0.7836\n",
      "Epoch 40/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0645 - val_loss: 0.7791\n",
      "Epoch 41/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0870 - val_loss: 0.7713\n",
      "Epoch 42/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1772 - val_loss: 0.7647\n",
      "Epoch 43/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0515 - val_loss: 0.7443\n",
      "Epoch 44/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0549 - val_loss: 0.7494\n",
      "Epoch 45/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0527 - val_loss: 0.7314\n",
      "Epoch 46/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1142 - val_loss: 0.7246\n",
      "Epoch 47/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0611 - val_loss: 0.7147\n",
      "Epoch 48/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0477 - val_loss: 0.7044\n",
      "Epoch 49/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0419 - val_loss: 0.6976\n",
      "Epoch 50/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0604 - val_loss: 0.6904\n",
      "Epoch 51/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0757 - val_loss: 0.6926\n",
      "Epoch 52/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1178 - val_loss: 0.6991\n",
      "Epoch 53/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0766 - val_loss: 0.8427\n",
      "Epoch 54/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0872 - val_loss: 0.8849\n",
      "Epoch 55/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1327 - val_loss: 0.6654\n",
      "Epoch 56/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0465 - val_loss: 0.6519\n",
      "Epoch 57/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0627 - val_loss: 0.6441\n",
      "Epoch 58/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0413 - val_loss: 0.6372\n",
      "Epoch 59/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0778 - val_loss: 0.6269\n",
      "Epoch 60/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1117 - val_loss: 0.6219\n",
      "Epoch 61/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0362 - val_loss: 0.6184\n",
      "Epoch 62/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0473 - val_loss: 0.6139\n",
      "Epoch 63/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1595 - val_loss: 0.6003\n",
      "Epoch 64/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0289 - val_loss: 0.5891\n",
      "Epoch 65/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.5791\n",
      "Epoch 66/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0378 - val_loss: 0.5717\n",
      "Epoch 67/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0389 - val_loss: 0.5675\n",
      "Epoch 68/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0915 - val_loss: 0.5582\n",
      "Epoch 69/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0476 - val_loss: 0.5587\n",
      "Epoch 70/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.1156 - val_loss: 0.5439\n",
      "Epoch 71/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0719 - val_loss: 0.5364\n",
      "Epoch 72/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0552 - val_loss: 0.5309\n",
      "Epoch 73/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0354 - val_loss: 0.5258\n",
      "Epoch 74/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0460 - val_loss: 0.5184\n",
      "Epoch 75/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0426 - val_loss: 0.5100\n",
      "Epoch 76/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0340 - val_loss: 0.5048\n",
      "Epoch 77/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0287 - val_loss: 0.4957\n",
      "Epoch 78/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0362 - val_loss: 0.4907\n",
      "Epoch 79/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0323 - val_loss: 0.4800\n",
      "Epoch 80/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0358 - val_loss: 0.4705\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0451 - val_loss: 0.4741\n",
      "Epoch 82/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0435 - val_loss: 0.4679\n",
      "Epoch 83/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0333 - val_loss: 0.4566\n",
      "Epoch 84/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0424 - val_loss: 0.4484\n",
      "Epoch 85/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0302 - val_loss: 0.4417\n",
      "Epoch 86/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0338 - val_loss: 0.4362\n",
      "Epoch 87/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0235 - val_loss: 0.4328\n",
      "Epoch 88/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0322 - val_loss: 0.4243\n",
      "Epoch 89/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0422 - val_loss: 0.4212\n",
      "Epoch 90/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0432 - val_loss: 0.4153\n",
      "Epoch 91/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0366 - val_loss: 0.4092\n",
      "Epoch 92/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0643 - val_loss: 0.4076\n",
      "Epoch 93/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0514 - val_loss: 0.3970\n",
      "Epoch 94/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0324 - val_loss: 0.4012\n",
      "Epoch 95/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0347 - val_loss: 0.4000\n",
      "Epoch 96/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0550 - val_loss: 0.3868\n",
      "Epoch 97/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0254 - val_loss: 0.3808\n",
      "Epoch 98/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0272 - val_loss: 0.3718\n",
      "Epoch 99/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0248 - val_loss: 0.3659\n",
      "Epoch 100/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.0261 - val_loss: 0.3639\n",
      "time: 111.58387684822083\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 87)                10092     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                5104      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                1711      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 87)                5133      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 115)               10120     \n",
      "=================================================================\n",
      "Total params: 33,900\n",
      "Trainable params: 33,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = deep_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",monitor='val_loss',save_best_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_opt, X_opt),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8993097602325019\n",
      "Precision 0.99894083825087\n",
      "Recall 0.7994671833373698\n",
      "Confusion Matrix [[16502    14]\n",
      " [ 3312 13204]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8993400339065148\n",
      "Precision 0.9991674865662605\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16505    11]\n",
      " [ 3314 13202]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8993400339065148\n",
      "Precision 0.9991674865662605\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16505    11]\n",
      " [ 3314 13202]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9993187495269094\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16507     9]\n",
      " [ 3314 13202]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9993187495269094\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16507     9]\n",
      " [ 3314 13202]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9993943981831945\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16508     8]\n",
      " [ 3314 13202]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9995457298606905\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3314 13202]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9995457298606905\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3314 13202]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9995457298606905\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3314 13202]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9995457298606905\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3314 13202]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9995457298606905\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3314 13202]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9995457298606905\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3314 13202]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9995456954645264\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3315 13201]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9995456954645264\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3315 13201]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8994914022765803\n",
      "Precision 0.9996213842192943\n",
      "Recall 0.7992855412932913\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3315 13201]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        \n",
    "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 7\n",
      "Treshold  497.1570853024116\n",
      "Accuracy  0.8973419714216517\n",
      "Precision  0.9998476654733796\n",
      "Recall 0.7948050375393558\n",
      "Confusion Matrix [[16514     2]\n",
      " [ 3389 13127]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "deep_tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "deep_acc = accuracy_score(Y_test, Y_pred)\n",
    "deep_precision = precision_score(Y_test, Y_pred)\n",
    "deep_recall = recall_score(Y_test, Y_pred)\n",
    "deep_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',deep_acc)\n",
    "print('Precision ',deep_precision)\n",
    "print(\"Recall\",deep_recall)\n",
    "print('Confusion Matrix',deep_cm)\n",
    "   \n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_dim):\n",
    "    original_dim = input_dim\n",
    "    intermediate_dim = 64\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    from keras import backend as K\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    return Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 2s 2ms/step - loss: 1.0212 - val_loss: 1.7923\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6729 - val_loss: 1.7872\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7683 - val_loss: 1.7815\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7898 - val_loss: 1.7774\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8689 - val_loss: 1.7746\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6699 - val_loss: 1.7778\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8016 - val_loss: 1.7715\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9111 - val_loss: 1.7699\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7934 - val_loss: 1.7719\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7776 - val_loss: 1.7671\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6474 - val_loss: 1.7657\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7419 - val_loss: 1.7647\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7787 - val_loss: 1.7637\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9663 - val_loss: 1.7635\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8624 - val_loss: 1.7628\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6606 - val_loss: 1.7629\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8540 - val_loss: 1.7622\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7723 - val_loss: 1.7628\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7259 - val_loss: 1.7623\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8501 - val_loss: 1.7625\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7784 - val_loss: 1.7626\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8848 - val_loss: 1.7627\n",
      "time: 22.713244438171387\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 2), (None, 2), (N 7684      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 115)               7667      \n",
      "=================================================================\n",
      "Total params: 15,351\n",
      "Trainable params: 15,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = vae_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_vae.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8987042867522402\n",
      "Precision 0.9975819857941666\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16484    32]\n",
      " [ 3314 13202]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8990372971663841\n",
      "Precision 0.9984118581259925\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16495    21]\n",
      " [ 3314 13202]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8992492128844757\n",
      "Precision 0.9989406779661016\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16502    14]\n",
      " [ 3314 13202]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8993400339065148\n",
      "Precision 0.9991674865662605\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16505    11]\n",
      " [ 3314 13202]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9993187495269094\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16507     9]\n",
      " [ 3314 13202]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9993943981831945\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16508     8]\n",
      " [ 3314 13202]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9995456610631531\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3316 13200]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 7\n",
      "Treshold  393.77157445074664\n",
      "Accuracy  0.8972511503996125\n",
      "Precision  0.9995431703974418\n",
      "Recall 0.7948655848873819\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3388 13128]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "vae_acc = accuracy_score(Y_test, Y_pred)\n",
    "vae_precision = precision_score(Y_test, Y_pred)\n",
    "vae_recall = recall_score(Y_test, Y_pred)\n",
    "vae_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',vae_acc)\n",
    "print('Precision ',vae_precision)\n",
    "print(\"Recall\",vae_recall)\n",
    "print('Confusion Matrix',vae_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(15, activation='relu')(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9357 - val_loss: 1.7769\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7562 - val_loss: 1.7656\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8967 - val_loss: 1.7553\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8678 - val_loss: 1.7505\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8859 - val_loss: 1.7479\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8526 - val_loss: 1.7455\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7586 - val_loss: 1.7440\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8496 - val_loss: 1.7430\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8027 - val_loss: 1.7414\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7968 - val_loss: 1.7400\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7894 - val_loss: 1.7394\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8166 - val_loss: 1.7402\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9307 - val_loss: 1.7388\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7340 - val_loss: 1.7383\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 1.1432 - val_loss: 1.7377\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7838 - val_loss: 1.7376\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.6968 - val_loss: 1.7374\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9204 - val_loss: 1.7391\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8590 - val_loss: 1.7373\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7676 - val_loss: 1.7368\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7893 - val_loss: 1.7377\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7276 - val_loss: 1.7372\n",
      "Epoch 23/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.6743 - val_loss: 1.7372\n",
      "Epoch 24/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.6570 - val_loss: 1.7372\n",
      "Epoch 25/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8147 - val_loss: 1.7361\n",
      "Epoch 26/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7458 - val_loss: 1.7360\n",
      "Epoch 27/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7003 - val_loss: 1.7359\n",
      "Epoch 28/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7457 - val_loss: 1.7358\n",
      "Epoch 29/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7017 - val_loss: 1.7357\n",
      "Epoch 30/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7892 - val_loss: 1.7357\n",
      "Epoch 31/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.7736 - val_loss: 1.7356\n",
      "Epoch 32/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.6799 - val_loss: 1.7354\n",
      "Epoch 33/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9213 - val_loss: 1.7354\n",
      "Epoch 34/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7130 - val_loss: 1.7354\n",
      "Epoch 35/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.6606 - val_loss: 1.7354\n",
      "Epoch 36/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7170 - val_loss: 1.7357\n",
      "Epoch 37/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8100 - val_loss: 1.7360\n",
      "Epoch 38/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8053 - val_loss: 1.7372\n",
      "Epoch 39/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.8298 - val_loss: 1.7355\n",
      "time: 30.07356548309326\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                1740      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 115)               1840      \n",
      "=================================================================\n",
      "Total params: 3,580\n",
      "Trainable params: 3,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = uc_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_undercomplete.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8987042867522402\n",
      "Precision 0.9975819857941666\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16484    32]\n",
      " [ 3314 13202]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8990372971663841\n",
      "Precision 0.9984118581259925\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16495    21]\n",
      " [ 3314 13202]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8993097602325019\n",
      "Precision 0.9990918722566975\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16504    12]\n",
      " [ 3314 13202]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8993400339065148\n",
      "Precision 0.9991674865662605\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16505    11]\n",
      " [ 3314 13202]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9993943981831945\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16508     8]\n",
      " [ 3314 13202]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9993943981831945\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16508     8]\n",
      " [ 3314 13202]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9995456610631531\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3316 13200]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 7\n",
      "Treshold  391.7806996861691\n",
      "Accuracy  0.8972511503996125\n",
      "Precision  0.9995431703974418\n",
      "Recall 0.7948655848873819\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3388 13128]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "uc_acc = accuracy_score(Y_test, Y_pred)\n",
    "uc_precision = precision_score(Y_test, Y_pred)\n",
    "uc_recall = recall_score(Y_test, Y_pred)\n",
    "uc_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',uc_acc)\n",
    "print('Precision ',uc_precision)\n",
    "print(\"Recall\",uc_recall)\n",
    "print('Confusion Matrix',uc_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(200, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-6))(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 2s 2ms/step - loss: 0.9523 - val_loss: 1.7509\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9852 - val_loss: 1.7433\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9090 - val_loss: 1.7408\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6552 - val_loss: 1.7397\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7730 - val_loss: 1.7393\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7880 - val_loss: 1.7391\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8354 - val_loss: 1.7388\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7975 - val_loss: 1.7381\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8412 - val_loss: 1.7387\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6777 - val_loss: 1.7377\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8605 - val_loss: 1.7398\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6667 - val_loss: 1.7396\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8195 - val_loss: 1.7397\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9585 - val_loss: 1.7415\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6824 - val_loss: 1.7371\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7005 - val_loss: 1.7372\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7716 - val_loss: 1.7369\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7529 - val_loss: 1.7371\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9321 - val_loss: 1.7374\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 1.7372\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7657 - val_loss: 1.7376\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7159 - val_loss: 1.7373\n",
      "time: 22.0718731880188\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               23200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 115)               23115     \n",
      "=================================================================\n",
      "Total params: 46,315\n",
      "Trainable params: 46,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = sparse_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8987042867522402\n",
      "Precision 0.9975819857941666\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16484    32]\n",
      " [ 3314 13202]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8990372971663841\n",
      "Precision 0.9984118581259925\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16495    21]\n",
      " [ 3314 13202]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8993097602325019\n",
      "Precision 0.9990918722566975\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16504    12]\n",
      " [ 3314 13202]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8993400339065148\n",
      "Precision 0.9991674865662605\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16505    11]\n",
      " [ 3314 13202]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9993943981831945\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16508     8]\n",
      " [ 3314 13202]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9993943981831945\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16508     8]\n",
      " [ 3314 13202]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9994700582935877\n",
      "Recall 0.7993460886413175\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3314 13202]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.899400581254541\n",
      "Precision 0.9994699780419475\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16509     7]\n",
      " [ 3316 13200]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8994308549285541\n",
      "Precision 0.9995456610631531\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3316 13200]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8994611286025672\n",
      "Precision 0.9996213555471413\n",
      "Recall 0.7992249939452652\n",
      "Confusion Matrix [[16511     5]\n",
      " [ 3316 13200]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 7\n",
      "Treshold  392.7369921355704\n",
      "Accuracy  0.8972511503996125\n",
      "Precision  0.9995431703974418\n",
      "Recall 0.7948655848873819\n",
      "Confusion Matrix [[16510     6]\n",
      " [ 3388 13128]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "sparse_acc = accuracy_score(Y_test, Y_pred)\n",
    "sparse_precision = precision_score(Y_test, Y_pred)\n",
    "sparse_recall = recall_score(Y_test, Y_pred)\n",
    "sparse_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',sparse_acc)\n",
    "print('Precision ',sparse_precision)\n",
    "print(\"Recall\",sparse_recall)\n",
    "print('Confusion Matrix',sparse_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_model(input_dim):\n",
    "    input_size = input_dim\n",
    "    hidden_size = 44\n",
    "    code_size = 5\n",
    "\n",
    "    input_img = Input(shape=(input_size,))\n",
    "    hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "    code = Dense(code_size, activation='relu')(hidden_1)\n",
    "    hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "    output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "    autoencoder = Model(input_img, output_img)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 2s 3ms/step - loss: 1.1034 - val_loss: 1.8937\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8007 - val_loss: 1.8916\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9845 - val_loss: 1.8891\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8809 - val_loss: 1.8887\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8706 - val_loss: 1.8782\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 1.0124 - val_loss: 1.8237\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7855 - val_loss: 1.8196\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7870 - val_loss: 1.8198\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8860 - val_loss: 1.8163\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8611 - val_loss: 1.8150\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7994 - val_loss: 1.8077\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8508 - val_loss: 1.8093\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9254 - val_loss: 1.8061\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9451 - val_loss: 1.8056\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7685 - val_loss: 1.8088\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7452 - val_loss: 1.8126\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9053 - val_loss: 1.8012\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9611 - val_loss: 1.8006\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8542 - val_loss: 1.8007\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9921 - val_loss: 1.7966\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7503 - val_loss: 1.7972\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9142 - val_loss: 1.7956\n",
      "Epoch 23/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8683 - val_loss: 1.7989\n",
      "Epoch 24/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8863 - val_loss: 1.7947\n",
      "Epoch 25/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 1.0471 - val_loss: 1.7958\n",
      "Epoch 26/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7741 - val_loss: 1.7916\n",
      "Epoch 27/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8772 - val_loss: 1.7903\n",
      "Epoch 28/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7601 - val_loss: 1.7902\n",
      "Epoch 29/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9026 - val_loss: 1.7897\n",
      "Epoch 30/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 1.2448 - val_loss: 1.7898\n",
      "Epoch 31/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8737 - val_loss: 1.7902\n",
      "Epoch 32/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7666 - val_loss: 1.7886\n",
      "Epoch 33/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8306 - val_loss: 1.7884\n",
      "Epoch 34/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8713 - val_loss: 1.7890\n",
      "Epoch 35/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8147 - val_loss: 1.7887\n",
      "Epoch 36/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8585 - val_loss: 1.7882\n",
      "Epoch 37/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8303 - val_loss: 1.7908\n",
      "Epoch 38/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6499 - val_loss: 1.7923\n",
      "Epoch 39/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7373 - val_loss: 1.7882\n",
      "Epoch 40/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7878 - val_loss: 1.7879\n",
      "Epoch 41/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7554 - val_loss: 1.7875\n",
      "Epoch 42/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7787 - val_loss: 1.7879\n",
      "Epoch 43/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7932 - val_loss: 1.7876\n",
      "Epoch 44/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8642 - val_loss: 1.7873\n",
      "Epoch 45/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7641 - val_loss: 1.7884\n",
      "Epoch 46/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9048 - val_loss: 1.7873\n",
      "Epoch 47/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 1.0317 - val_loss: 1.7871\n",
      "Epoch 48/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.7699 - val_loss: 1.7865\n",
      "Epoch 49/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9728 - val_loss: 1.7875\n",
      "Epoch 50/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8239 - val_loss: 1.7876\n",
      "Epoch 51/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.6624 - val_loss: 1.7920\n",
      "Epoch 52/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9998 - val_loss: 1.7892\n",
      "Epoch 53/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.8487 - val_loss: 1.7905\n",
      "time: 51.682546615600586\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 44)                5104      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 225       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 44)                264       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 115)               5175      \n",
      "=================================================================\n",
      "Total params: 10,768\n",
      "Trainable params: 10,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "x_opt_noisy = np.clip(x_opt_noisy, 0., 1.)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "#x_train_noisy = scaler.fit_transform(x_train_noisy)\n",
    "#x_opt_noisy = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#call function to create the model\n",
    "model = denoise_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(x_train_noisy, X_train,\n",
    "                    epochs=epochs, validation_data=(x_opt_noisy, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.5\n",
      "Precision 0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(x_opt_noisy)\n",
    "mse = np.mean(np.power(x_opt_noisy - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "X_opt_scaled = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 1\n",
      "Treshold  0.5555472989596869\n",
      "Accuracy  0.5\n",
      "Precision  0.5\n",
      "Recall 1.0\n",
      "Confusion Matrix [[    0 16516]\n",
      " [    0 16516]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(x_test_noisy, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=20)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "X_test_scaled = scaler.transform(x_test_noisy)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "denoise_acc = accuracy_score(Y_test, Y_pred)\n",
    "denoise_precision = precision_score(Y_test, Y_pred)\n",
    "denoise_recall = recall_score(Y_test, Y_pred)\n",
    "denoise_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',denoise_acc)\n",
    "print('Precision ',denoise_precision)\n",
    "print(\"Recall\",denoise_recall)\n",
    "print('Confusion Matrix',denoise_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(80, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Dense(labels.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, callbacks=[monitor], patience=5) \n",
    "    model.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n",
    "          verbose=1,epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 1\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 0\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))\n",
    "\n",
    "X = df_ben.drop(columns=['class'])\n",
    "y = df_ben['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=17)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1762/1762 [==============================] - 3s 1ms/step - loss: 0.0083\n",
      "Epoch 2/100\n",
      "1762/1762 [==============================] - 2s 990us/step - loss: 0.0019\n",
      "Epoch 3/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0017\n",
      "Epoch 4/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0017\n",
      "Epoch 5/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0018\n",
      "Epoch 6/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0016\n",
      "Epoch 7/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0010\n",
      "Epoch 8/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0019\n",
      "Epoch 9/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0014\n",
      "Epoch 10/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 9.6967e-04\n",
      "Epoch 11/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0014\n",
      "Epoch 12/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 8.8490e-04\n",
      "Epoch 13/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 9.6673e-04\n",
      "Epoch 14/100\n",
      "1762/1762 [==============================] - 2s 1ms/step - loss: 0.0018\n",
      "time 28.726961851119995\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_dim=115, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "\n",
    "#compile and fit model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=15,callbacks=[es])\n",
    "\n",
    "end = time.time()\n",
    "print(\"time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9977296806417436\n",
      "Precision  0.9963724304715841\n",
      "Recall 0.9990906335253107\n",
      "Confusion Matrix [[3296   12]\n",
      " [   3 3296]]\n"
     ]
    }
   ],
   "source": [
    "dnn_acc = accuracy_score(y_test, y_pred)\n",
    "dnn_precision = precision_score(y_test, y_pred)\n",
    "dnn_recall = recall_score(y_test, y_pred)\n",
    "dnn_cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy ',dnn_acc)\n",
    "print('Precision ',dnn_precision)\n",
    "print(\"Recall\",dnn_recall)\n",
    "print('Confusion Matrix',dnn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danmini Doorbell\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>CM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denoising Autoendoer</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[0, 16516], [0, 16516]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variational AutoEncoder</td>\n",
       "      <td>0.897251</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.794866</td>\n",
       "      <td>[[16510, 6], [3388, 13128]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse AutoEncoder</td>\n",
       "      <td>0.897251</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.794866</td>\n",
       "      <td>[[16510, 6], [3388, 13128]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undercomplete Autoencoder</td>\n",
       "      <td>0.897251</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.794866</td>\n",
       "      <td>[[16510, 6], [3388, 13128]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep AutoEncoder</td>\n",
       "      <td>0.897342</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>0.794805</td>\n",
       "      <td>[[16514, 2], [3389, 13127]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  \\\n",
       "4       Denoising Autoendoer  0.500000   0.500000  1.000000   \n",
       "1    Variational AutoEncoder  0.897251   0.999543  0.794866   \n",
       "2         Sparse AutoEncoder  0.897251   0.999543  0.794866   \n",
       "3  Undercomplete Autoencoder  0.897251   0.999543  0.794866   \n",
       "0           Deep AutoEncoder  0.897342   0.999848  0.794805   \n",
       "\n",
       "                            CM  \n",
       "4     [[0, 16516], [0, 16516]]  \n",
       "1  [[16510, 6], [3388, 13128]]  \n",
       "2  [[16510, 6], [3388, 13128]]  \n",
       "3  [[16510, 6], [3388, 13128]]  \n",
       "0  [[16514, 2], [3389, 13127]]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Danmini Doorbell\")\n",
    "model_summary = pd.DataFrame({'Model' :['Deep AutoEncoder',\"Variational AutoEncoder\",\"Sparse AutoEncoder\",\"Undercomplete Autoencoder\",\"Denoising Autoendoer\"],\n",
    "                             'Accuracy':[deep_acc,vae_acc,sparse_acc,uc_acc,denoise_acc],\n",
    "                             'Precision':[deep_precision,vae_precision,sparse_precision,uc_precision,denoise_precision],\n",
    "                             'Recall':[deep_recall,vae_recall,sparse_recall,uc_recall,denoise_recall],\n",
    "                             'CM':[deep_cm,vae_cm,sparse_cm,uc_cm, denoise_cm]})\n",
    "model_summary.sort_values(by='Accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
