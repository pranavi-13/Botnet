{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=pd.read_csv(\"SecurityCam/benign_traffic.csv\")\n",
    "x_train, x_opt, x_test = np.split(benign.sample(frac=1, random_state=20), [int(1/3*len(benign)), int(2/3*len(benign))])\n",
    "\n",
    "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('SecurityCam/mirai/*.csv', recursive=False)), ignore_index=True)\n",
    "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('SecurityCam/gafgyt/*.csv', recursive=False)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 'malicious'\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 'benign'\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting samples of benign and malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n = 2000\n",
    "atk = df_attack.sample(n=plot_n, random_state=76)\n",
    "nrm = x_train.sample(n=plot_n, random_state=42)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
    "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
    "\n",
    "plt.xlabel('MI_dir_L0.1_weight')\n",
    "plt.ylabel('MI_dir_L1_weight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'HH_jit_L0.01_mean', 'score': 0.8188262695738087},\n",
       " {'feature': 'HH_jit_L0.1_mean', 'score': 0.8133162887063956},\n",
       " {'feature': 'HH_jit_L1_mean', 'score': 0.7769508654198414},\n",
       " {'feature': 'MI_dir_L0.1_weight', 'score': 0.7759777777720478},\n",
       " {'feature': 'H_L0.1_weight', 'score': 0.7759777777695762}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['benign','malicious']\n",
    "scored = []\n",
    "indices = {}\n",
    "shps = {}\n",
    "\n",
    "#classifying benign as true and attack as false\n",
    "for cl in classes:\n",
    "    indices[cl] = df_ben['class'] == cl    \n",
    "    shps[cl] =  df_ben[indices[cl]].shape[0]\n",
    "        \n",
    "for col in df_ben.columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "    num = 0\n",
    "    den = 0\n",
    "    m = df_ben[col].mean()\n",
    "    \n",
    "    for cl in classes:\n",
    "        num += (shps[cl] / df_ben.shape[0]) * (m - df_ben[indices[cl]][col].mean())**2\n",
    "        den += (shps[cl] / df_ben.shape[0]) * df_ben[indices[cl]][col].var()\n",
    "    score = {'feature': col, 'score': num / den}\n",
    "    scored.append(score)\n",
    "    #print(score)\n",
    "scored.sort(key=lambda x: x['score'], reverse=True)\n",
    "scored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    #initialize model\n",
    "    def __init__(self, model, threshold, scaler):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #predict the outcome using treshold\n",
    "    def predict(self, x):\n",
    "        x_pred = self.model.predict(x)\n",
    "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
    "        y_pred = mse > self.threshold\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    #scale the classes\n",
    "    def scale_predict_classes(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.predict(x)\n",
    "        classes_arr = []\n",
    "        for e in y_pred:\n",
    "            el = [0,0]\n",
    "            el[e] = 1\n",
    "            classes_arr.append(el)\n",
    "        print(classes_arr)\n",
    "\n",
    "        return np.array(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation - Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
    "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    return Model(inp, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1027/1027 [==============================] - 4s 3ms/step - loss: 0.2682 - val_loss: 0.0777\n",
      "Epoch 2/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0702 - val_loss: 0.0479\n",
      "Epoch 3/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0511 - val_loss: 0.0378\n",
      "Epoch 4/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0355 - val_loss: 0.0313\n",
      "Epoch 5/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0332 - val_loss: 0.0252\n",
      "Epoch 6/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0275 - val_loss: 0.0228\n",
      "Epoch 7/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0227 - val_loss: 0.0195\n",
      "Epoch 8/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0209 - val_loss: 0.0222\n",
      "Epoch 9/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0243 - val_loss: 0.0172\n",
      "Epoch 10/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0177 - val_loss: 0.0196\n",
      "Epoch 11/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0185 - val_loss: 0.0162\n",
      "Epoch 12/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0180 - val_loss: 0.0145\n",
      "Epoch 13/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0172 - val_loss: 0.0141\n",
      "Epoch 14/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0169 - val_loss: 0.0158\n",
      "Epoch 15/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0151 - val_loss: 0.0145\n",
      "Epoch 16/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0152 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0139 - val_loss: 0.0145\n",
      "Epoch 18/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0152 - val_loss: 0.0127\n",
      "Epoch 19/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0134 - val_loss: 0.0149\n",
      "Epoch 20/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0186 - val_loss: 0.0125\n",
      "Epoch 21/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 22/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 24/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 25/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 27/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 28/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 29/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 30/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 31/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 32/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 33/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 34/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 35/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.0082 - val_loss: 0.0095\n",
      "Epoch 36/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.0088 - val_loss: 0.0124\n",
      "time: 59.171337604522705\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 87)                10092     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                5104      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                1711      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 87)                5133      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 115)               10120     \n",
      "=================================================================\n",
      "Total params: 33,900\n",
      "Trainable params: 33,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = deep_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",monitor='val_loss',save_best_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_opt, X_opt),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.867820817345758\n",
      "Precision 0.989980122510243\n",
      "Recall 0.7431634082465436\n",
      "Confusion Matrix [[32591   247]\n",
      " [ 8434 24404]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8697241001279006\n",
      "Precision 0.9950256870260132\n",
      "Recall 0.7431634082465436\n",
      "Confusion Matrix [[32716   122]\n",
      " [ 8434 24404]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8702417930446434\n",
      "Precision 0.9964475296039199\n",
      "Recall 0.7431329557220293\n",
      "Confusion Matrix [[32751    87]\n",
      " [ 8435 24403]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8704549607162434\n",
      "Precision 0.9970174865174048\n",
      "Recall 0.7431329557220293\n",
      "Confusion Matrix [[32765    73]\n",
      " [ 8435 24403]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8706681283878434\n",
      "Precision 0.9976287816843826\n",
      "Recall 0.743102503197515\n",
      "Confusion Matrix [[32780    58]\n",
      " [ 8436 24402]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8707594859613862\n",
      "Precision 0.9978735585180338\n",
      "Recall 0.743102503197515\n",
      "Confusion Matrix [[32786    52]\n",
      " [ 8436 24402]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8708203910104148\n",
      "Precision 0.9980368098159509\n",
      "Recall 0.743102503197515\n",
      "Confusion Matrix [[32790    48]\n",
      " [ 8436 24402]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8710031061575004\n",
      "Precision 0.9985676870191521\n",
      "Recall 0.7430720506730008\n",
      "Confusion Matrix [[32803    35]\n",
      " [ 8437 24401]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.871064011206529\n",
      "Precision 0.9987720016373312\n",
      "Recall 0.7430415981484865\n",
      "Confusion Matrix [[32808    30]\n",
      " [ 8438 24400]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8710944637310433\n",
      "Precision 0.9988537743572949\n",
      "Recall 0.7430415981484865\n",
      "Confusion Matrix [[32810    28]\n",
      " [ 8438 24400]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.871170595042329\n",
      "Precision 0.9990582647504401\n",
      "Recall 0.7430415981484865\n",
      "Confusion Matrix [[32815    23]\n",
      " [ 8438 24400]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8711858213045861\n",
      "Precision 0.9991400491400492\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32817    21]\n",
      " [ 8439 24399]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8712315000913575\n",
      "Precision 0.9992628086988573\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32820    18]\n",
      " [ 8439 24399]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8712619526158718\n",
      "Precision 0.9993446651648576\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32822    16]\n",
      " [ 8439 24399]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8712619526158718\n",
      "Precision 0.9993446651648576\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32822    16]\n",
      " [ 8439 24399]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8712619526158718\n",
      "Precision 0.9993446651648576\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32822    16]\n",
      " [ 8439 24399]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8712619526158718\n",
      "Precision 0.9993446651648576\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32822    16]\n",
      " [ 8439 24399]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8712771788781289\n",
      "Precision 0.9993855984271319\n",
      "Recall 0.7430111456239722\n",
      "Confusion Matrix [[32823    15]\n",
      " [ 8439 24399]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8712924051403861\n",
      "Precision 0.9994674531973291\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32825    13]\n",
      " [ 8440 24398]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8713076314026433\n",
      "Precision 0.9995083981974601\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32826    12]\n",
      " [ 8440 24398]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8713228576649005\n",
      "Precision 0.9995493465525012\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32827    11]\n",
      " [ 8440 24398]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8713228576649005\n",
      "Precision 0.9995493465525012\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32827    11]\n",
      " [ 8440 24398]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8713533101894148\n",
      "Precision 0.999631253328963\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32829     9]\n",
      " [ 8440 24398]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8713533101894148\n",
      "Precision 0.999631253328963\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32829     9]\n",
      " [ 8440 24398]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8713685364516719\n",
      "Precision 0.9996722117512087\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8440 24398]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8713685364516719\n",
      "Precision 0.9996722117512087\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8440 24398]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8713685364516719\n",
      "Precision 0.9996722117512087\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8440 24398]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8713685364516719\n",
      "Precision 0.9996722117512087\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8440 24398]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.871383762713929\n",
      "Precision 0.9997131735300143\n",
      "Recall 0.7429806930994579\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8440 24398]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        \n",
    "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 29\n",
      "Threshold  2.913537642248193\n",
      "Accuracy  0.8700286253730434\n",
      "Precision  0.9993835278645405\n",
      "Recall 0.740514038613801\n",
      "Confusion Matrix [[32823    15]\n",
      " [ 8521 24317]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "deep_tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Threshold \",tr)\n",
    "deep_acc = accuracy_score(Y_test, Y_pred)\n",
    "deep_precision = precision_score(Y_test, Y_pred)\n",
    "deep_recall = recall_score(Y_test, Y_pred)\n",
    "deep_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',deep_acc)\n",
    "print('Precision ',deep_precision)\n",
    "print(\"Recall\",deep_recall)\n",
    "print('Confusion Matrix',deep_cm)\n",
    "   \n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_dim):\n",
    "    original_dim = input_dim\n",
    "    intermediate_dim = 64\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    from keras import backend as K\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    return Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.7306 - val_loss: 0.5760\n",
      "Epoch 2/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6018 - val_loss: 0.5733\n",
      "Epoch 3/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5705 - val_loss: 0.5718\n",
      "Epoch 4/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5825 - val_loss: 0.5699\n",
      "Epoch 5/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5664 - val_loss: 0.5672\n",
      "Epoch 6/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5740 - val_loss: 0.5647\n",
      "Epoch 7/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5775 - val_loss: 0.5628\n",
      "Epoch 8/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5708 - val_loss: 0.5622\n",
      "Epoch 9/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5736 - val_loss: 0.5623\n",
      "Epoch 10/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5619 - val_loss: 0.5615\n",
      "Epoch 11/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5580 - val_loss: 0.5599\n",
      "Epoch 12/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5606 - val_loss: 0.5602\n",
      "Epoch 13/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5537 - val_loss: 0.5593\n",
      "Epoch 14/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5535 - val_loss: 0.5590\n",
      "Epoch 15/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5567 - val_loss: 0.5596\n",
      "Epoch 16/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5593 - val_loss: 0.5594\n",
      "Epoch 17/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5653 - val_loss: 0.5586\n",
      "Epoch 18/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5583 - val_loss: 0.5583\n",
      "Epoch 19/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5441 - val_loss: 0.5589\n",
      "Epoch 20/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5524 - val_loss: 0.5579\n",
      "Epoch 21/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5489 - val_loss: 0.5580\n",
      "Epoch 22/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5503 - val_loss: 0.5580\n",
      "Epoch 23/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5627 - val_loss: 0.5576\n",
      "Epoch 24/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5611 - val_loss: 0.5576\n",
      "Epoch 25/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5558 - val_loss: 0.5576\n",
      "Epoch 26/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5759 - val_loss: 0.5573\n",
      "Epoch 27/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5702 - val_loss: 0.5574\n",
      "Epoch 28/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5716 - val_loss: 0.5573\n",
      "Epoch 29/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5613 - val_loss: 0.5572\n",
      "Epoch 30/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5518 - val_loss: 0.5567\n",
      "Epoch 31/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5635 - val_loss: 0.5570\n",
      "Epoch 32/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5689 - val_loss: 0.5567\n",
      "Epoch 33/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5601 - val_loss: 0.5568\n",
      "Epoch 34/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5512 - val_loss: 0.5579\n",
      "Epoch 35/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5843 - val_loss: 0.5554\n",
      "Epoch 36/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5635 - val_loss: 0.5553\n",
      "Epoch 37/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5592 - val_loss: 0.5547\n",
      "Epoch 38/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5525 - val_loss: 0.5544\n",
      "Epoch 39/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5529 - val_loss: 0.5547\n",
      "Epoch 40/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5613 - val_loss: 0.5545\n",
      "Epoch 41/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5502 - val_loss: 0.5542\n",
      "Epoch 42/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5575 - val_loss: 0.5544\n",
      "Epoch 43/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5565 - val_loss: 0.5543\n",
      "Epoch 44/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5471 - val_loss: 0.5541\n",
      "Epoch 45/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5497 - val_loss: 0.5541\n",
      "Epoch 46/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5465 - val_loss: 0.5538\n",
      "Epoch 47/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5948 - val_loss: 0.5536\n",
      "Epoch 48/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5536 - val_loss: 0.5536\n",
      "Epoch 49/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5687 - val_loss: 0.5551\n",
      "Epoch 50/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5583 - val_loss: 0.5536\n",
      "Epoch 51/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5549 - val_loss: 0.5535\n",
      "Epoch 52/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5743 - val_loss: 0.5535\n",
      "Epoch 53/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5593 - val_loss: 0.5535\n",
      "Epoch 54/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5526 - val_loss: 0.5535\n",
      "Epoch 55/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5520 - val_loss: 0.5532\n",
      "Epoch 56/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5583 - val_loss: 0.5555\n",
      "Epoch 57/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5517 - val_loss: 0.5533\n",
      "Epoch 58/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5836 - val_loss: 0.5532\n",
      "Epoch 59/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5583 - val_loss: 0.5531\n",
      "Epoch 60/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5561 - val_loss: 0.5536\n",
      "Epoch 61/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5611 - val_loss: 0.5530\n",
      "Epoch 62/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5737 - val_loss: 0.5532\n",
      "Epoch 63/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5422 - val_loss: 0.5530\n",
      "Epoch 64/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5761 - val_loss: 0.5530\n",
      "Epoch 65/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5449 - val_loss: 0.5535\n",
      "Epoch 66/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5594 - val_loss: 0.5533\n",
      "time: 101.72742176055908\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 2), (None, 2), (N 7684      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 115)               7667      \n",
      "=================================================================\n",
      "Total params: 15,351\n",
      "Trainable params: 15,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = vae_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_vae.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9941835678177721\n",
      "Precision 0.9885597302504817\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32458   380]\n",
      " [    2 32836]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9981271697423716\n",
      "Precision 0.9963887961642339\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32719   119]\n",
      " [    4 32834]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9984316949875145\n",
      "Precision 0.9969938966993593\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32739    99]\n",
      " [    4 32834]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9985382788233145\n",
      "Precision 0.9972360588020897\n",
      "Recall 0.9998477373774286\n",
      "Confusion Matrix [[32747    91]\n",
      " [    5 32833]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9986144101346002\n",
      "Precision 0.9974177476683781\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32753    85]\n",
      " [    6 32832]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9987818990194287\n",
      "Precision 0.9977511699993922\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32764    74]\n",
      " [    6 32832]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9988428040684573\n",
      "Precision 0.9978724697586773\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32768    70]\n",
      " [    6 32832]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.998918935379743\n",
      "Precision 0.9980241359394474\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32773    65]\n",
      " [    6 32832]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9989493879042572\n",
      "Precision 0.9980848153214774\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32775    63]\n",
      " [    6 32832]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.998236546062633\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32780    58]\n",
      " [    6 32832]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.998236546062633\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32780    58]\n",
      " [    6 32832]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9990711980023144\n",
      "Precision 0.9983276066530848\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32783    55]\n",
      " [    6 32832]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9990559717400572\n",
      "Precision 0.9983578640068118\n",
      "Recall 0.9997563798038858\n",
      "Confusion Matrix [[32784    54]\n",
      " [    8 32830]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.9983577641262696\n",
      "Recall 0.9996954747548572\n",
      "Confusion Matrix [[32784    54]\n",
      " [   10 32828]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9990102929532858\n",
      "Precision 0.9983880288329937\n",
      "Recall 0.9996345697058286\n",
      "Confusion Matrix [[32785    53]\n",
      " [   12 32826]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.9984487163888551\n",
      "Recall 0.9996041171813144\n",
      "Confusion Matrix [[32787    51]\n",
      " [   13 32825]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.9984487163888551\n",
      "Recall 0.9996041171813144\n",
      "Confusion Matrix [[32787    51]\n",
      " [   13 32825]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.9989950666910287\n",
      "Precision 0.9984486220113159\n",
      "Recall 0.9995432121322858\n",
      "Confusion Matrix [[32787    51]\n",
      " [   15 32823]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8708965223217005\n",
      "Precision 0.9988123029037146\n",
      "Recall 0.7426761678543151\n",
      "Confusion Matrix [[32809    29]\n",
      " [ 8450 24388]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8711249162555575\n",
      "Precision 0.999590063130278\n",
      "Recall 0.742554357756258\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8454 24384]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8710792374687861\n",
      "Precision 0.999590012709606\n",
      "Recall 0.7424630001827152\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8457 24381]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8710792374687861\n",
      "Precision 0.9996309811800402\n",
      "Recall 0.7424325476582009\n",
      "Confusion Matrix [[32829     9]\n",
      " [ 8458 24380]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.871064011206529\n",
      "Precision 0.9996719429180677\n",
      "Recall 0.7423716426091723\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8460 24378]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8708812960594433\n",
      "Precision 0.9996717814064167\n",
      "Recall 0.742006212315001\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8472 24366]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8708203910104148\n",
      "Precision 0.9997127380170716\n",
      "Recall 0.7418539496924295\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8477 24361]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8707594859613862\n",
      "Precision 0.9997126908553604\n",
      "Recall 0.7417321395943723\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8481 24357]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8707899384859005\n",
      "Precision 0.9997947623347837\n",
      "Recall 0.7417321395943723\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8481 24357]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8707290334368719\n",
      "Precision 0.9997947286312505\n",
      "Recall 0.7416103294963152\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8485 24353]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8707138071746148\n",
      "Precision 0.9997947202036376\n",
      "Recall 0.7415798769718009\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8486 24352]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 12\n",
      "Treshold  21.827029617649078\n",
      "Accuracy  0.9987362202326573\n",
      "Precision  0.9979022892408719\n",
      "Recall 0.9995736646568001\n",
      "Confusion Matrix [[32769    69]\n",
      " [   14 32824]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Threshold \",tr)\n",
    "vae_acc = accuracy_score(Y_test, Y_pred)\n",
    "vae_precision = precision_score(Y_test, Y_pred)\n",
    "vae_recall = recall_score(Y_test, Y_pred)\n",
    "vae_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',vae_acc)\n",
    "print('Precision ',vae_precision)\n",
    "print(\"Recall\",vae_recall)\n",
    "print('Confusion Matrix',vae_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(15, activation='relu')(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.7468 - val_loss: 0.5578\n",
      "Epoch 2/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5566 - val_loss: 0.5459\n",
      "Epoch 3/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5351 - val_loss: 0.5427\n",
      "Epoch 4/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5374 - val_loss: 0.5409\n",
      "Epoch 5/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5335 - val_loss: 0.5400\n",
      "Epoch 6/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5369 - val_loss: 0.5389\n",
      "Epoch 7/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5339 - val_loss: 0.5382\n",
      "Epoch 8/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5414 - val_loss: 0.5379\n",
      "Epoch 9/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5571 - val_loss: 0.5376\n",
      "Epoch 10/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5232 - val_loss: 0.5374\n",
      "Epoch 11/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5500 - val_loss: 0.5373\n",
      "Epoch 12/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5355 - val_loss: 0.5371\n",
      "Epoch 13/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5441 - val_loss: 0.5370\n",
      "Epoch 14/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5509 - val_loss: 0.5370\n",
      "Epoch 15/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5309 - val_loss: 0.5369\n",
      "Epoch 16/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5269 - val_loss: 0.5369\n",
      "Epoch 17/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5197 - val_loss: 0.5368\n",
      "Epoch 18/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5329 - val_loss: 0.5366\n",
      "Epoch 19/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5323 - val_loss: 0.5365\n",
      "Epoch 20/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5505 - val_loss: 0.5365\n",
      "Epoch 21/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5520 - val_loss: 0.5364\n",
      "Epoch 22/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5378 - val_loss: 0.5364\n",
      "Epoch 23/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5429 - val_loss: 0.5364\n",
      "Epoch 24/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5448 - val_loss: 0.5363\n",
      "Epoch 25/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5531 - val_loss: 0.5363\n",
      "Epoch 26/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5406 - val_loss: 0.5362\n",
      "Epoch 27/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5161 - val_loss: 0.5362\n",
      "Epoch 28/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5280 - val_loss: 0.5362\n",
      "Epoch 29/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5228 - val_loss: 0.5361\n",
      "Epoch 30/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5261 - val_loss: 0.5361\n",
      "Epoch 31/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5301 - val_loss: 0.5361\n",
      "Epoch 32/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5425 - val_loss: 0.5361\n",
      "Epoch 33/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5310 - val_loss: 0.5361\n",
      "Epoch 34/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5332 - val_loss: 0.5361\n",
      "Epoch 35/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5654 - val_loss: 0.5361\n",
      "Epoch 36/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5523 - val_loss: 0.5361\n",
      "Epoch 37/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5365 - val_loss: 0.5360\n",
      "Epoch 38/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5517 - val_loss: 0.5360\n",
      "Epoch 39/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5488 - val_loss: 0.5359\n",
      "Epoch 40/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5449 - val_loss: 0.5359\n",
      "Epoch 41/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5519 - val_loss: 0.5359\n",
      "Epoch 42/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5512 - val_loss: 0.5359\n",
      "Epoch 43/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5584 - val_loss: 0.5359\n",
      "Epoch 44/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5624 - val_loss: 0.5358\n",
      "Epoch 45/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5411 - val_loss: 0.5358\n",
      "Epoch 46/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5300 - val_loss: 0.5358\n",
      "Epoch 47/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5491 - val_loss: 0.5358\n",
      "Epoch 48/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5616 - val_loss: 0.5358\n",
      "Epoch 49/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5429 - val_loss: 0.5358\n",
      "Epoch 50/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5192 - val_loss: 0.5357\n",
      "Epoch 51/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5465 - val_loss: 0.5358\n",
      "Epoch 52/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5256 - val_loss: 0.5358\n",
      "Epoch 53/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5342 - val_loss: 0.5358\n",
      "Epoch 54/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5416 - val_loss: 0.5358\n",
      "Epoch 55/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5274 - val_loss: 0.5358\n",
      "time: 68.24735140800476\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                1740      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 115)               1840      \n",
      "=================================================================\n",
      "Total params: 3,580\n",
      "Trainable params: 3,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = uc_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_undercomplete.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9917016870698581\n",
      "Precision 0.983732286767129\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32295   543]\n",
      " [    2 32836]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.998157622266886\n",
      "Precision 0.9964492731631817\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32721   117]\n",
      " [    4 32834]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9984773737742859\n",
      "Precision 0.9970847251746128\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32742    96]\n",
      " [    4 32834]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9985535050855716\n",
      "Precision 0.9972663487531513\n",
      "Recall 0.9998477373774286\n",
      "Confusion Matrix [[32748    90]\n",
      " [    5 32833]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9986600889213716\n",
      "Precision 0.9975086589293309\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32756    82]\n",
      " [    6 32832]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9988275778062001\n",
      "Precision 0.9978421420539161\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32767    71]\n",
      " [    6 32832]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9988428040684573\n",
      "Precision 0.9978724697586773\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32768    70]\n",
      " [    6 32832]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9989493879042572\n",
      "Precision 0.9980848153214774\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32775    63]\n",
      " [    6 32832]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9989646141665144\n",
      "Precision 0.9981151577795343\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32776    62]\n",
      " [    6 32832]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.998236546062633\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32780    58]\n",
      " [    6 32832]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9990407454778001\n",
      "Precision 0.9982668977469671\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32781    57]\n",
      " [    6 32832]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9990711980023144\n",
      "Precision 0.9983276066530848\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32783    55]\n",
      " [    6 32832]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9990407454778001\n",
      "Precision 0.9983275049414627\n",
      "Recall 0.9997563798038858\n",
      "Confusion Matrix [[32783    55]\n",
      " [    8 32830]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9990407454778001\n",
      "Precision 0.9983578140680595\n",
      "Recall 0.9997259272793715\n",
      "Confusion Matrix [[32784    54]\n",
      " [    9 32829]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9989950666910287\n",
      "Precision 0.9983879798041243\n",
      "Recall 0.9996041171813144\n",
      "Confusion Matrix [[32785    53]\n",
      " [   13 32825]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.9990102929532858\n",
      "Precision 0.9984183471727955\n",
      "Recall 0.9996041171813144\n",
      "Confusion Matrix [[32786    52]\n",
      " [   13 32825]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.9990102929532858\n",
      "Precision 0.9984486692015209\n",
      "Recall 0.9995736646568001\n",
      "Confusion Matrix [[32787    51]\n",
      " [   14 32824]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.9989798404287715\n",
      "Precision 0.9984485748182399\n",
      "Recall 0.9995127596077715\n",
      "Confusion Matrix [[32787    51]\n",
      " [   16 32822]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8708660697971862\n",
      "Precision 0.9988122056113046\n",
      "Recall 0.7426152628052866\n",
      "Confusion Matrix [[32809    29]\n",
      " [ 8452 24386]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8710944637310433\n",
      "Precision 0.9995900295178747\n",
      "Recall 0.7424934527072294\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8456 24382]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.871064011206529\n",
      "Precision 0.999589995899959\n",
      "Recall 0.7424325476582009\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8458 24380]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8710487849442718\n",
      "Precision 0.9995899790889335\n",
      "Recall 0.7424020951336866\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8459 24379]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8709726536329861\n",
      "Precision 0.9996718621821165\n",
      "Recall 0.7421889274620866\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8466 24372]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8708356172726719\n",
      "Precision 0.9996717410036519\n",
      "Recall 0.741914854741458\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8475 24363]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8708051647481576\n",
      "Precision 0.9997127262280954\n",
      "Recall 0.7418234971679152\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8478 24360]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8707594859613862\n",
      "Precision 0.9997126908553604\n",
      "Recall 0.7417321395943723\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8481 24357]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8707138071746148\n",
      "Precision 0.9997126554739132\n",
      "Recall 0.7416407820208295\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8484 24354]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8707290334368719\n",
      "Precision 0.9997947286312505\n",
      "Recall 0.7416103294963152\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8485 24353]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8706985809123576\n",
      "Precision 0.9997947117753325\n",
      "Recall 0.7415494244472867\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8487 24351]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 12\n",
      "Treshold  21.383059035779077\n",
      "Accuracy  0.9987362202326573\n",
      "Precision  0.9979022892408719\n",
      "Recall 0.9995736646568001\n",
      "Confusion Matrix [[32769    69]\n",
      " [   14 32824]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Threshold \",tr)\n",
    "uc_acc = accuracy_score(Y_test, Y_pred)\n",
    "uc_precision = precision_score(Y_test, Y_pred)\n",
    "uc_recall = recall_score(Y_test, Y_pred)\n",
    "uc_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',uc_acc)\n",
    "print('Precision ',uc_precision)\n",
    "print(\"Recall\",uc_recall)\n",
    "print('Confusion Matrix',uc_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(200, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-6))(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1027/1027 [==============================] - 3s 2ms/step - loss: 0.6099 - val_loss: 0.5390\n",
      "Epoch 2/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5433 - val_loss: 0.5368\n",
      "Epoch 3/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5360 - val_loss: 0.5358\n",
      "Epoch 4/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5542 - val_loss: 0.5352\n",
      "Epoch 5/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5215 - val_loss: 0.5350\n",
      "Epoch 6/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5249 - val_loss: 0.5348\n",
      "Epoch 7/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5429 - val_loss: 0.5346\n",
      "Epoch 8/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5436 - val_loss: 0.5344\n",
      "Epoch 9/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5509 - val_loss: 0.5343\n",
      "Epoch 10/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5523 - val_loss: 0.5342\n",
      "Epoch 11/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5623 - val_loss: 0.5341\n",
      "Epoch 12/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5312 - val_loss: 0.5342\n",
      "Epoch 13/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5379 - val_loss: 0.5341\n",
      "Epoch 14/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5384 - val_loss: 0.5340\n",
      "Epoch 15/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5338 - val_loss: 0.5339\n",
      "Epoch 16/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5286 - val_loss: 0.5339\n",
      "Epoch 17/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5420 - val_loss: 0.5339\n",
      "Epoch 18/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5276 - val_loss: 0.5338\n",
      "Epoch 19/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5314 - val_loss: 0.5338\n",
      "Epoch 20/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5322 - val_loss: 0.5338\n",
      "Epoch 21/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5426 - val_loss: 0.5338\n",
      "Epoch 22/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5545 - val_loss: 0.5337\n",
      "Epoch 23/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5311 - val_loss: 0.5337\n",
      "Epoch 24/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5236 - val_loss: 0.5338\n",
      "Epoch 25/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5280 - val_loss: 0.5337\n",
      "Epoch 26/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5284 - val_loss: 0.5338\n",
      "Epoch 27/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5455 - val_loss: 0.5337\n",
      "Epoch 28/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5321 - val_loss: 0.5337\n",
      "Epoch 29/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5445 - val_loss: 0.5336\n",
      "Epoch 30/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5587 - val_loss: 0.5336\n",
      "Epoch 31/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5438 - val_loss: 0.5338\n",
      "Epoch 32/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5350 - val_loss: 0.5336\n",
      "Epoch 33/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5427 - val_loss: 0.5336\n",
      "Epoch 34/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5380 - val_loss: 0.5336\n",
      "Epoch 35/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5277 - val_loss: 0.5336\n",
      "Epoch 36/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5463 - val_loss: 0.5336\n",
      "Epoch 37/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5508 - val_loss: 0.5336\n",
      "Epoch 38/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5301 - val_loss: 0.5336\n",
      "Epoch 39/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5449 - val_loss: 0.5335\n",
      "Epoch 40/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5472 - val_loss: 0.5335\n",
      "Epoch 41/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5291 - val_loss: 0.5335\n",
      "Epoch 42/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5366 - val_loss: 0.5335\n",
      "Epoch 43/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5322 - val_loss: 0.5337\n",
      "Epoch 44/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5247 - val_loss: 0.5335\n",
      "Epoch 45/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5405 - val_loss: 0.5335\n",
      "Epoch 46/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5306 - val_loss: 0.5336\n",
      "Epoch 47/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5468 - val_loss: 0.5335\n",
      "Epoch 48/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5327 - val_loss: 0.5337\n",
      "Epoch 49/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5322 - val_loss: 0.5335\n",
      "Epoch 50/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5529 - val_loss: 0.5335\n",
      "Epoch 51/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5418 - val_loss: 0.5335\n",
      "Epoch 52/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5420 - val_loss: 0.5335\n",
      "Epoch 53/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5203 - val_loss: 0.5340\n",
      "Epoch 54/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5383 - val_loss: 0.5334\n",
      "Epoch 55/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5366 - val_loss: 0.5335\n",
      "Epoch 56/100\n",
      "1027/1027 [==============================] - 2s 1ms/step - loss: 0.5283 - val_loss: 0.5335\n",
      "Epoch 57/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5347 - val_loss: 0.5335\n",
      "Epoch 58/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5255 - val_loss: 0.5335\n",
      "Epoch 59/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5354 - val_loss: 0.5334\n",
      "Epoch 60/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5333 - val_loss: 0.5334\n",
      "Epoch 61/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5492 - val_loss: 0.5334\n",
      "Epoch 62/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5402 - val_loss: 0.5335\n",
      "Epoch 63/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5344 - val_loss: 0.5335\n",
      "Epoch 64/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5494 - val_loss: 0.5335\n",
      "Epoch 65/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5217 - val_loss: 0.5334\n",
      "Epoch 66/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.5321 - val_loss: 0.5334\n",
      "time: 101.06451654434204\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               23200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 115)               23115     \n",
      "=================================================================\n",
      "Total params: 46,315\n",
      "Trainable params: 46,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = sparse_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9915951032340581\n",
      "Precision 0.9835260288743785\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32288   550]\n",
      " [    2 32836]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.998157622266886\n",
      "Precision 0.9964492731631817\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32721   117]\n",
      " [    4 32834]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9984773737742859\n",
      "Precision 0.9970847251746128\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32742    96]\n",
      " [    4 32834]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9985839576100859\n",
      "Precision 0.9973269341757541\n",
      "Recall 0.9998477373774286\n",
      "Confusion Matrix [[32750    88]\n",
      " [    5 32833]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9986600889213716\n",
      "Precision 0.9975086589293309\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32756    82]\n",
      " [    6 32832]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9988275778062001\n",
      "Precision 0.9978421420539161\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32767    71]\n",
      " [    6 32832]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9988428040684573\n",
      "Precision 0.9978724697586773\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32768    70]\n",
      " [    6 32832]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9989493879042572\n",
      "Precision 0.9980848153214774\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32775    63]\n",
      " [    6 32832]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9989646141665144\n",
      "Precision 0.9981151577795343\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32776    62]\n",
      " [    6 32832]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9989798404287715\n",
      "Precision 0.99814550208251\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32777    61]\n",
      " [    6 32832]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9990407454778001\n",
      "Precision 0.9982668977469671\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32781    57]\n",
      " [    6 32832]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9990711980023144\n",
      "Precision 0.9983276066530848\n",
      "Recall 0.9998172848529143\n",
      "Confusion Matrix [[32783    55]\n",
      " [    6 32832]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9990407454778001\n",
      "Precision 0.9983275049414627\n",
      "Recall 0.9997563798038858\n",
      "Confusion Matrix [[32783    55]\n",
      " [    8 32830]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.999025519215543\n",
      "Precision 0.9983577641262696\n",
      "Recall 0.9996954747548572\n",
      "Confusion Matrix [[32784    54]\n",
      " [   10 32828]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9989950666910287\n",
      "Precision 0.9983879798041243\n",
      "Recall 0.9996041171813144\n",
      "Confusion Matrix [[32785    53]\n",
      " [   13 32825]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.9990102929532858\n",
      "Precision 0.9984183471727955\n",
      "Recall 0.9996041171813144\n",
      "Confusion Matrix [[32786    52]\n",
      " [   13 32825]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.9990102929532858\n",
      "Precision 0.9984486692015209\n",
      "Recall 0.9995736646568001\n",
      "Confusion Matrix [[32787    51]\n",
      " [   14 32824]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.9989798404287715\n",
      "Precision 0.9984485748182399\n",
      "Recall 0.9995127596077715\n",
      "Confusion Matrix [[32787    51]\n",
      " [   16 32822]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8708660697971862\n",
      "Precision 0.9988122056113046\n",
      "Recall 0.7426152628052866\n",
      "Confusion Matrix [[32809    29]\n",
      " [ 8452 24386]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8710944637310433\n",
      "Precision 0.9995900295178747\n",
      "Recall 0.7424934527072294\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8456 24382]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.871064011206529\n",
      "Precision 0.999589995899959\n",
      "Recall 0.7424325476582009\n",
      "Confusion Matrix [[32828    10]\n",
      " [ 8458 24380]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8710487849442718\n",
      "Precision 0.9996309509164719\n",
      "Recall 0.7423716426091723\n",
      "Confusion Matrix [[32829     9]\n",
      " [ 8460 24378]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8709878798952433\n",
      "Precision 0.9996718756408679\n",
      "Recall 0.7422193799866009\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8465 24373]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8708356172726719\n",
      "Precision 0.9996717410036519\n",
      "Recall 0.741914854741458\n",
      "Confusion Matrix [[32830     8]\n",
      " [ 8475 24363]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8708051647481576\n",
      "Precision 0.9997127262280954\n",
      "Recall 0.7418234971679152\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8478 24360]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8707594859613862\n",
      "Precision 0.9997126908553604\n",
      "Recall 0.7417321395943723\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8481 24357]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8707290334368719\n",
      "Precision 0.9997126672686971\n",
      "Recall 0.7416712345453438\n",
      "Confusion Matrix [[32831     7]\n",
      " [ 8483 24355]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8707290334368719\n",
      "Precision 0.9997947286312505\n",
      "Recall 0.7416103294963152\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8485 24353]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8706985809123576\n",
      "Precision 0.9997947117753325\n",
      "Recall 0.7415494244472867\n",
      "Confusion Matrix [[32833     5]\n",
      " [ 8487 24351]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 12\n",
      "Treshold  21.347145231367207\n",
      "Accuracy  0.9987362202326573\n",
      "Precision  0.9979022892408719\n",
      "Recall 0.9995736646568001\n",
      "Confusion Matrix [[32769    69]\n",
      " [   14 32824]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Threshold \",tr)\n",
    "sparse_acc = accuracy_score(Y_test, Y_pred)\n",
    "sparse_precision = precision_score(Y_test, Y_pred)\n",
    "sparse_recall = recall_score(Y_test, Y_pred)\n",
    "sparse_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',sparse_acc)\n",
    "print('Precision ',sparse_precision)\n",
    "print(\"Recall\",sparse_recall)\n",
    "print('Confusion Matrix',sparse_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_model(input_dim):\n",
    "    input_size = input_dim\n",
    "    hidden_size = 44\n",
    "    code_size = 5\n",
    "\n",
    "    input_img = Input(shape=(input_size,))\n",
    "    hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "    code = Dense(code_size, activation='relu')(hidden_1)\n",
    "    hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "    output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "    autoencoder = Model(input_img, output_img)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.8382 - val_loss: 0.6866\n",
      "Epoch 2/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6849 - val_loss: 0.6401\n",
      "Epoch 3/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6399 - val_loss: 0.6352\n",
      "Epoch 4/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6339 - val_loss: 0.6259\n",
      "Epoch 5/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6380 - val_loss: 0.6235\n",
      "Epoch 6/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6201 - val_loss: 0.6184\n",
      "Epoch 7/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6359 - val_loss: 0.6156\n",
      "Epoch 8/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6202 - val_loss: 0.6159\n",
      "Epoch 9/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6143 - val_loss: 0.6144\n",
      "Epoch 10/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6289 - val_loss: 0.6169\n",
      "Epoch 11/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6147 - val_loss: 0.6119\n",
      "Epoch 12/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6258 - val_loss: 0.6128\n",
      "Epoch 13/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6180 - val_loss: 0.6115\n",
      "Epoch 14/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6269 - val_loss: 0.6126\n",
      "Epoch 15/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6198 - val_loss: 0.6141\n",
      "Epoch 16/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6289 - val_loss: 0.6123\n",
      "Epoch 17/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6247 - val_loss: 0.6138\n",
      "Epoch 18/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6146 - val_loss: 0.6099\n",
      "Epoch 19/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6152 - val_loss: 0.6099\n",
      "Epoch 20/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6179 - val_loss: 0.6159\n",
      "Epoch 21/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6243 - val_loss: 0.6108\n",
      "Epoch 22/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6083 - val_loss: 0.6109\n",
      "Epoch 23/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6172 - val_loss: 0.6094\n",
      "Epoch 24/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6129 - val_loss: 0.6089\n",
      "Epoch 25/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6075 - val_loss: 0.6128\n",
      "Epoch 26/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6129 - val_loss: 0.6089\n",
      "Epoch 27/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6230 - val_loss: 0.6129\n",
      "Epoch 28/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6099 - val_loss: 0.6095\n",
      "Epoch 29/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6072 - val_loss: 0.6077\n",
      "Epoch 30/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6024 - val_loss: 0.6094\n",
      "Epoch 31/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6160 - val_loss: 0.6080\n",
      "Epoch 32/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6079 - val_loss: 0.6104\n",
      "Epoch 33/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6041 - val_loss: 0.6070\n",
      "Epoch 34/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6297 - val_loss: 0.6072\n",
      "Epoch 35/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6145 - val_loss: 0.6072\n",
      "Epoch 36/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6153 - val_loss: 0.6067\n",
      "Epoch 37/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6111 - val_loss: 0.6078\n",
      "Epoch 38/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5967 - val_loss: 0.6094\n",
      "Epoch 39/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6128 - val_loss: 0.6056\n",
      "Epoch 40/100\n",
      "1027/1027 [==============================] - 1s 1ms/step - loss: 0.6260 - val_loss: 0.6088\n",
      "Epoch 41/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5945 - val_loss: 0.6060\n",
      "Epoch 42/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6134 - val_loss: 0.6094\n",
      "Epoch 43/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5987 - val_loss: 0.6051\n",
      "Epoch 44/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6051 - val_loss: 0.6063\n",
      "Epoch 45/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6003 - val_loss: 0.6065\n",
      "Epoch 46/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5908 - val_loss: 0.6095\n",
      "Epoch 47/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6265 - val_loss: 0.6043\n",
      "Epoch 48/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6157 - val_loss: 0.6060\n",
      "Epoch 49/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6313 - val_loss: 0.6048\n",
      "Epoch 50/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5992 - val_loss: 0.6040\n",
      "Epoch 51/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6021 - val_loss: 0.6046\n",
      "Epoch 52/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6121 - val_loss: 0.6045\n",
      "Epoch 53/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.5986 - val_loss: 0.6048\n",
      "Epoch 54/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6158 - val_loss: 0.6048\n",
      "Epoch 55/100\n",
      "1027/1027 [==============================] - 2s 2ms/step - loss: 0.6190 - val_loss: 0.6052\n",
      "time: 83.6279628276825\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 44)                5104      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 225       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 44)                264       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 115)               5175      \n",
      "=================================================================\n",
      "Total params: 10,768\n",
      "Trainable params: 10,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "x_opt_noisy = np.clip(x_opt_noisy, 0., 1.)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "#x_train_noisy = scaler.fit_transform(x_train_noisy)\n",
    "#x_opt_noisy = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#call function to create the model\n",
    "model = denoise_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(x_train_noisy, X_train,\n",
    "                    epochs=epochs, validation_data=(x_opt_noisy, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.6331232109141848\n",
      "Precision 0.5767832364358105\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 8743 24095]\n",
      " [    0 32838]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.7478987758085145\n",
      "Precision 0.6648041299726692\n",
      "Recall 1.0\n",
      "Confusion Matrix [[16281 16557]\n",
      " [    0 32838]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8336074060539619\n",
      "Precision 0.7503198976327575\n",
      "Recall 0.9999695474754857\n",
      "Confusion Matrix [[21911 10927]\n",
      " [    1 32837]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8925787197758694\n",
      "Precision 0.8231681331628689\n",
      "Recall 0.9999695474754857\n",
      "Confusion Matrix [[25784  7054]\n",
      " [    1 32837]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9302789451245508\n",
      "Precision 0.877642656688494\n",
      "Recall 0.9999695474754857\n",
      "Confusion Matrix [[28260  4578]\n",
      " [    1 32837]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9549607162433765\n",
      "Precision 0.9173883891154943\n",
      "Recall 0.9999695474754857\n",
      "Confusion Matrix [[29881  2957]\n",
      " [    1 32837]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9694408916499178\n",
      "Precision 0.9424274603220159\n",
      "Recall 0.9999695474754857\n",
      "Confusion Matrix [[30832  2006]\n",
      " [    1 32837]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9778153358913454\n",
      "Precision 0.957542355582772\n",
      "Recall 0.9999695474754857\n",
      "Confusion Matrix [[31382  1456]\n",
      " [    1 32837]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9840885559412875\n",
      "Precision 0.9692139673544083\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[31795  1043]\n",
      " [    2 32836]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9879408002923442\n",
      "Precision 0.9765062749063225\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32048   790]\n",
      " [    2 32836]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9911839941531153\n",
      "Precision 0.9827312722593002\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32261   577]\n",
      " [    2 32836]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9932395395578294\n",
      "Precision 0.986717951799988\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32396   442]\n",
      " [    2 32836]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9944728668006578\n",
      "Precision 0.9891255233906678\n",
      "Recall 0.9999390949509714\n",
      "Confusion Matrix [[32477   361]\n",
      " [    2 32836]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9951275960777148\n",
      "Precision 0.9904379826254827\n",
      "Recall 0.9999086424264572\n",
      "Confusion Matrix [[32521   317]\n",
      " [    3 32835]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9956148364699433\n",
      "Precision 0.9913949275362319\n",
      "Recall 0.9999086424264572\n",
      "Confusion Matrix [[32553   285]\n",
      " [    3 32835]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.9960259455508862\n",
      "Precision 0.9922037893210044\n",
      "Recall 0.9999086424264572\n",
      "Confusion Matrix [[32580   258]\n",
      " [    3 32835]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.9964218283695718\n",
      "Precision 0.9930137607742325\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32607   231]\n",
      " [    4 32834]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.9968177111882575\n",
      "Precision 0.993795211719483\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32633   205]\n",
      " [    4 32834]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.9971831414824289\n",
      "Precision 0.9945176434953809\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32657   181]\n",
      " [    4 32834]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.9975485717766003\n",
      "Precision 0.9952411263677973\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32681   157]\n",
      " [    4 32834]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.9978074182349717\n",
      "Precision 0.9957542306059319\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32698   140]\n",
      " [    4 32834]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.9978987758085145\n",
      "Precision 0.9959354525600582\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32704   134]\n",
      " [    4 32834]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.9980053596443145\n",
      "Precision 0.9961469615606323\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32711   127]\n",
      " [    4 32834]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.9981271697423716\n",
      "Precision 0.9963887961642339\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32719   119]\n",
      " [    4 32834]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.9981728485291431\n",
      "Precision 0.9964795144157815\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32722   116]\n",
      " [    4 32834]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.9982337535781717\n",
      "Precision 0.996600497784253\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32726   112]\n",
      " [    4 32834]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.9982489798404288\n",
      "Precision 0.9966307482167248\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32727   111]\n",
      " [    4 32834]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.9982946586272002\n",
      "Precision 0.9967215105336652\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32730   108]\n",
      " [    4 32834]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.9983555636762288\n",
      "Precision 0.9968425526747222\n",
      "Recall 0.9998781899019429\n",
      "Confusion Matrix [[32734   104]\n",
      " [    4 32834]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(x_opt_noisy)\n",
    "mse = np.mean(np.power(x_opt_noisy - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "X_opt_scaled = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 29\n",
      "Treshold  7.13378303198655\n",
      "Accuracy  0.9999238686887143\n",
      "Precision  1.0\n",
      "Recall 0.9998477373774286\n",
      "Confusion Matrix [[32838     0]\n",
      " [    5 32833]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(x_test_noisy, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=20)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "X_test_scaled = scaler.transform(x_test_noisy)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Threshold \",tr)\n",
    "denoise_acc = accuracy_score(Y_test, Y_pred)\n",
    "denoise_precision = precision_score(Y_test, Y_pred)\n",
    "denoise_recall = recall_score(Y_test, Y_pred)\n",
    "denoise_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',denoise_acc)\n",
    "print('Precision ',denoise_precision)\n",
    "print(\"Recall\",denoise_recall)\n",
    "print('Confusion Matrix',denoise_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(80, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Dense(labels.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, callbacks=[monitor], patience=5) \n",
    "    model.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n",
    "          verbose=1,epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 1\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 0\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))\n",
    "\n",
    "X = df_ben.drop(columns=['class'])\n",
    "y = df_ben['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=17)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3503/3503 [==============================] - 5s 966us/step - loss: 0.0052\n",
      "Epoch 2/100\n",
      "3503/3503 [==============================] - 3s 884us/step - loss: 0.0013\n",
      "Epoch 3/100\n",
      "3503/3503 [==============================] - 3s 982us/step - loss: 0.0011\n",
      "Epoch 4/100\n",
      "3503/3503 [==============================] - 3s 819us/step - loss: 8.2216e-04\n",
      "Epoch 5/100\n",
      "3503/3503 [==============================] - 3s 767us/step - loss: 7.0724e-04\n",
      "Epoch 6/100\n",
      "3503/3503 [==============================] - 3s 789us/step - loss: 0.0011\n",
      "Epoch 7/100\n",
      "3503/3503 [==============================] - 3s 769us/step - loss: 9.1269e-04\n",
      "Epoch 8/100\n",
      "3503/3503 [==============================] - 3s 763us/step - loss: 8.8811e-04\n",
      "Epoch 9/100\n",
      "3503/3503 [==============================] - 3s 806us/step - loss: 6.8285e-04\n",
      "time 27.796162843704224\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_dim=115, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "\n",
    "#compile and fit model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=15,callbacks=[es])\n",
    "\n",
    "end = time.time()\n",
    "print(\"time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9986297198538368\n",
      "Precision  0.998180991359709\n",
      "Recall 0.999089667728721\n",
      "Confusion Matrix [[6533   12]\n",
      " [   6 6585]]\n"
     ]
    }
   ],
   "source": [
    "dnn_acc = accuracy_score(y_test, y_pred)\n",
    "dnn_precision = precision_score(y_test, y_pred)\n",
    "dnn_recall = recall_score(y_test, y_pred)\n",
    "dnn_cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy ',dnn_acc)\n",
    "print('Precision ',dnn_precision)\n",
    "print(\"Recall\",dnn_recall)\n",
    "print('Confusion Matrix',dnn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provision PT_838_Security Camera\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>CM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep AutoEncoder</td>\n",
       "      <td>0.870029</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.740514</td>\n",
       "      <td>[[32823, 15], [8521, 24317]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variational AutoEncoder</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.997902</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>[[32769, 69], [14, 32824]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse AutoEncoder</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.997902</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>[[32769, 69], [14, 32824]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undercomplete Autoencoder</td>\n",
       "      <td>0.998736</td>\n",
       "      <td>0.997902</td>\n",
       "      <td>0.999574</td>\n",
       "      <td>[[32769, 69], [14, 32824]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denoising Autoendoer</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999848</td>\n",
       "      <td>[[32838, 0], [5, 32833]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  \\\n",
       "0           Deep AutoEncoder  0.870029   0.999384  0.740514   \n",
       "1    Variational AutoEncoder  0.998736   0.997902  0.999574   \n",
       "2         Sparse AutoEncoder  0.998736   0.997902  0.999574   \n",
       "3  Undercomplete Autoencoder  0.998736   0.997902  0.999574   \n",
       "4       Denoising Autoendoer  0.999924   1.000000  0.999848   \n",
       "\n",
       "                             CM  \n",
       "0  [[32823, 15], [8521, 24317]]  \n",
       "1    [[32769, 69], [14, 32824]]  \n",
       "2    [[32769, 69], [14, 32824]]  \n",
       "3    [[32769, 69], [14, 32824]]  \n",
       "4      [[32838, 0], [5, 32833]]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Provision PT_838_Security Camera\")\n",
    "model_summary = pd.DataFrame({'Model' :['Deep AutoEncoder',\"Variational AutoEncoder\",\"Sparse AutoEncoder\",\"Undercomplete Autoencoder\",\"Denoising Autoendoer\"],\n",
    "                             'Accuracy':[deep_acc,vae_acc,sparse_acc,uc_acc,denoise_acc],\n",
    "                             'Precision':[deep_precision,vae_precision,sparse_precision,uc_precision,denoise_precision],\n",
    "                             'Recall':[deep_recall,vae_recall,sparse_recall,uc_recall,denoise_recall],\n",
    "                             'CM':[deep_cm,vae_cm,sparse_cm,uc_cm, denoise_cm]})\n",
    "model_summary.sort_values(by='Accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
