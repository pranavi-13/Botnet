{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=pd.read_csv(\"SimpleHome_XCS7_1002_WHT_Security_Camera/benign_traffic.csv\")\n",
    "x_train, x_opt, x_test = np.split(benign.sample(frac=1, random_state=20), [int(1/3*len(benign)), int(2/3*len(benign))])\n",
    "\n",
    "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('SimpleHome_XCS7_1002_WHT_Security_Camera/mirai/*.csv', recursive=False)), ignore_index=True)\n",
    "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('SimpleHome_XCS7_1002_WHT_Security_Camera/gafgyt/*.csv', recursive=False)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 'malicious'\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 'benign'\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting samples of benign and malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEJCAYAAACHRBAhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABVW0lEQVR4nO29eXyU5bn//7lmEhJCAoQdghCoMcgmKFWpVsHWI5xa6WYLtdW2Vuz3aLXbqWjPqdUe/elX22/12NbicaulcNTqqXIaaKtRrMYF3BBkDMgWCGsIEEJClvv3x2dun2cmszyzJTPJ9X695jUzzzzLPU8y93VfuxhjoCiKoijx8PX0ABRFUZTcQAWGoiiK4gkVGIqiKIonVGAoiqIonlCBoSiKonhCBYaiKIriiYwKDBF5SET2ich7rm13icgmEXlXRJ4WkcGuz24Ukc0iEhCRi1zbzxCR9cHP7hURyeS4FUVRlK5IJvMwROQ8AE0Afm+MmRrc9k8AnjfGtIvInQBgjLlBRCYDWA7gTABjAPwdwCnGmA4ReR3A9QBeBfAXAPcaY6riXX/YsGGmvLw8A99MURSld7Ju3boDxpjhkT7Ly+SFjTFrRKQ8bNtfXW9fBfCl4OsFAFYYY1oBbBWRzQDOFJFtAAYaY2oAQER+D+BzAOIKjPLycqxduzbVr6EoitJnEJHt0T7raR/Gt+BM/GUAdro+qwtuKwu+Dt+uKIqidCM9JjBE5CcA2gEss5si7GZibI923sUislZE1u7fvz/1gSqKoigAekhgiMgVAC4GcJlxnCh1AE5y7TYWwO7g9rERtkfEGLPUGDPLGDNr+PCIZjhFURQlCTLqw4iEiMwDcAOA840xza6PngHwRxH5Jej0rgDwetDpfVREzgbwGoDLAfxnstdva2tDXV0dWlpakv8SvZDCwkKMHTsW+fn5PT0URVGylIwKDBFZDmAOgGEiUgfgZgA3AigA8LdgdOyrxpjvGGM2iMjjADaCpqprjDEdwVP9HwCPAOgP+jziOryjUVdXh5KSEpSXl0Ojc4kxBgcPHkRdXR0mTJjQ08NRFCVLyXSU1KIImx+Msf9tAG6LsH0tgKnpGFNLS4sKizBEBEOHDoX6fBRFiUW3m6SyARUWXdF7oig5SiAA1NYCFRVAZWVGL9UnBYaiKEqvIBAAbr8d8PuBjg7gppsyKjR6Og9D6WbKy8tx4MCBnh6GoijpoLaWwmLcOD7X1mb0ciowcoj29vaeHoKiKNlERQU1ix07+FxRkdHLqcDoZrZt24ZTTz0VV111FaZMmYJ/+qd/wvHjx/H222/j7LPPxvTp0/H5z38ehw4dAgDMmTMHN910E84//3zcc889mDNnDr7//e/jvPPOw6mnnoo33ngDX/jCF1BRUYF/+7d/++g6n/vc53DGGWdgypQpWLp0aU99XUVRMkllJc1QX/hCxs1RgAoMTwQCwMqVfE4HtbW1uOaaa7BhwwYMHjwYf/rTn3D55ZfjzjvvxLvvvotp06bhlltu+Wj/xsZGvPjii/jhD38IAOjXrx/WrFmD73znO1iwYAF+/etf47333sMjjzyCgwcPAgAeeughrFu3DmvXrsW999770XZFUXoZlZXAxRdnXFgA6vSOSyZ8ShMmTMCMGTMAAGeccQa2bNmCxsZGnH/++QCAK664ApdeeulH+3/lK18JOf6SSy4BAEybNg1TpkzB6NGjAQATJ07Ezp07MXToUNx77714+umnAQA7d+5EbW0thg4dmtrAFUXp06iGEYdM+JQKCgo+eu33+9HY2Bhz/wEDBkQ83ufzhZzL5/Ohvb0dL7zwAv7+97+jpqYG77zzDmbOnKmZ7YqipIwKjDh0h09p0KBBKC0txUsvvQQAeOyxxz7SNpLh8OHDKC0tRVFRETZt2oRXX301XUNVFKUPoyapOFifUqbzYh599FF85zvfQXNzMyZOnIiHH3446XPNmzcP999/P6ZPn47KykqcffbZaRypoih9lYx23OtpZs2aZcIbKL3//vs49dRTe2hE2Y3eG0VRRGSdMWZWpM/UJKUoiqJ4Qk1SiqIoqdCNtZx6GhUYiqIoydLNtZx6GjVJKYqiJEt31XJKd/ZwkqiGoSiKkizdEXefRVqMCgxFUZRk6Y64e7cWs2MH3/eQwFCTVJZw++23f/S6sbERv/nNb5I+1ze+8Q08+eST6RiWoijxyHQtp26uSBsLFRhZQjoFhqIovYhEKtJm2NehJqke4HOf+xx27tyJlpYWXH/99fjwww9x/PhxzJgxA1OmTEFHRwe2bNmCGTNm4MILL8TNN9+MBQsW4NChQ2hra8N//Md/YMGCBQCA3//+97j77rshIpg+fToee+yxkGv9+7//O3bu3ImHHnoIPp+uDxQlJ6msjK/BdIOvQwWGF9IcZ/3QQw9hyJAhOH78OD7+8Y/jxRdfxH333Ye3334bAHtmvPfeex+9b29vx9NPP42BAwfiwIEDOPvss3HJJZdg48aNuO222/Dyyy9j2LBhaGhoCLnOj3/8Yxw+fBgPP/yw9uxWlN5ON/g6VGDEIwNSO1Lp8VgYY3DTTTdhzZo18Pl82LVrF/bu3Yvnn38eX/rSlzBs2DAAwJAhQz465uc//znOOussbZ6kZJ4+lLiW1XSDr0MFRjzSLLXdpceLioowZ86cuKXHly1bhv3792PdunXIz89HeXk5WlpaYIyJqjl8/OMfx7p169DQ0BAiSBQlrWRRyGefpxsittSoHY80S+1opcfz8/PR1tYGACgpKcHRo0dDjhkxYgTy8/NRXV2N7du3AwA+9alP4fHHH/+om57bJDVv3jwsWbIEn/nMZ0LOpShxScRx2l2Ja4o3MhyxpRpGPNIstaOVHl+8eDGmT5+O008/HcuWLcM555yDqVOnYv78+bjhhhvw2c9+FrNmzcKMGTMwadIkAMCUKVPwk5/8BOeffz78fj9mzpyJRx555KNrXXrppTh69CguueQS/OUvf0H//v1TGrvSS3GblABHYzh0CLjoImDu3Oj/91kU8qlknoyWNxeRhwBcDGCfMWZqcNsQAP8NoBzANgBfNsYcCn52I4ArAXQAuM4Yszq4/QwAjwDoD+AvAK43Hgau5c0TQ+9NHyTcpDR7NvD660BREbBqFVBeDpSVxTY1qQ+jV9GT5c0fATAvbNsSAM8ZYyoAPBd8DxGZDGAhgCnBY34jIv7gMb8FsBhARfARfk5FUZIh3KQEUHBYc9SkSfFNTZlOXMsF0pn/kCV1oyKRUZOUMWaNiJSHbV4AYE7w9aMAXgBwQ3D7CmNMK4CtIrIZwJkisg3AQGNMDQCIyO8BfA5AVSbHrih9gnCT0ty5fFRXU8NoblZTUzzS6fjP8iCCnvBhjDTG1AOAMaZeREYEt5cBcDefrgtuawu+Dt+eNLGii/oqvbnzohKDaD66ykoKDjU1xSedkZRZVDcqEtnk9I40g5sY2yOfRGQxaL7CuHHjunxeWFiIgwcPYujQoSo0ghhjcPDgQRQWFvb0UJSeIFoWsZfsYiW9jv8sDyLoCYGxV0RGB7WL0QD2BbfXATjJtd9YALuD28dG2B4RY8xSAEsBOr3DPx87dizq6uqwf//+1L5FL6OwsBBjx46Nv6OiKKGkM5LSfS637yhLBHdPCIxnAFwB4I7g859d2/8oIr8EMAZ0br9ujOkQkaMicjaA1wBcDuA/k714fn4+JkyYkMr4FUVRQklWG7MRZtZn4RY4WejLyKjAEJHloIN7mIjUAbgZFBSPi8iVAHYAuBQAjDEbRORxABsBtAO4xhjTETzV/4ETVlsFdXgripLrWAd3UxPw9tvAjBlAcXGohpFlvoxMR0ktivLRp6LsfxuA2yJsXwtgahqHpiiK0rNYoVBQAPh8fLZmqCz1ZWST01tRFKXvYIVCayvQ2cnn/HzHLJXpTn5JoAJDURTvaFa3N7zcp3AHt1uTWLmSry++uPvG7AEVGIqieCPLk8qyhkTuU7izPNV7XFUF1NSwxMv8+al9jwhotVpFUbyhlWlDiVbCI5X7lMqxVVXAN78J/OpXwFe/CjzwgPdjPaIahqIo3shSR2yPEE0TCASAujpW+gUSv0+p3OPf/x44cID+EIDjO++8tGqBKjAURfFGNEdsX/RrRAp7BRwhYgxw5pmxS8NHIhVn99GjFDKW9va0h+OqwFAUxTuRbO433MBcguJi4M47+4bQiKQJuIUIAIwdm9y9SDYJsLycUVbt7YAIMGRI2rVAFRiKkix9cWUdTnU18N57QEkJsG0b36eS8dyT9zKRMUTTBHrKZBcIAJs2AQMGAG1t7GFyxx1pv5cqMBQlGXItYigbJuRoZMO9TGYM4ZpAT+ZOVFdTYI8aBTQ2AosWaZSUomQN6YwYynTDHDsZPvUUn9N5nblzgWnTgGHD+Dx3buLn6O7oq0j3O9Ux2HMCPdtMqrCQWsaoURk5vWoYipIM6YoY6o7VdSbrElVW0vSRyqo6/F76/Zx8IxXkS5Vo9zuVv2c2aEhz5wJPPskoqfLy5AS3B1RgKEoypGJ+cJuHuqPIXKbDYVPtmxGe8bxiReSCfOm4L9Hud/jfE/AutLz8DbvDJFhcHPqcAVRgKL2DVH+QgQDtwID3UMhkJsrw1ejChZl3lGZpXaIQ7L20k3SkgnzpGHcs4WnH4K4i+8YbjHYaOTK6EzmeQO4uLXLIEArYDFa3VYGh5D6p/iBtaOh77/H96tXRJwcvginWPuGrUTveTE/mmeiel4lVc6yCfOkgmibh/g72b9TaSgdyXh6wb1/0CLB4Ark7tEi/n07vw4epYWQoQksFhpL7pPqDrK3larKkhO+bmqKbFeIJpnj7RFqN5mIr1EytmqMV5Evn/QnXJKL5MxoamIBXUMBQVS/njESmTYKBAM14paUUcN/+dsb+n1RgKLlPqj/IigquyrZt4/vy8sjn8CKY4u2TC+YhL2TakZ6p+xLJf1RUxBwGa5KsraWpcPt24IknmARXXNzVkexVw8r039x+j2nTnN9AhlCBoeQe4T/UVH+QlZXMUI7nw/AimLzsk4saRTi5WFfKrVE0NNDev307HwCjjFav5krdahzjxzvVX8Mz3JcscTLc4yXJZfJv3o1/CzHGZOzkPc2sWbPM2rVre3oYSjrp6RDGVH0Y3UV3jCGd14h2Lvd2ILXrrVwJPPwwfRNvvgmMGEGT04ABwOmnU8sQAc45h5PvmWcCq1Y5QuHqq0PDfp99Fhg6FDh4EPjsZ4HrrusVf28RWWeMmRXpM9UwlOwjEadxd/c69rJS7GkNoruEaqzvGasvQ/jfN1blV7v90CFO7kOGeP9O9jp+P7WIDRuAl18GmpuBY8eA/v2BI0eAfv0oEIzh9vXr+X7PHqfsyQcfALfcAgwcyM8HD3bGdOAA8MorFCw9uYDphmZLKjCU7CIZp3FfJpJwra4Gdu/m++bm7heqVVXA4sX8+zz8MLB0KYXGAw8ATz/NsQ0b5hQrjLYIcG/fuZOTs9ewURv5tm8f8OGHdFw3N3NSLyzkuXbuZKG+khLg1VeBiROBj33McRxbUxVAp3drK6977BhDfvPzeX6/3zl3d97rHtC2VWAo2UVfcRqng0gTBkAzytatfEybFjkvIJP379lnGd5ZVMRJ9Nln2SPiBz/gpNvWRlNOv37A8uWsexRpEeBeHFgNwOtCoboaeOstTu5HjlAzKSzkeACey0Y+tbVRcHz4IXDuucCgQbzG3Ln0aTQ1cbxNTcCJEwz3tccUFvL56FFqHN25gHH/VtavB5YtAy67LKO/CRUYSnbRV5zG6SBaT4YhQ4B582iTv+iirj4Bt5A591yutNPZ0nPECE6ix47xGiNGAM8/z0na0tBAk9CqVRQYkRYBlZWMVqqpAS69lBpAPD+H3b5hA01KnZ0cS0MDtZrBg4Hjx7mPvQfHj1NbaGujb6OiwkkWtJpSRQWwZg1w443Myzh6lEKssZHnOnw48d4XqWJ/K+vXMyse4N82g5qGCgyl54j0Q1cNIjbue+YWrg0NXMWPH89tzc0scR0eCuoWMq+8Avz7v9Ncs3Qp8POfA1dd5f360f42ZWU8Z2cnJ9WzzuK2p592usH5/YxGKivj+SIV7LP5BbZcyE03dbXTR9Oy3niDDmxjqOmMHEmBOGMGv+ubbzpjEaFQ8/mAmTN5DXvdhgYKX3uvOzt5bzs76buwDBgAvPAC8OUvd9//rP2t3HMPv9/o0Rk3QarAUHqGWPZX1SAiE+me3XQTzS+rVwOvv87n005jtdLwFa9tH9rQwPd79/JcLS1cZd93X+yWnl4TF1esoHPY53Mm2quu4or/oYe4/eBBCrdYWck2obKggKas6uquwiqallVWRv9CfT0FxmmnOYJg3DiOs72dWk5nJzWMkSO5z/bt9LMUFgLr1vE8NTX8HocPUwiFR5ceP57eEiaJUF/PMa5aBUydmlGzmAoMpWfo6WinXCTSPbv4Yj6XlnJiXLOG5pJw7cI92YswZHT2bGoYdrIbOTL238Fr4uLgwXw0N3NSrqjg9WfOpJBZvpzOZVtLK9r1/H4KwY4O+g42bwZOPpkT/EUX8fvV13NSr6vjCttOlsXF3LdfP+DTnwa++93QBLc9e3i+tjaamBobOeZbb+W49++nYPX5gC1beI/y8vg+UmJcRwfw/vs8f3di//bz5vEez5unPgylF6LRTokT7Z7Z7ba/w6RJXU0TkdqHWvPOffc5Jo1Yfwd7nVdeoXYye3bo51aD6ezkZN3YCPzoR/zMCqvt2znBeclK3r6dws3noxCsr6em0dzM908+yWv6fNQITjmFx1nfx113AVOmcEzV1Y65bv16+m1OnKB2VVTE1/X11HwKCvgAKFAOHqRD2+ejALSUlPA4ABg+nPc0g1nWEbF/k+ZmYMyYjJU1t3gWGCJyjjHm5XjbEjjf9wF8G4ABsB7ANwEUAfhvAOUAtgH4sjHmUHD/GwFcCaADwHXGmNXJXFfJEtRX4R233yCac9iaplat4uQRLoSjCZurrqIZymuJi3PPdfwed9zBSXL+/FANxhjgwgsdk5itQDtuHE06hw517X0R6dp79nDCtuYfn48RTwCF4j/+wXOMHk0n9//8D/DSS8DnP+/sX1gIvPYaHfADBtCHsW8fx33oEAWfjXg6fJjPHR3c3+LzUXDZXtkiTkmRYcMovFpbKXBWrere/+du/h0lomH8J4DTPWyLi4iUAbgOwGRjzHEReRzAQgCTATxnjLlDRJYAWALgBhGZHPx8CoAxAP4uIqcYY7pZnCtpRX0V8YnkN4iWoDV2rJONHD55xJpYEvk77NzJlXVZGbBrF2378+dH1mCA0J4SNjz22992hMXvfsdJ2xjg5pudSK1AAHjnHU7O1jQk4hSIfPNN+h9sldbWVjqh6+tpQsrPp7DYsIGvR4xwBEdTE6/Z0sLxlJby9e7dPLdbQPn9jhCx3wOgFnX8OK9bUsJjGxqYa7JuHfDII90rNLrpWnEFhojMBvAJAMNF5AeujwYCSMVglwegv4i0gZrFbgA3ApgT/PxRAC8AuAHAAgArjDGtALaKyGYAZwKoSeH6ipI50pXrEO43iOT49ZrAlezE4u4VctJJnCx37eKzNUtF6ppne0ocOsTQWWvysmO4/35O/E1NnJRvuYXbOzpoRiotZcmON99kHsShQzQBtbZSS5g0CfjpT6lZVFc74bLNzRQSAwbQVFRQQAEBUIi8+qqTvDd3LvDJT3K8v/gF/Ro2esr6K4zhs89HAWNLn1vNxGp0duwbN0YvhZ7jeNEw+gEoDu5b4tp+BMCXkrmoMWaXiNwNYAeA4wD+aoz5q4iMNMbUB/epF5ERwUPKALzqOkVdcFsXRGQxgMUAMM6udhSlO0lnBq57Ij50iCaP8PIYqQQQPPAAcyQuuCBySO0DD3AiPXyYE/DUqSy6F567Ea7B2AinDRtoRnrwQeDRR7uOyybPiVAI3HILMHkyV+siTnju5s2cnI2h8zkvj9t27WJ+xmqXhdoYHmtDYM85h6ajkhImM4oAEyZQiLz3Hq/R0cFAgNpa5/jCQuccdqz9+tGstWEDtRLbt8NNL67PF1dgGGNeBPCiiDxijNkeb38viEgpqDVMANAI4AkR+VqsQyINLdKOxpilAJYCLD6Y2kiVuGRDob1sI50RYO6JuK6OUUPh500kgMD993r8ceC22zj5rlzJz91Co6qK/oojR5wQ1KYmagqRhEu4BrNrF001eXl8Dl91z51LIbJxIzWHo0c5/lnBundnnknTVmsr8Pe/O34EGzV14gRNPz4f9/f5nMm7qMjROGy46dVX0yz14IMUFg0N3K+oiLWi3n6bmonVJgYOpJB209LCbWPGMJJKhOO2+HwURhl2PvcUifgwCkRkKeiQ/ug4Y8wFSVz30wC2GmP2A4CIPAWavfaKyOigdjEawL7g/nUATnIdPxY0YSk9SU9Xjs1WvLTsTETI2ok4EKDPIPy8Xh2f4eW933iD58nL46r4+edDBUFNDVffRUWOs9prN7fKSoZ47tjBUhvRGhANGMCV/7FjwNlnMzR10yYnLLiyEli7Fnjuua4r97Y2jql/f77Py6NAmTzZyS+xnzU18bv+7Gc8991387O6OuCpp3guK5A6Oznxl5cz8urFF51r9+/PiLJPfIKC6P33Q8c0Zkz8Uuc5TCIC4wkA9wP4LzBSKRV2ADhbRIpAk9SnAKwFcAzAFQDuCD7/Obj/MwD+KCK/BJ3eFQBeT3EMSqpoLkVkYk3gtiieLZl9553e71mqjuvwv9fAgVwlt7Zy+wVha7/Zs1mfaMAATrbnnMNVeryif3Z8ixZx1W6/a/iqu7qaDuuSEgqkgwcZbmtzLKyQHDXKMb0ZwwndTuBtbY7QKS2lVnHKKRxvU5PTFGvIEAqHQIAa0kknURC2tPAxaBA1BZsdDvAeXXklNZmtW3mvCgvpVP/+9zmuX/3KqS0lAixYkL4SK1lIIgKj3Rjz23Rc1Bjzmog8CeBNAO0A3gLNSMUAHheRK0Ghcmlw/w3BSKqNwf2v0QipLEBzKaITbQKvrnZKZm/blrhzNJWImPBifpMmcSLdvRv41re6mpnmz2eOxsqVnGhHjGCm9MSJkcdQVcWV++DBPP9NNznVaGNpPoWFnOxnznR6SgQC1AZWraJGUF7OfV5+2TE75eXRhFRSQt/H6NGhbV0//JBjF6F57PXXqTUtXBjaYXHUKAqT1lanTMiAAdQkRo1iTokxjvYydGhoccK9eymoSkp4nUCg1y6cvERJDQm+fFZE/gXA0wBa7efGmIZkLmyMuRnAzWGbW0FtI9L+twG4LZlrKRlCcynSQ3f5gcL/XkBo7+xIE938+U6BvliaZCDARLmdOxneevLJXWtEhX/PuXOdBkXjx4cKixtuYILg4cOc2IcM4bN1fANOgUMRJx/EPR5bD2rjRpqYysoYdltTQ03JXb78b39zGisZw/1HjuQYx4+nQCosdKK37Hf453+muSwvj4Ls2LFerWl70TDWgQ5m63j+V9dnBsDEdA9KySE0lyIx3CWzy8s5GXWnHyjS3yve9aNpkuH9sa0PobGRK21rArJCINJ1rr4aeOwxnm/NGse5v2+fU0583z4+3OYiS2cnhcCSJRQA1pTl7te9YwcF3rZtTumO7dtDGzXVBCP0x42j033q1NBzTZ7M7eEVgHfupACxGeh79/ZqTdtLlNSE7hiIovQJKivpFHVPtLH8QJnWPrz4odyZ5O5xuX0xn/kMbfutrdxWWuqYgKxWE6lI4C9+wcilzk5Ws500iY52ayKyRCr4Z7e3tND5/LvfOdezQu7NN+mbGDGCjv7ycqcsif2utpTI3XdTC9m0iecdPz40Ci1SBWDr57Fce22vXkAlUhrkCxE2Hwaw3hizL8JnSi6iYbKZJ3yVH80P1B1RaIn4oWpqOJaaGoaOWl9MbS2jlfr14yRvE+WKijjJWkFjQ1Ttdaw2AVB7OHGC4a0dHRRCIo7W4sbvd4oo2uQ5Y6hp2J4ZF1/slP7eto2f9+/PsUX6rh0dFBCtrcBf/0oz1rPP0rcTrV8H4Ph5orWj7WUk4vS+EsBsAHaZMQdMpjtFRG41xjyW5rEp3Y2GyXY/sfxA3RGF5tUPFT6W/ftpr29s5Ar+yBGu9K3t3/pEiouBJ55wzEnuCKg1axyHsY18sklyJ07weuFJcQCju776VY7j2Wed7QcOMJnPHW782c9yn5YWnu/KKx3nuNVy3FrEhg0c69ChdJo/8ggjve68M3pJlvnze72gsCQiMDoBnGqM2QsAIjISwG8BnAVgDQAVGLmOhsn2DNH8QN0VhebFDxU+llGjnIS+9nZGFZWWUosYOZKPefNYQPAPf6AmYhPcrN/gwQedjOqWltBKrzYqKRL9+9PH8L//G7q9o8MpTujeduaZTk8NW54k0sLIll5/8EH6YFpaaF57661eW+ojURIRGOVWWATZB+AUY0xDsB6UkutomGx2ke4otHjmxlifh49l2TLmLgD0DRw7xon/jDOAL33J0SJ+9jN+lp8fer7qaq7gDx+OrEVEw+djDgUQORmwoCB0oVNRwfPv3+8kHUZbGNnxlpUBP/kJjz96lBrQnj3ex9iLSURgvCQiK8EEPgD4IoA1IjIALO+h5DoaJpt9uLO8o5UB90I8c6MXc6RbEznpJCfRze9neOknPxna5S8QoDnH5kEMG0a/x/33swz54cOJfQefj+XVly6lsAnvPeHzOSGvbqzD3DrNYy2MqqqY8V5cTEFnDLWnUaMSG2svJRGBcQ0oJM4BQ2x/D+BPxhgDoHcWTumLaJhs9pEO35I7zNRWn03FXzJ6NJ281sm9aFFXG39trVPJtaWFDu4HH6Qm0tHh9Mj2Smcn8y1sqOvo0aEr/zFjgCuuCB13dTUnfndTKesQD18YVVUxyqmlhb6VvOD0+LGP9draUIniWWAEBcOTwYeiKJki3DSUDt9SRQX9C2vW8P2qVaHagFdzpB2b3981szocvx949106xm3Jc1ue3FaTTQSfj70mqqoofHbt4nbrULflyt1jXbWKZT22bmU4rdshHn4Pa2p4jQEDKCxGjqR56vLLdREVxEum9z+MMeeKyFGEVogVUI4MzNjoFKWvEUmb8DKZx/NPVFYyQuno0cgtXL2YI6uqmM1dWkqTzcKFoc2a3GMAOAGPGeM4x90+h2RKgFuBs2QJ+1zk5zsmsc5O4Pzzu2pNQ4bQ+R6ecBeJ2bMZFXXwoFMRd8QI1S5ceEncOzf4XBJvX0VRUiSSNmFNKO7EOTdeTVZz53ISj9TCFYhujrQmLDuZHjzI0h/btzud9dyJfE1NTne83bspXGxpdNsDO1EkWGhi926npHhzM4VX//4cx09/GnpMrIS7SMyfz7yLp5/m/W9pobBR7eIjEvFhQETOBVBhjHlYRIYBKDHGbM3M0BSll+A1GTIQoKmlIVieLXxSdyfOuYVCPP+EJZmgBiuMbG8Lm4y3e3doMyebyNfSQr+CdRQXFdEfYEuHJ4sx9H3060dhsWcPhU9hIYXFzTdH/j62I6Db/BaLRYtovrLCV7WLEBLJ9L4ZwCwAlQAeBjvx/QF0giuKEgmv5czdWoIIcwfck1wsP0Y8/4SbRIMa7HUnTXKKAPbvz4ioHTtCE/lsLaXOTicc1d1jIlWamuhbsH22Ab7ety+0kCBA89mSJfSXeNEuLBopGJNENIzPA5gJliSHMWa3iKiZSlFi4bWcuW1pWlBAx6uNBrLE8mPE8094JdwHUVvLpLW1a6ktTJ1KE42dfG+/HVi/nk7thQuBv/yFY/f5uvos0oE1S504wdc2yio8xyMQoLDYuJH71dUxIe9nP/N2HY0UjEoiAuOEMcaIiAGAYP6FoijpwO9nzoJtM+r3dzVlxVr5xvNPxMOt4ezYQeFlo5xso6Vbbw3tmXHuuSzY5/OxnpIVdukWFBZ7XwCn4dGgQUwWdGsQtbVOJJbfz/G88UbifSoimRL7eK21RATG4yLyOwCDReQqAN8C8EBmhqUoOUa0iSS8nHk000hHBzBjhlPCYvt2p5+D25EdbZJK1ZTi9oPYekrNzfRJDB3KVfzOnaFhtbaExokTFBRFRTRXJevY9sKAAUz4O3aMY5gxA1i8uKs2VlZGzaKtzRFit98eOWExWmfE8EACoM/XWkskD+NuEbkQwBHQj/FTY8zfMjYyRckVYkUphZczjzbBVFTQx+H3OyYWt8+iujr+OWJFObmPjTRJWpNXIEDHsq3LZAwn3uHDmd1tv+e2bU75cWsqam7OrLDIy2M3P4BajxVo4V0AKyuB3/yGZqg33qCw+MQnuvp+Yv3dopVj7+O11hJxen8LwEvGmH+Nu7Oi9CXiJdbFs4nbCdyd1wDQxLRjB6OmVq9mCGmiK9vwSXHhwuiaiw3dXbWK/SUKCpi8duQIMGeOk6g3bhxX+c3NnLgPHqTQ6NfPKTWeDie3GxH6UZqbeY39+/ncv79TeTb8nsyaBZx1Fr9vJN9PvECCSD6jPl5rLaHigwC+JiLjwS58L4EC5O0MjEtRuod02KRTKdoYa5VrTUx1dWxGFG9lG+m7hE+KNjQ30rms4Jg7l6vzhx6itlNaymzniRNDe4JfeSWd4jt20DQ1aBD7WZw44fS+SIfgKCpir4r6epqi3D6SNWuACy6I3UckPMHQEi+QIJKJr49HUCVikvopAIhIfwBXga1afwXAn5GRKUqmSVf/j1T8B7FWue7Cg1bbiNYiFYj8XcInxdmzo6+43d9n0SK+3rePPSVsvwf7Pd96i47ukSMpFA4coJ+mrY2aSXFx11LjyTJiBM1RHR30R7g5fhw47bSu9aN27XIixjo6IveyiPd3i6QZ9vEIqkRMUv8G5lwUA3gLwI9ALUNRchMvNZq8aiDJVpX1op1EmtjChd3s2dFLdocfa7vSRfNphJ974sTQsXz4IfDrXzNKacsW+jaKi2kisiGvLS3e/gZe2LOHeR87d1JwuFu3trdTWFkCAZrvtm3jY+pUfo9of5M+LgASJRGT1BcAtAP4XwAvAnjVGJPG/wpF6WbiTdbRNJBEImvi+S6qq5klPWqUk2wX6fzhE1u4sANim1ei+VQi1YeqqaG2MG0a8yzuvZev7fhskb62Nj42b3Yc321tTjHAdNGvH01ypaXUHOz99fkoQNzXqq3lfvPm8T7OmBHZZ6MkRSImqdODiXrnArgQwAMistfWmlKUnCOeSSJ8Uq6u5sM6oA8dCm05mkhVWZtctn4930+dyvN4FTrhwm7uXD7c36WqKnav6UCAeRQ7d7LUR//+3DZwIMe1Zw/PL8Lv/OSTzL1oaKC5yfoSwkt+pFNYADQ77dhB05e9lggfAweGmpvc9aPGjKEgdmek98HIpnSSiElqKoBPAjgfLBGyE2qSUnKdWCYJ96RsI5WOHqWp46yzOKkePerUdkrE+W0zu0uCxRKamhIL3Ywm7Nyaw7XXchW+bBn9DeFCo7aWYaq7dlFoAE6r1X79nKZHAE1M777LHI38/NTqQiWKzei2DZNs+ZRRo+inCDeZue8LENn/oyRFIiapO0FT1L0A3jDGZCidU1FSJF3ZuO7Jx0YqlZVRYGzYwH28NOaJhM272Bqs3Tl+fOKhm7GEnTUblZVx4q+p6Sow/H5qSSKOs7qxkcJg4EAe29FBH8Hhw/RPDBtGDaKggJ91h+Cwfb+PHeN7n4+C7rzzuD1eGHMyBRf7cCRULBIxSX0m1uci8idjzBe9nk9EBgP4LwBTwT4b3wIQAPDfYAjvNgBfNsYcCu5/I4ArAXQAuM4Ys9rrtZQ+RLoinyzhkUrNzTQfnXQSk8Lq651e0e79vZx38WI6Y4cPZ1RSOkM3Z8+mZrFrF1fntmqrJRCgbb+0lKGwtv9DezuFSGsrty1ezJyMN9+klmVNV1ao2Dar4e1S04k7r8NqF8ZwjPn58bWGRBzb6f7/6WX44u/imYnxdwnhHgCrjDGTAJwG4H0ASwA8Z4ypAPBc8D1EZDKAhQCmAJgH4DciouG8SlfcfgSb0OXGRjEFAomd12obX/gCcPXVtOGXlTmF9xKdVAIB9qb+4APgnXe6Xuvii1ObqObPpxlq0SI+T5wY+r3tfZo2zckw7+x0/A/NzdQsfvc7htAePEgzVVERJ+zKSh5ru9NZp3cmyM93rmGFxeTJwIUXpn9Cj/f/08dJqB9GHDx7ukRkIIDzAHwDAIwxJwCcEJEFAOYEd3sUwAsAbgCwAMAKY0wrgK0ishnAmQBq0jR2pbcQy4+Q6urR7rtsmRNFZK+TKNXV9IGUlNAsFa2KbSrMn89HIABccw0FwLBhDIl136fSUt6T8FDYlhZqUHv2OEX/Cgoc57g1ZeWlcxqJgA2jzcujULPXralJf7+KVJIw+wAZ/ktHZSKA/QAeFpHTwMzx6wGMNMbUA4Axpl5ERgT3LwPwquv4uuC2LojIYgCLAWDcuHGZGb2SvcSKfEq1N7YVOE1NrCwLhJqjspXly4HXXuNKfcsWp9S32z/j89HsFC40rCkoP5/3Li+P+9gSID4ftZFMYjWL/v157aIi4PTTky/jHotUkjD7AOkUGInopHkATgfwXWPMayJyD4LmpwTOHVGjMcYsBbAUAGbNmpXm+D4lJ4hms0519eg24wDAlCnAZZclN6nMncuaTU1NdHgns1L26pzdvz+01tP+/dzu9s/89rfcFi2HwuejNlRQ4DifAYa8Zpq8PI6zqIjXHjYs+TLuXtBkvqikU2DckMC+dQDqjDGvBd8/CQqMvSIyOqhdjAawz7X/Sa7jxwLYneqAlT5GtNWj14nXLXCKi5MXFnYsd96Z/ErWayc/gP6QZ57h2AcN6lomY80aah6xsrPz8+kHGT+eEWI2uipTAsPno3AuLWV48Je/3LW5U3dqABo5BSBFgSEiVcaY+QBgjPmr1+OMMXtEZKeIVBpjAgA+BWBj8HEFgDuCz38OHvIMgD+KyC8BjAFQAeD1VMau9BHCf+jhq8dE/BrpNlekspL12skP4ER/5ZVOA6GJE0P7Wtx2W6jWEIn2djroBwzg++nTKXyeeCK58cfC73dMfYsXO02bwkNn45GuSV4jpz4irsAQkdOjfQRgRgrX/i6AZSLSD8CHAL4JRm09LiJXAtgB4FIAMMZsEJHHQYHSDuAaY0wG4/iUXoGXH3qifo1cM1eE+11OnGBUljHsz71xY2gtpmi0t/MerltH4bJ7t5OLkQmOH2dI8B13sF1tpEz1WFRVMYt98GAKn1Qm+VR9X70ILxrGG2DCXiQ/wuBkLxwsiz4rwkefirL/bQBuS/Z6Sh/Eyw89V6NivHbys/fAtk8tKKAPwxjWWXrhBU7O8eo/dXYylLijw+nGd/Ro5PLlXmtJ2VDc8H07OznW4mJGSEVKOoxFIMD6WDt3UhiefHJqk3yu/o9kAC8C430AVxtjugQki8jO9A9JUdJEspVgc4HKSu+d/Do6OPF2dvK5uJiT9CuvcBVvjBPxJNJVa7BhrBbbJ9s60SPtX1REbSZaMULrhLcCp7ycWovd12oYPh+TJBPBFiA8eJCCrbExtUk+V/9HMoAXgfEzRE/w+276hqIoacbrDz3XzEwWL+N23wNrmrOT589+xtIatq1qZydDV6M5sgsKKACMYZb38OH0n7gFRmEh93H7RCJpG/36Aaeeygl9yBAWCjx6lNutM334cG4fPdo5zotfwpZdOflkOud/9KOe9Tf1IuIKDGPMkzE+1mxrJbtJ9YfeG6JjIjn6a2vZmCi8yVEkYWHboALUUNxJfpMmcZLfvZsreVtSJB6trczW/ulP+b62liXJly9nGO2WLRyzO8/Fq/NZNYKMkWpY7f8D8Kd0DERRsg63w/jQIeBf/zW2LT2ecMkG4eP+TmvW0OQTr42qNe9Ys1RRkZPdPWQIzUmnnkoH8733dj3eTvDh/P3vPLct7W7NZwDDd8PbqibifFaNICOkKjAyWEBGUXoYW4J882aaTu6+myGp0YRBrNVvT4ZmugWVnXRbW6lNhAsMEQoDKxxs97z+/amR1NXxWGM42Z93HsuMjx/PWlUFBaEd8QBez/pJ3OaphgbgwQdpenrySYYIl5Y6/T3SFaCQDYK6l5CqwNBMaqX3UlFBzaK5mavqwYOjr2rjrX4zHZoZbVKM1FGvo4OTtTH0OTQ1UUj4/Zz4Dx8G9u7l8cbw+xvDfYYMYYZ7czNrTL3yCnMzjAG2bw91jtvs8GHDeL3Dh0MFRmcnz5mXx2gmEfbnjnZ/kjE1aQ5FWvGSh7EekQWDABiZ9hEpSrZQWUkzlDueP9qqNt7qN5OhmdEmxaoqdvVrbOT4Tz6Zk/rs2Yxu2rCBE7zP5/gpTjmFfT/ckU0nnURfR0EBtYnWVhZObG+nIJg4ERg6lNV7N23i9vZ2CoKSEuCKK1j19tgxp1R5Zyezx1ta+Jg4kfc33v1J1NSkORRpxYuGcXH8XRSllzJ/PiczL5FWsVa/mXTERpoUAeDWW1lt1pqIdu1i7obPBzz/PLUEW9L8xAlu/8c/uG9hodPp7tgxOrYvvpgCYdMmx7zU2srzjB/P58JC55zDhgHf/CZNeuPH0w9SUkIhNWECI6B27QI+8Qmee/t2XjuSOSpZNIcirXiJktru5UQiUmOMmR1/T0XJMRJpihQvSxxwJvRMTorV1ZyM7Wrf56Pga23l49ix0G55ra2OyenECa7+rYYxfDhNRvX13HbsGPcxhprI174GzJpF01d5OU1VF1zghOH6/cDMmRQoo0cDn/88BVNTE01lM2awmZPVkNJZslwjptJKOosPFqbxXIrS+8iUPT18UgTYf1sEGDnS8UccOMBw1YEDIyfb+XzcPn06cO65zAjfs4fVedevp+9izBiaod5/nwKjqIjH1NRw8p88mVV49+3jvrNn0xy1Zg2vU15OR/nYsTT1lZZSWAwe7PQXyUTJchUUaaFHGigpSp/ERl3ZSKJ0TozuUuU2bLazkyYi201vxw6ahMrK6L8Ij44qL2cXOxvmCvBc7uq8APDIIzRR+f30faxaxXPaHiFTpzKnwpqWtm+nVlJZSS2jupp5G1ZIrF/P4AI1G2U9PdVASVF6D17DNv1+Tqo2lNWfgbxXOxlXVgJnnsmJffhwTsbbtlErqK/vetywYWxKtGsXJ/WaGmotkcw5N98M3HKL478YODB2j5C5c51+6IcOUcDYewFQGH37213zLpSso6caKClK7hMIcIJevdrJH4hkZrL7rVnDybWsLDOVXgMBTsZbt/IxbRpw+eU0+Wze7GRp79sXelxREQXL9u38bN48p5tdpN7iNnnxrrsojLZsoebi7hESLkTd3f1ef50OeiC1JlRKt+NJYIiIH8BqY8ynY+z29fQMSVFyAJvf0NLSdZINT9hbsoRlwQ8e5Aq/oYFO4HSbXmpr6bSeN4+RTBdd5ER5XXYZtYy8PEdQ2bpNNmLplFMocAIBvg8fn1sIdHTQhDVuHIWFe+KP5quxn9XUpKcJldLteBIYxpgOEWkWkUHGmMNR9nkvvUNTlCwlEKDDdudORhodO8Z+2BUVfIRnVtvEuIICruZLSzmpp3uitBN5czO1GOuHqKwErr4a+N73+LnP55jFfD42Qtq0ieMcPpyCI1yzCBcCNgEw0sQfK/dBo5ZymkRMUi0A1ovI3wB8VIrSGHNd2kelKNlMbS0dtnV11BoKCjhJT5hAs9Py5aGZ1cXFFCwnTnAiHTYsvaGjlkjRUitX8rXtWvf88xRwNTVOiOzhwwx/teXAx4yhGctdBiVcCNgEQKBr3kS83IdIUUtaviMnSERg/G/woSh9h0gTmS2fPXQoM6BnzWIY64oVnHRtGZGTT+aEeccdFCJPP80yGsXFmRtfeLSU2yx01VV83H8/O+21tNAJbRPmKivp9C4o4HFuzcAtBBoaQv024cIvUS1Cy3fkDJ4FhjHm0UwORFGyBne/6xUraKppbGRfhfnznQnROrz37uUkOngwezq0tFCjGDrUWV13dlKApDPXwD3RNjSEhrLGMgvNncte3G++6ZjJfD5qGkePMl9j9OhQzSCa4zpW3Sev30/Ld+QMXmpJPW6M+XK0mlLGmOkZGZmi9ATuSXjbNkYW2a50d93lmGncE9qaNdyno8PJgG5ooHCwQsXnCw0jTYfD2060RUUcgzU13XRTbLNQZSVw6aWsVtvQwM+Liig8pk93fBTRhIDbcZ2OvAkt35EzeNEwrg8+a02pJHjgAVoiJk4EvvtdXThlPe7Vbl0d8NZbFAIizE62q1+3YGlu5iS3ZQsn3bFjOXlXVzNBbts24KyzmHU9ahRw3XXp+UewE+2mTXxfWckci2XL6IQONwu5zVc2N8L2+jjvPE7YdpUfK+Q3Vcd1JDOaOsJzAi+1pOqDz55qSikODzwAXHONU/F52TLgj39MrJ+90s24V7vt7XRkf/ABtYYtW5xkO7dgAWgO2rOH/R0Ap4bSyJHc9/nn6b/YtSv1MbonXLdprL7e0WJuv52fXRxc51VVhVbdDU/Ks8dEW+VH85UkM/ZoIbcqKLIeLyapo4hR9sMYMzCtI+pF/O53oe0BGhuZ0Pr88/rbyFrcq12/n5Ps0KE0Kbk7woWbUazv4KyzGJm0bh19Aa+9xvIc/fsDZ5xBDSQVG32kCfc73+H1ly3jPuF+kkCA5rSdOzmmk0+OnJQXLcIKAG64gdpIcTFw553Jjz+T5VGUjONFwygBABG5FcAeAI+BWd2XASjJ6OhynPDGYwCDaPQ3kuWEr3ZvuYUCo6jImUCjmVHmz+dEfvw491+3jiarY8coPKZOTc1GH62UeW0tw1y3b++qJdTWOm1Wm5u5cok0BvsdqquZwDdkCM8zYQLw3ntM0Nu2jZ8n+w/cHeVRlIyRSFjtRcaYs1zvfysirwH4v2keU6/hxImu23w+/Y3kFBMnMmKoqYl+jA8/7GqaCcc6zEtLqVmMGcNzBAKpJ+xZzcYW7KuvZ8ST9UUsWuREOIWHAZ98Mvf50Y8ij8FqL7t3s7SIzV7fvz/58YbT0cFy5lbDSHd5FCWj+BLYt0NELhMRv4j4ROQyAPrXjsLPf+4s/iw+HytC6G8kh7Cr83PO4R/wrruAp57ixBoIdN0/EGAobmkpV/KLFnGytglxqSbsVVYygqmx0SkNXl/PWlE7dzp9JWprnfFZbeib3wR++9voTjSrvVhhsmkT/1kvvphmrmHD+JzKd7DCq7AwfdFiSreRiIbxVQD3BB8GwMvBbUkTrFG1FsAuY8zFIjIEwH8DKAewDcCXjTGHgvveCOBKUEhdZ4xZncq1M83f/ua0F7DYDpSqYeQQbl+FnaRj5QvYSdf6EUaPTn8EUEcHO9iNG0dNo7bWMYFZv8v48Yk7ld2lRaZNYy0q65vx0nXQCxoRldMkkri3DcCCaJ+LyI3GmP8vwetfD+B9ANZxvgTAc8aYO0RkSfD9DSIyGcBCAFMAjAHwdxE5xRiTtWv1Cy8EXn7ZeW/rvLW0OIm1Sg4Q7gRfsSJ2vkCknIJ0RwC5zVKNjcypeOEFRkAdOhRfqMX7rtXVfO8u+ZHO76ARUTlLOsubXwrAs8AQkbEAPgPgNgA/CG5eAGBO8PWjAF4AcENw+wpjTCuArSKyGcCZAGrSMfBMMGoUF3w2j6u9nYvAY8foP1RyCPcEF2+l3R0raGuWuusuCofNm+mX6OjwJtTiUVPD89gkQJ3clSA92Q/jVwB+jNBIq5GuvI96ERkR3F4G4FXXfnXBbVlJIADcdhuFRVERQ2tbW+n/bG93WiUrvZTuWEG7y4tb4WBzLlIxH2VbmQ4tSphV9EiLVhG5GMA+Y8w6EZnj5RCv1xORxQAWA8A4m1TVzSxfzvJC7e20GAwYQGtBfj5/ixdrznz2E2mi8lokrzsmuXilPwAn6iKRMWRTmQ4tSph19JSGcQ6AS0TknwEUAhgoIn8AsFdERge1i9EAbGuwOgAnuY4fC2B3pBMbY5YCWAoAs2bN6pG1/Acf8HnAAPos5sxhxndNDUPlNdM7y4k2UXlZfXfXJBfL9JXsGKygs70uenpVn23ajpJQWG08nvC6ozHmRmPMWGNMOejMft4Y8zUAzwC4IrjbFQD+HHz9DICFIlIgIhMAVAB4PW0jTyMPPAC8+CJ/b62tTBK+5hoKiVtvVWGRE9hs5JYWPtuVupfVt3uSs+GtmaKyMnIL1WTGYIXMU0/RB9LTwgLILm1HAeCtNMh/InZpkOuCz7enYTx3AHhcRK4EsAN0pMMYs0FEHgewEUA7gGuyMUKqqgr48Y9ZJVqEuUlf/CKFRFUVNYzDh9nR84ILnJ42SpYRLRvZi0M7Gya5ZMaQjat5DcHNOryYpNZmcgDGmBfAaCgYYw4C+FSU/W4DI6qylpUruSA1ho+2NuY6VVUB117rtBooKOC+gAqNrCQ8G3n7djYdAhhqGssJlQ2TXDJjyAZBF4lsC8Ht4054L7WktHGSR0S4ILUUFDC8tqaGi1WAgqRfPz4//7wKjKzEZiP7/YyFfuIJJ3lm9Wp20Is1WWTDJBdpDLEmu2wQdNmOOuE9maSeifW5MeaS9A0nt5k6FRg0iGYnnw/42Me4IP3wQ6eQqAjDbfPyaJZSspDw7nJPPsnCe4Dj04g2UWTrCtTLZJcNgi6byUazXTfjxSQ1G8BOAMsBvIbE8y36DOPHMzIqL48axLXXOr/B++5zfBibN7MA6Hnn9fSIlai4u8utWsViggBzH6KZa7J5BaqTXepkq9muG/EiMEYBuBDAIrB21P8CWG6M2ZDJgeUir71GgfGxjzE6avRo57OJE/n5/v00izc3Oz1u9HebxVRWsv9DpHIZ4WTzpBxeTkQLmiWOmu08+TA6AKwCsEpECkDB8YKI3GqM+c9MDzBXqKqiFnH0KM3d55zjLEACAScPw92ILdVeOko34dVUk80r0PByIitWOP3JFe/0cbOdpzyMYP7DFwD8AcA1AO4F8FQmB5ZrPPYY6761tTF8v7AwNOH2ww+dhkonTrCvTrbNKUqK2BXomWcyQzPbsOVEpk2LnZ8RCDCML1L5dqVP48Xp/SiAqQCqANxijNHSeRGorQ2NkGpqcl77/bQCdHTQt5GXB5x+upqjei3ZWrzPiwaUapZ4HzXV9BW8+DC+DuAYgFMAXCfykc9bABjt6c3firspmc/HXjmWjg5g1izgnXeofZSXAzffrL+rXkk2+zG82OCTGX82O/uVtOLFh5HO8iG9ktpa4JRT2DLZVqj9+tedzysq6AAvKaGmEa1DptIL6Gk/RryVfjwbfG/JElcyQjqLD/ZZrECYPZtVaq+9NrRmlAZX9CF68o+djpV+b8oSV9KOCow0YANQYlWj7ePBFX2Lnvpjp2uln+j4kxEyifg81D+SNajASAOBAKMUbbOzXhmt6P7RAvoDzkZSWemnOiknImQS0YTUP5JVqMBIA73ehOv+0R46xFCvIUP0B5xtJGsO6+5JOZEfTK//ceUW6tBOA34/K0esX99LTbjuH21TEx/d0e9BSZxoPTJi0Z09PAD+QBoagH/8g8+xfjDqH8kqVMNIkUAAWLqU4bK7dmVJuGy6bb4VFUxff/llvh87Vn/AvYmemJRFnEcsNGIkq1CBkSLLlwOvvsqe3W1tThXsjBFPGHgxLyQqUD78EHj3XeDIESaZDBnCbOZYdZWU3KG7J+XaWpYnOe00b2YmjRjJGlRgpEAgQIFx8CBrSA0Z0g0XjCcM4tl8E7FXV1WxRMRf/8ovKUKBcegQtQz9EfceunNSVjNTzqICIwWWL6dG0d7O//v+/bnozhheHIDxfoyxzmE1D7+fpXXvv5/12Fta+LkxrH9y4oT+yJXkUTNTzqICIwXWrmVBQdtpb/RooBIBYGUafgiRzEZeVmbxfozRzmE1j6Ym9rPOz6cm0d7e9RrjxumPXEkNNTPlJCow0oAxfK5EmsITI5mNAAqBhQudiT7auWP9GKMJFKtZFBTQ7DRwIIWFu6Kioih9GhUYKTBokPPa5wNmFKcpZjzcbFRdzTahBw4Aw4YBv/51aquzSALFah6trRQSeXm0sTU3OxLRUlyc/LUVBaB/LFZpBCUrUYGRJIEAsGUL59SODgqPwbMqgK1pcOaFm43ee48/Lp+PwmT5cuBnP+s6oFQzda3mYX0Y77zTVViIsNyuoiRLVRULrvl8bHZ/330qNHIEFRhJUlsLlJXRzH/0KJWB0xdVAkiDMy/cbPTDH9LxnJdHAfLBB6H7pytT1615dHSwvG5zc+g+hYXA1KnJfS9FAZzFT1kZk5dqalRg5Aia6Z0kFRW0zEydCpx6qithL5lMW6BrlzN7HgDYuZMr+/Z2CoUjRxjBZPdNR6au+/qBAD36R4923a+0NMOhYEpWks4ufLNn0+y5axefs7E7oRIR1TCSJK2RgbE0hNpaSqa8PCd+9+WXgTffBB55hJLK1iY5fJj7JmoKc1+/oYHCae9ep6esm5kzNbqlr5HuWlPz59MM1RM+DK18mxI9omGIyEkiUi0i74vIBhG5Prh9iIj8TURqg8+lrmNuFJHNIhIQkYt6YtxuqqpofvX70/B/F16radkyZyVXXw9s3OgkzYnQTHTgADOwb7mFtUlKS9mdaeHCxAcUqVbU0aOcHMIZPDjFL6vkHJmoNTV/PnDrrd0vLG6/HXjqKT5rz/KE6SmTVDuAHxpjTgVwNoBrRGQygCUAnjPGVAB4Lvgewc8WApgCYB6A34iIv0dGDuCBB4DLL6dV6OqrKTxSwjq5169nDsSGDfyHrqqig7uoiD/U/HxqGe3trENy4gS1gKYmYNo0YPz4yJN8NKyZwa4cd+yghlJcDOzb13V/kdDQMKVv0Fsys7u7yGIvpEdMUsaYegD1wddHReR9AGUAFgCYE9ztUQAvALghuH2FMaYVwFYR2QzgTAA13TtyzrF3301nt89HS9HKlSkulKx9a9kyvp82jT/OmhpqDsOGMVrp8GHmSRhDgdHeDtTV0Q68fn1i5qhAALjhBgqb4mLgM5+hr+TSS9nQ4+tf7yo08vKAGTNS+KJKTtJbMrN7i+DrQXrchyEi5QBmAngNwMigMIExpl5ERgR3KwPwquuwuuC2bqe21sns7ujgI17BTTdRTaiVlcBll1GzsP/Qs2ez6N+AAYySmjCBNZ3q6yk0ioudgoCHDgHf/rb3H3N1NcN1S0oYdbVnDzB5MjtA3XQTMGJE6P75+cDHP850dqXv0Rsys3uL4OtBelRgiEgxgD8B+J4x5ohEn3kjfWAibIOILAawGADGjRuXjmGG4PfTvG/TE/x+KgBeiOs7DP+HBqgBNDezsmH//nxubeWjsJCfDRpEoZFsqdy2Nmov69dTa1m+nKYxNwMHAiefrKsyJbfpDYKvB+kxgSEi+aCwWGaMeSq4ea+IjA5qF6MBWJtIHYCTXIePBbA70nmNMUsBLAWAWbNmRRQqyWJ7XzQ18b3Px8nfK9aEOrMogI5NtdhdXYHKykqeuLqaO82d64TT3n8/o59KShiCWFoKDB9Ok5F1fjc3A1u3UgNYvdp7yfG5c7l/UxOlXyDg1I1qbKTG4ebYMeDcc/XHpih9mB4RGEJV4kEA7xtjfun66BkAVwC4I/j8Z9f2P4rILwGMAVAB4PXuGzGpreX8bc1Qfj+tQqNGeTu+ogIY3hDAzDW3owN+nLa6Axi/EPjd72geOnwY6NcP+NKXgAsv5KTd1saIqCNHgKFDOWnv2MF+FGPHMl/i5Zc5kTc3J1aO5KJgsNn69RRItnbUvn1dneclJfRxKIrSZ+kpDeMcAF8HsF5E3g5uuwkUFI+LyJUAdgC4FACMMRtE5HEAG8EIq2uMMQmEA6WHt95iAFNbm7Pt5JO957FVVgLXzquFOeZHUeU4DG4OOrabmmhiOniQO953H/DSS5y0jxxx6jnt3Ok4t60m4fdz3/r66E7vcMdJuG3s3HOBZ56hwOrocMqZu2lr0wQrRenj9FSU1D8Q2S8BAJ+KcsxtAG7L2KDiEAgwiMkYzrM+H/3CV1yRmJXmpLkVQE0H0Bzm2G5o4Mnz87n9ww8ZTmuzu/PzqdaMHAlcf70z8S9dChw/TqHy059G7q4X7jgJL244ejTP89hjwLp1vHZ4ldrTTtPyDYrSx+nxKKlcobqaC3CA867fD0yalESVjGiRGmvXctJvb6dgKCigo/n4cUdo9O8PTJ/uHFNdTY2jpISe+EhO70gNk6KFF5aW8trFxfRjWPLyeI5AQH0YitKHUYGRAAMGcM4+cAA47zzgF79Icv4Mj9TYvp0RT2PHUtM480zHo15QQHNV//58PX68c9yePXRG5+eHnt9tgookHCormRFuSzMAwJIl1C727+9qkho8mI9ky7UritIrUIHhEb+fj5ISLvLvvDMNc6eNjlqzhj6CYcMoFL7yFV7svvtogurspJ+jrIx5EhMn8vh33qGwaGxkDsXcuZFNUOEaTSDA8/j9fJ49m+cfMMDxo7g5coROcQ2pVZQ+jQoMD1RVsexNSwsVgH/5lwSERbRMvUCAJ9q40dnWvz81iPHjmU7e3MwigAMGUOMoKODEXlvLDO+mJuCTn2RU0xe/yPPbUh9uE1R49dxwMxVA/0ldHU1g4RQWAvPmqXahKH0cFRgeePZZmqF8Pi7233rL44GxMvWqqyksbEXY8eOBT3+a2d61tTQBHThAodHSwpX/rl30J9TXA6tWMf9i61aWErHOFC/lD8L3mTuX5q26Om5zCw0RYNYsYNGiZG+foii9BBUYHjh8mHO2iFPSyRORHM7uVXp+PgVGeztX8Zdd5nxeXMyY3V27OIFbLeNjH2N47ZAhXPVv2sR8Cnucl/IHkTLK33mHwskdMwzQEf6jH6l2oSiKCgwvDBrk1PxLqGBrrNW+zbTeu5dqizsk1j2h19WxHPORI9zP1o5qaOC+ZWVdQ7W8lD9w77NyJQXD9Ok0c9lr9esHnHFGYhVwFUXptajA8MDMmVQUOjs5V8+c6fHAWKv9ykrgjjui+zfsdr+fzcM7OxkRJUIBJMJoKq+lQGLh9zNSy++n4Cgvp6lr8mTmaKizW1EUqMDwREcHcMopdB+UliZYsDXWaj/8Mxs1tXo1L2QT+2bMoIqzbRtNU7ao4tixqQsLGzE1eDAr3i5Zwi9o/S5a1VNRlCAqMOIQCNC/bNtbjx2boQW3dZDv2kXBMG8endvr13PiLixkarnVMNJVz9/6WWwPjtGjneKHiqIoLlRgxKG6mpags86iu8HtX04rduIeOZIO6P/5H164vJxFB+fNc3wV6aznr01lFEXxiAqMGAQCwKOP8rmwkEIj4VIg0U4cPulXVNCR/dZbdDw3NnIC/+AD1pSqrHT8FemUWNpURlEUj6jAiMHy5aw6boOSysrSlN0dKTejspJaxLZtdHAfOMBw29ZWxvS+8goFSZeuS2kYjwoLRVE84OvpAWQz+/bRZdC/PyNMwwu4JkV1Nf0URUVdG9HPncs2rDbhQ4SPvDxKq3Q3rrfC66mn+BwIpO/ciqL0OlRgxOCzn3W6nw4axPcpEQgwAmrbNnrSGxpCfQY21Pamm1jqY9AgFq/KywNOnHB8DIEAcydSneDdiYXpFkaKovQ61CQVg7o6p5ve4sVpaAdRW0tHdmkpzU2R6jNZ89TYsTRFFRTQPHX22cwEB+I0Bk8AdXgripIAKjCi8MADwDXXsFKGzwc89BBLmiczN1dVsZL4ZdveQuVLL/GE8RqCV1SwPIjfz1BXWzYkUnHBZAWGOrwVRUkAFRhRWLrUKavU2clgpWTm5qoq4OqrgfEtAXzl0JNoE0G+D3SMxOqRHW0yT7dWkO6oK0VRei0qMKIQXmDwxInk5uaVKxkhe56vFoc7iwHTBnR00iR10kmxD440matWoChKD6ECIwqjR4f6gCdPTm5uHj6cGsrGjgr4OjvQmZcP+DvZfjXZon6qFSiK0gNolFQUBg50Xvt8wMc/ntx5yspYxXyzvxLrCz8OKSjgRvcFIlFVxQq2VVXJXVhRFCXNqMCIQFUV8PzzzvuBA4GpUxM/TyAAPPggo2Jn9A/g9P7vo9Ofz/Lh5eXR08arqoBrr2Xm4LXXqtBQFCUrUIERgTvuYC8hi9+fXEmQ6mrWD2xvB2YcrsbwY9sgQ4dSgkyaRJtXpFyKmhqqNWVlfK6pSf7LKIqipAkVGBHYvTv0/YABybsM8vOZy1HQj+cpGFTItPG1a6NnWM+eTcfHrl18nj07uYsriqKkEXV6R2DsWGDzZuf9uecmdx7bVK+pCWgum4t8rALQxGS8srLouRTz5wP33UfNYvbsNGQMKoqipI4KjDBskp1l4kT6npMhtKleJQbiTqccx4oV7HXR2Bg5gW/+fBUUiqJkFTklMERkHoB7APgB/Jcx5o50X+P664HxrQGcjFpsRgUONFamFMEaGgEbFg57110sE7JiBSWThsoqipLF5IwPQ0T8AH4NYD6AyQAWicjktF+nNoCNmIRn8VlsxCQMawjgsssyUMi1o4ORUtOmaeE/RVFyglzSMM4EsNkY8yEAiMgKAAsAbEznRd7DpI+kqATfFz9p0NxM81LalAAt/KcoSo6RSwKjDIC7+FIdgLPCdxKRxQAWA8C4ceMSvki4yuUDI1ubmlKr89cFLfGhKEqOkUsCQyJsM102GLMUwFIAmDVrVpfP49ERvJAET94BFo0tLs6AEqAlPhRFySFySWDUAXBX6xsLYHeUfZOmnzE4IQI/KCy++VWDn3/SaaetKIrSV8klgfEGgAoRmQBgF4CFAL6aiQv1M1RM/ACWZeICiqIoOUjOCAxjTLuIXAtgNTiXP2SM2dDDw1IURekz5IzAAABjzF8A/KWnx6EoitIXyZk8DEVRFKVnUYGhKIqieEIFhqIoiuIJFRiKoiiKJ8SYhHPbcgYR2Q9ge5KHDwNwII3DyXX0foSi96Mrek9CydX7Md4YMzzSB71aYKSCiKw1xszq6XFkC3o/QtH70RW9J6H0xvuhJilFURTFEyowFEVRFE+owIjO0p4eQJah9yMUvR9d0XsSSq+7H+rDUBRFUTyhGoaiKIriCRUYYYjIPBEJiMhmEVnS0+PJFCJykohUi8j7IrJBRK4Pbh8iIn8Tkdrgc6nrmBuD9yUgIhe5tp8hIuuDn90rIpF6l+QEIuIXkbdEZGXwfV+/H4NF5EkR2RT8X5ndl++JiHw/+Ht5T0SWi0hhn7ofxhh9BB9gFdwtACYC6AfgHQCTe3pcGfquowGcHnxdAuADsFf6/wWwJLh9CYA7g68nB+9HAYAJwfvkD372OoDZYN+pKgDze/r7pXBffgDgjwBWBt/39fvxKIBvB1/3AzC4r94TsOvnVgD9g+8fB/CNvnQ/VMMI5aO+4caYEwBs3/BehzGm3hjzZvD1UQDvgz+IBeAkgeDz54KvFwBYYYxpNcZsBbAZwJkiMhrAQGNMjeEv4feuY3IKERkL4DMA/su1uS/fj4EAzgPwIAAYY04YYxrRh+8JWOG7v4jkASgCm7j1mfuhAiOUSH3Dy3poLN2GiJQDmAngNQAjjTH1AIUKgBHB3aLdm7Lg6/DtucivAPwYQKdrW1++HxMB7AfwcNBM918iMgB99J4YY3YBuBvADgD1AA4bY/6KPnQ/VGCE4qlveG9CRIoB/AnA94wxR2LtGmGbibE9pxCRiwHsM8as83pIhG295n4EyQNwOoDfGmNmAjgGmlyi0avvSdA3sQA0L40BMEBEvhbrkAjbcvp+qMAIpVv6hmcLIpIPCotlxpingpv3BlVmBJ/3BbdHuzd1wdfh23ONcwBcIiLbQFPkBSLyB/Td+wHwu9QZY14Lvn8SFCB99Z58GsBWY8x+Y0wbgKcAfAJ96H6owAjlo77hItIP7Bv+TA+PKSMEozIeBPC+MeaXro+eAXBF8PUVAP7s2r5QRAqCfdUrALweVMGPisjZwXNe7jomZzDG3GiMGWuMKQf/7s8bY76GPno/AMAYswfAThGpDG76FICN6Lv3ZAeAs0WkKPg9PgX6/vrO/ehpr3u2PQD8MxgxtAXAT3p6PBn8nueCavC7AN4OPv4ZwFAAzwGoDT4PcR3zk+B9CcAV1QFgFoD3gp/dh2BCaK4+AMyBEyXVp+8HgBkA1gb/T/4HQGlfvicAbgGwKfhdHgMjoPrM/dBMb0VRFMUTapJSFEVRPKECQ1EURfGECgxFURTFEyowFEVRFE+owFAURVE8oQJDURRF8YQKDCVnEREjIo+53ueJyH5XafJviMh9CZyvKfg8RkSeTOC4chF5L8L2qGWvw/Z7SET2RTpHuhCRSyROuX4RmWPvXYTPviciRZkZnZIrqMBQcpljAKaKSP/g+wsB7Er1pMaY3caYL4VvD1YoTYQlAJ4zxlSACV3RJuxHAMxL8NwJYYx5xhhzRwqn+B5YnVXpw6jAUHKdKrAkOQAsArDc64HBEjA1IvKGiPzctf0jjSGopTwhIs8C+GuCY4tW9joEY8waAA0exjtCRNYFX58W1LDGBd9vCZasGC4ifwp+pzdE5BzX97gv+PpjIvJq8PNbrWYVpFichknLhFwHFturFpHqBO+B0otQgaHkOivAej2FAKaDJdq9cg9YifXjAPbE2G82gCuMMRckOLZoZa+TwhizD0BhsE/FJ8GSHZ8UkfFgpd1m8Dv9v+B3+iJCe3tY7gFwT3Cf8KJ3M0FtYjJY3vwcY8y9wf3mGmPmpvIdlNxGBYaS0xhj3gVQDmoXf0nw8HPgaCSPxdjvb8aYuBpAN/EKOO7zANwefP4kgJeCn38awH0i8jZY/G6giJSEnWM2gCeCr/8Y9tnrxpg6Y0wnWF+sPM3jV3KYRG2yipKNPAM2tpkDFoJLBC/F1I4lOqAge0VktDGmPqzsdSq8BAqI8WCF0xvA72Cd1T4As40xx90HifeW0a2u1x3QOUJxoRqG0ht4CMCtxpj1CR73MljKHAAuS++QAEQve50KawB8DUBtUAtoAKsMvxz8/K8ArrU7i8iMCOd4FTRXAc73j8dRsPe70odRgaHkPEETyj1JHHo9gGtE5A0Ag1IcRqWI1LkelwK4A8CFIlILRnDdAXwUtvuR+UxElgOocZ3jymgXMcZsC75cE3z+B4BGY8yh4PvrAMwSkXdFZCOA70Q4zfcA/EBEXgcwGsBhD99vKYAqdXr3bbS8uaL0MYL5FMeNMUZEFgJYZIxZ0NPjUrIftU8qSt/jDNAxLgAaAXyrZ4ej5AqqYSi9HhH5CYBLwzY/YYy5LcHzTEPXaKpWY8xZqYwvyrV+DUZDubnHGPNwuq+lKF5RgaEoiqJ4Qp3eiqIoiidUYCiKoiieUIGhKIqieEIFhqIoiuIJFRiKoiiKJ/5/V2sB0BahRM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n = 2000\n",
    "atk = df_attack.sample(n=plot_n, random_state=76)\n",
    "nrm = x_train.sample(n=plot_n, random_state=42)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
    "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
    "\n",
    "plt.xlabel('MI_dir_L0.1_weight')\n",
    "plt.ylabel('MI_dir_L1_weight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'MI_dir_L0.1_weight', 'score': 1.1394566521439042},\n",
       " {'feature': 'H_L0.1_weight', 'score': 1.1394555357208591},\n",
       " {'feature': 'MI_dir_L1_weight', 'score': 1.0159791903790414},\n",
       " {'feature': 'H_L1_weight', 'score': 1.0159786430763942},\n",
       " {'feature': 'MI_dir_L3_weight', 'score': 0.8699374428709418}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['benign','malicious']\n",
    "scored = []\n",
    "indices = {}\n",
    "shps = {}\n",
    "\n",
    "#classifying benign as true and attack as false\n",
    "for cl in classes:\n",
    "    indices[cl] = df_ben['class'] == cl    \n",
    "    shps[cl] =  df_ben[indices[cl]].shape[0]\n",
    "        \n",
    "for col in df_ben.columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "    num = 0\n",
    "    den = 0\n",
    "    m = df_ben[col].mean()\n",
    "    \n",
    "    for cl in classes:\n",
    "        num += (shps[cl] / df_ben.shape[0]) * (m - df_ben[indices[cl]][col].mean())**2\n",
    "        den += (shps[cl] / df_ben.shape[0]) * df_ben[indices[cl]][col].var()\n",
    "    score = {'feature': col, 'score': num / den}\n",
    "    scored.append(score)\n",
    "    #print(score)\n",
    "scored.sort(key=lambda x: x['score'], reverse=True)\n",
    "scored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    #initialize model\n",
    "    def __init__(self, model, threshold, scaler):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #predict the outcome using treshold\n",
    "    def predict(self, x):\n",
    "        x_pred = self.model.predict(x)\n",
    "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
    "        y_pred = mse > self.threshold\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    #scale the classes\n",
    "    def scale_predict_classes(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.predict(x)\n",
    "        classes_arr = []\n",
    "        for e in y_pred:\n",
    "            el = [0,0]\n",
    "            el[e] = 1\n",
    "            classes_arr.append(el)\n",
    "        print(classes_arr)\n",
    "\n",
    "        return np.array(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation - Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
    "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    return Model(inp, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "486/486 [==============================] - 3s 5ms/step - loss: 0.4881 - val_loss: 0.4146\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.1598 - val_loss: 0.3628\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.1126 - val_loss: 0.3366\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 1s 3ms/step - loss: 0.0943 - val_loss: 0.3180\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0719 - val_loss: 0.2994\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 1s 3ms/step - loss: 0.0550 - val_loss: 0.2881\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0371 - val_loss: 0.2783\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0879 - val_loss: 0.2645\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0449 - val_loss: 0.2564\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0395 - val_loss: 0.2466\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0392 - val_loss: 0.2408\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0311 - val_loss: 0.2341\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0359 - val_loss: 0.2312\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0363 - val_loss: 0.2300\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0448 - val_loss: 0.2180\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0281 - val_loss: 0.2152\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0227 - val_loss: 0.2093\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0238 - val_loss: 0.2055\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0262 - val_loss: 0.2020\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0310 - val_loss: 0.1980\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0302 - val_loss: 0.1976\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0205 - val_loss: 0.1912\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0202 - val_loss: 0.1928\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0191 - val_loss: 0.1870\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0288 - val_loss: 0.1893\n",
      "Epoch 26/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0263 - val_loss: 0.1845\n",
      "Epoch 27/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0265 - val_loss: 0.1929\n",
      "Epoch 28/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0205 - val_loss: 0.1831\n",
      "Epoch 29/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0170 - val_loss: 0.1816\n",
      "Epoch 30/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0172 - val_loss: 0.1840\n",
      "Epoch 31/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0132 - val_loss: 0.1787\n",
      "Epoch 32/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0153 - val_loss: 0.1742\n",
      "Epoch 33/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0153 - val_loss: 0.1765\n",
      "Epoch 34/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0143 - val_loss: 0.1716\n",
      "Epoch 35/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0150 - val_loss: 0.2044\n",
      "Epoch 36/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0152 - val_loss: 0.1719\n",
      "Epoch 37/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0160 - val_loss: 0.1710\n",
      "Epoch 38/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0177 - val_loss: 0.1966\n",
      "Epoch 39/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0120 - val_loss: 0.1712\n",
      "Epoch 40/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0173 - val_loss: 0.1845\n",
      "Epoch 41/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.1714\n",
      "Epoch 42/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0123 - val_loss: 0.1651\n",
      "Epoch 43/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0113 - val_loss: 0.1714\n",
      "Epoch 44/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0127 - val_loss: 0.1848\n",
      "Epoch 45/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0131 - val_loss: 0.1905\n",
      "Epoch 46/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0167 - val_loss: 0.1683\n",
      "Epoch 47/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.0114 - val_loss: 0.1715\n",
      "time: 51.809672594070435\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 87)                10092     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                5104      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                1711      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 87)                5133      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 115)               10120     \n",
      "=================================================================\n",
      "Total params: 33,900\n",
      "Trainable params: 33,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = deep_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",monitor='val_loss',save_best_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_opt, X_opt),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.880280783101494\n",
      "Precision 0.9994079837618404\n",
      "Recall 0.7610123647604328\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 3711 11817]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8763523956723338\n",
      "Precision 0.9994871794871795\n",
      "Recall 0.7530911901081917\n",
      "Confusion Matrix [[15522     6]\n",
      " [ 3834 11694]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8730358062854199\n",
      "Precision 0.999482624816763\n",
      "Recall 0.7464580113343637\n",
      "Confusion Matrix [[15522     6]\n",
      " [ 3937 11591]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.868753219989696\n",
      "Precision 0.9997381742014313\n",
      "Recall 0.737699639361154\n",
      "Confusion Matrix [[15525     3]\n",
      " [ 4073 11455]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8635690365790829\n",
      "Precision 0.9997344427724174\n",
      "Recall 0.7273312725399279\n",
      "Confusion Matrix [[15525     3]\n",
      " [ 4234 11294]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.85448866563627\n",
      "Precision 0.9998183964405702\n",
      "Recall 0.7091061308603812\n",
      "Confusion Matrix [[15526     2]\n",
      " [ 4517 11011]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8508178773827924\n",
      "Precision 0.9998164969263235\n",
      "Recall 0.7017645543534261\n",
      "Confusion Matrix [[15526     2]\n",
      " [ 4631 10897]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8491756826378155\n",
      "Precision 0.9999078001106398\n",
      "Recall 0.6984157650695518\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 4683 10845]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8468250901597115\n",
      "Precision 0.9999071753457718\n",
      "Recall 0.6937145801133436\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 4756 10772]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.845021895929933\n",
      "Precision 0.9999066903051227\n",
      "Recall 0.6901081916537867\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 4812 10716]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8430255023183926\n",
      "Precision 0.9999061473486626\n",
      "Recall 0.6861154044307058\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 4874 10654]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8409647089129315\n",
      "Precision 0.999905580209612\n",
      "Recall 0.6819938176197836\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 4938 10590]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8385819165378671\n",
      "Precision 0.9999049158505278\n",
      "Recall 0.6772282328696548\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5012 10516]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8361025244719217\n",
      "Precision 0.9999042145593869\n",
      "Recall 0.6722694487377641\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5089 10439]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8332367336424523\n",
      "Precision 0.9999033909767172\n",
      "Recall 0.6665378670788253\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5178 10350]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8313691396187533\n",
      "Precision 0.9999028465947731\n",
      "Recall 0.6628026790314271\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5236 10292]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8288253477588872\n",
      "Precision 0.999902095163501\n",
      "Recall 0.657715095311695\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5315 10213]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8263459556929418\n",
      "Precision 0.9999013514846602\n",
      "Recall 0.6527563111798043\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5392 10136]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.824317362184441\n",
      "Precision 0.9999007345642248\n",
      "Recall 0.6486991241628027\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5455 10073]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.821193972179289\n",
      "Precision 0.9998997694697805\n",
      "Recall 0.6424523441524987\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5552  9976]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8183281813498197\n",
      "Precision 0.9998988673139159\n",
      "Recall 0.63672076249356\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5641  9887]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8160741885625966\n",
      "Precision 0.9998981462619678\n",
      "Recall 0.6322127769191138\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5711  9817]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8146573930963421\n",
      "Precision 0.9998976877429916\n",
      "Recall 0.6293791859866048\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5755  9773]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8133371973209685\n",
      "Precision 0.9998972567553683\n",
      "Recall 0.6267387944358578\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5796  9732]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8119848016486347\n",
      "Precision 0.999896811474564\n",
      "Recall 0.6240340030911901\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5838  9690]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8105036063884595\n",
      "Precision 0.9998963193364437\n",
      "Recall 0.6210716125708398\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5884  9644]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8090224111282844\n",
      "Precision 0.9998958224815085\n",
      "Recall 0.6181092220504895\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5930  9598]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8073802163833076\n",
      "Precision 0.9998952660242982\n",
      "Recall 0.6148248325605358\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5981  9547]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8058990211231324\n",
      "Precision 0.9998947589981056\n",
      "Recall 0.6118624420401855\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6027  9501]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        \n",
    "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 1\n",
      "Treshold  448.35397879481826\n",
      "Accuracy  0.8040762444458754\n",
      "Precision  0.9998941350836332\n",
      "Recall 0.6082168845386052\n",
      "Confusion Matrix [[15528     1]\n",
      " [ 6084  9445]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "deep_tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "deep_acc = accuracy_score(Y_test, Y_pred)\n",
    "deep_precision = precision_score(Y_test, Y_pred)\n",
    "deep_recall = recall_score(Y_test, Y_pred)\n",
    "deep_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',deep_acc)\n",
    "print('Precision ',deep_precision)\n",
    "print(\"Recall\",deep_recall)\n",
    "print('Confusion Matrix',deep_cm)\n",
    "   \n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_dim):\n",
    "    original_dim = input_dim\n",
    "    intermediate_dim = 64\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    from keras import backend as K\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    return Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "486/486 [==============================] - 2s 3ms/step - loss: 0.8866 - val_loss: 1.0005\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7488 - val_loss: 0.9915\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6850 - val_loss: 0.9901\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7083 - val_loss: 0.9892\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7057 - val_loss: 0.9883\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7277 - val_loss: 0.9888\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6955 - val_loss: 0.9886\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7219 - val_loss: 0.9869\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7068 - val_loss: 0.9870\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7425 - val_loss: 0.9857\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7039 - val_loss: 0.9848\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6760 - val_loss: 0.9845\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7435 - val_loss: 0.9847\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7103 - val_loss: 0.9834\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7185 - val_loss: 0.9835\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7093 - val_loss: 0.9834\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6749 - val_loss: 0.9830\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7209 - val_loss: 0.9826\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7088 - val_loss: 0.9825\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6911 - val_loss: 0.9824\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6836 - val_loss: 0.9835\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7442 - val_loss: 0.9838\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7196 - val_loss: 0.9835\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6883 - val_loss: 0.9828\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6819 - val_loss: 0.9825\n",
      "time: 24.778944492340088\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 2), (None, 2), (N 7684      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 115)               7667      \n",
      "=================================================================\n",
      "Total params: 15,351\n",
      "Trainable params: 15,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = vae_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_vae.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8812789799072643\n",
      "Precision 0.9982327695026508\n",
      "Recall 0.7639103554868625\n",
      "Confusion Matrix [[15507    21]\n",
      " [ 3666 11862]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8760947964966512\n",
      "Precision 0.9992306377158489\n",
      "Recall 0.7527691911385883\n",
      "Confusion Matrix [[15519     9]\n",
      " [ 3839 11689]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8711038124678001\n",
      "Precision 0.99930681916645\n",
      "Recall 0.7427228232869655\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 3995 11533]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8640520350334879\n",
      "Precision 0.999293411058117\n",
      "Recall 0.728619268418341\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 4214 11314]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8530074703760948\n",
      "Precision 0.9993623029971759\n",
      "Recall 0.7064657393096342\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4558 10970]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8494976816074189\n",
      "Precision 0.999355907250644\n",
      "Recall 0.6994461617722824\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4667 10861]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8467928902627512\n",
      "Precision 0.9993508902077152\n",
      "Recall 0.6940365790829469\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4751 10777]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8444744976816074\n",
      "Precision 0.9994397759103641\n",
      "Recall 0.6893353941267388\n",
      "Confusion Matrix [[15522     6]\n",
      " [ 4824 10704]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8413833075734157\n",
      "Precision 0.9995288352808142\n",
      "Recall 0.6830886141164348\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 4921 10607]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8378413189077795\n",
      "Precision 0.9995239002094839\n",
      "Recall 0.6760046367851623\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 5031 10497]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8340739309634209\n",
      "Precision 0.9995185363505056\n",
      "Recall 0.6684698608964451\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 5148 10380]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8314335394126738\n",
      "Precision 0.9997087095834547\n",
      "Recall 0.6630602782071098\n",
      "Confusion Matrix [[15525     3]\n",
      " [ 5232 10296]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8278593508500772\n",
      "Precision 0.9998036520714706\n",
      "Recall 0.6558475012879958\n",
      "Confusion Matrix [[15526     2]\n",
      " [ 5344 10184]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8243817619783617\n",
      "Precision 0.9999007542675665\n",
      "Recall 0.648827923750644\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5453 10075]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8200347758887172\n",
      "Precision 0.9998994064983402\n",
      "Recall 0.640133951571355\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5588  9940]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8165571870170015\n",
      "Precision 0.9998983016373436\n",
      "Recall 0.6331787738279238\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5696  9832]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8148183925811437\n",
      "Precision 0.9998977400552204\n",
      "Recall 0.6297011849562082\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5750  9778]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8129507985574446\n",
      "Precision 0.9998971299249049\n",
      "Recall 0.6259659969088099\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5808  9720]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8110832045337455\n",
      "Precision 0.9998965124702474\n",
      "Recall 0.6222308088614117\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5866  9662]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8087326120556414\n",
      "Precision 0.999895724713243\n",
      "Recall 0.6175296239052035\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5939  9589]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8065752189592993\n",
      "Precision 0.9998949910742413\n",
      "Recall 0.6132148377125193\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6006  9522]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8050296239052035\n",
      "Precision 0.9998944591029024\n",
      "Recall 0.6101236476043277\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6054  9474]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8031298299845441\n",
      "Precision 0.9998937977909941\n",
      "Recall 0.6063240597630087\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6113  9415]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8016808346213292\n",
      "Precision 0.9998932878027958\n",
      "Recall 0.6034260690365791\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6158  9370]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8004250386398764\n",
      "Precision 0.9998928418345477\n",
      "Recall 0.6009144770736734\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6197  9331]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.7993946419371458\n",
      "Precision 0.9998924731182796\n",
      "Recall 0.5988536836682122\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6229  9299]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.7982354456465739\n",
      "Precision 0.999892055267703\n",
      "Recall 0.5965352910870685\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6265  9263]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.7969152498712004\n",
      "Precision 0.9998915754093028\n",
      "Recall 0.5938948995363215\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6306  9222]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.7954662545079856\n",
      "Precision 0.9998910438003923\n",
      "Recall 0.5909969088098919\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6351  9177]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 1\n",
      "Treshold  24.296960242198608\n",
      "Accuracy  0.8790327773842488\n",
      "Precision  0.9974645030425964\n",
      "Recall 0.7599974241741259\n",
      "Confusion Matrix [[15499    30]\n",
      " [ 3727 11802]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "vae_acc = accuracy_score(Y_test, Y_pred)\n",
    "vae_precision = precision_score(Y_test, Y_pred)\n",
    "vae_recall = recall_score(Y_test, Y_pred)\n",
    "vae_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',vae_acc)\n",
    "print('Precision ',vae_precision)\n",
    "print(\"Recall\",vae_recall)\n",
    "print('Confusion Matrix',vae_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(15, activation='relu')(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9453 - val_loss: 0.9899\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7244 - val_loss: 0.9728\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6797 - val_loss: 0.9668\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7026 - val_loss: 0.9640\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6878 - val_loss: 0.9622\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7034 - val_loss: 0.9608\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7019 - val_loss: 0.9600\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7072 - val_loss: 0.9593\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6669 - val_loss: 0.9586\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7113 - val_loss: 0.9581\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7115 - val_loss: 0.9576\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6635 - val_loss: 0.9569\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6964 - val_loss: 0.9565\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6892 - val_loss: 0.9562\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6622 - val_loss: 0.9558\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6901 - val_loss: 0.9555\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7590 - val_loss: 0.9553\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6852 - val_loss: 0.9551\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7127 - val_loss: 0.9550\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6662 - val_loss: 0.9548\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6919 - val_loss: 0.9547\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7050 - val_loss: 0.9545\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6766 - val_loss: 0.9544\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6615 - val_loss: 0.9542\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6416 - val_loss: 0.9542\n",
      "Epoch 26/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7179 - val_loss: 0.9541\n",
      "Epoch 27/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6710 - val_loss: 0.9541\n",
      "Epoch 28/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6631 - val_loss: 0.9540\n",
      "Epoch 29/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7111 - val_loss: 0.9540\n",
      "Epoch 30/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6638 - val_loss: 0.9539\n",
      "Epoch 31/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6839 - val_loss: 0.9538\n",
      "Epoch 32/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6885 - val_loss: 0.9538\n",
      "Epoch 33/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6729 - val_loss: 0.9538\n",
      "Epoch 34/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6686 - val_loss: 0.9537\n",
      "Epoch 35/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6819 - val_loss: 0.9537\n",
      "Epoch 36/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6896 - val_loss: 0.9537\n",
      "Epoch 37/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6911 - val_loss: 0.9536\n",
      "Epoch 38/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6993 - val_loss: 0.9536\n",
      "Epoch 39/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6924 - val_loss: 0.9536\n",
      "Epoch 40/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6778 - val_loss: 0.9536\n",
      "Epoch 41/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6757 - val_loss: 0.9535\n",
      "Epoch 42/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6846 - val_loss: 0.9535\n",
      "Epoch 43/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7001 - val_loss: 0.9535\n",
      "Epoch 44/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6614 - val_loss: 0.9535\n",
      "Epoch 45/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6777 - val_loss: 0.9534\n",
      "Epoch 46/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6998 - val_loss: 0.9534\n",
      "Epoch 47/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6932 - val_loss: 0.9533\n",
      "Epoch 48/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6643 - val_loss: 0.9534\n",
      "Epoch 49/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6967 - val_loss: 0.9534\n",
      "Epoch 50/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7115 - val_loss: 0.9533\n",
      "Epoch 51/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6833 - val_loss: 0.9533\n",
      "Epoch 52/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6975 - val_loss: 0.9533\n",
      "Epoch 53/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7277 - val_loss: 0.9533\n",
      "Epoch 54/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7142 - val_loss: 0.9533\n",
      "Epoch 55/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6708 - val_loss: 0.9533\n",
      "Epoch 56/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6416 - val_loss: 0.9533\n",
      "Epoch 57/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7277 - val_loss: 0.9533\n",
      "Epoch 58/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6756 - val_loss: 0.9533\n",
      "Epoch 59/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6896 - val_loss: 0.9533\n",
      "Epoch 60/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6820 - val_loss: 0.9533\n",
      "Epoch 61/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6789 - val_loss: 0.9533\n",
      "Epoch 62/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6668 - val_loss: 0.9533\n",
      "Epoch 63/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7021 - val_loss: 0.9533\n",
      "Epoch 64/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.6852 - val_loss: 0.9533\n",
      "Epoch 65/100\n",
      "486/486 [==============================] - 1s 1ms/step - loss: 0.7236 - val_loss: 0.9533\n",
      "Epoch 66/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6523 - val_loss: 0.9532\n",
      "Epoch 67/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6682 - val_loss: 0.9533\n",
      "Epoch 68/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6661 - val_loss: 0.9533\n",
      "Epoch 69/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6917 - val_loss: 0.9533\n",
      "Epoch 70/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6438 - val_loss: 0.9532\n",
      "Epoch 71/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6661 - val_loss: 0.9533\n",
      "Epoch 72/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7051 - val_loss: 0.9532\n",
      "Epoch 73/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6693 - val_loss: 0.9532\n",
      "Epoch 74/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6490 - val_loss: 0.9532\n",
      "Epoch 75/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6706 - val_loss: 0.9533\n",
      "time: 55.36045289039612\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                1740      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 115)               1840      \n",
      "=================================================================\n",
      "Total params: 3,580\n",
      "Trainable params: 3,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = uc_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_undercomplete.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.881053580628542\n",
      "Precision 0.9984835720303286\n",
      "Recall 0.7632663575476558\n",
      "Confusion Matrix [[15510    18]\n",
      " [ 3676 11852]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8761269963936116\n",
      "Precision 0.9993160639480209\n",
      "Recall 0.7527691911385883\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 3839 11689]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8710716125708398\n",
      "Precision 0.9993067590987869\n",
      "Recall 0.7426584234930448\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 3996 11532]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8640520350334879\n",
      "Precision 0.999293411058117\n",
      "Recall 0.728619268418341\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 4214 11314]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8531040700669758\n",
      "Precision 0.9993624772313296\n",
      "Recall 0.7066589386913962\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4555 10973]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8496264811952602\n",
      "Precision 0.9993561442236939\n",
      "Recall 0.6997037609479649\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4663 10865]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8470182895414735\n",
      "Precision 0.9993513112779168\n",
      "Recall 0.6944873776403916\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4744 10784]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8444744976816074\n",
      "Precision 0.9994397759103641\n",
      "Recall 0.6893353941267388\n",
      "Confusion Matrix [[15522     6]\n",
      " [ 4824 10704]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8414799072642968\n",
      "Precision 0.9995289684408856\n",
      "Recall 0.6832818134981968\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 4918 10610]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8380667181865018\n",
      "Precision 0.9995242173375202\n",
      "Recall 0.6764554353426069\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 5024 10504]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8342993302421432\n",
      "Precision 0.9995188606620478\n",
      "Recall 0.6689206594538898\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 5141 10387]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8315301391035549\n",
      "Precision 0.9997087944088526\n",
      "Recall 0.6632534775888718\n",
      "Confusion Matrix [[15525     3]\n",
      " [ 5229 10299]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8278915507470376\n",
      "Precision 0.9998036713458329\n",
      "Recall 0.6559119010819165\n",
      "Confusion Matrix [[15526     2]\n",
      " [ 5343 10185]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8245427614631633\n",
      "Precision 0.9999008034917171\n",
      "Recall 0.6491499227202473\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5448 10080]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8202923750643998\n",
      "Precision 0.9998994873856669\n",
      "Recall 0.6406491499227203\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5580  9948]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8168147861926842\n",
      "Precision 0.9998983843105376\n",
      "Recall 0.633693972179289\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5688  9840]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8150115919629057\n",
      "Precision 0.9998978027593255\n",
      "Recall 0.6300875837197321\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5744  9784]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8133049974240082\n",
      "Precision 0.9998972461981094\n",
      "Recall 0.6266743946419372\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5797  9731]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8115662029881504\n",
      "Precision 0.9998966728662947\n",
      "Recall 0.6231968057702215\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5851  9677]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8089258114374034\n",
      "Precision 0.9998957899124635\n",
      "Recall 0.6179160226687275\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5933  9595]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8069294178258629\n",
      "Precision 0.999895112229914\n",
      "Recall 0.6139232354456465\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5995  9533]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8052550231839258\n",
      "Precision 0.9998945370175069\n",
      "Recall 0.6105744461617723\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6047  9481]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8034518289541474\n",
      "Precision 0.9998939104604286\n",
      "Recall 0.6069680577022154\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6103  9425]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8018740340030912\n",
      "Precision 0.9998933560840354\n",
      "Recall 0.603812467800103\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6152  9376]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.800586038124678\n",
      "Precision 0.9998928992181643\n",
      "Recall 0.6012364760432767\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6192  9336]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.7998454404945904\n",
      "Precision 0.9998926347433971\n",
      "Recall 0.5997552807831015\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6215  9313]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.7987828438948995\n",
      "Precision 0.9998922529899795\n",
      "Recall 0.5976300875837197\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6248  9280]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.7973338485316847\n",
      "Precision 0.9998917280207882\n",
      "Recall 0.59473209685729\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6293  9235]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.7959492529623905\n",
      "Precision 0.9998912215816382\n",
      "Recall 0.5919629057187017\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6336  9192]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 1\n",
      "Treshold  24.258207484916756\n",
      "Accuracy  0.8788073926202589\n",
      "Precision  0.9974630021141649\n",
      "Recall 0.7595466546461459\n",
      "Confusion Matrix [[15499    30]\n",
      " [ 3734 11795]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "uc_acc = accuracy_score(Y_test, Y_pred)\n",
    "uc_precision = precision_score(Y_test, Y_pred)\n",
    "uc_recall = recall_score(Y_test, Y_pred)\n",
    "uc_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',uc_acc)\n",
    "print('Precision ',uc_precision)\n",
    "print(\"Recall\",uc_recall)\n",
    "print('Confusion Matrix',uc_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(200, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-6))(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8149 - val_loss: 0.9625\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7024 - val_loss: 0.9573\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6867 - val_loss: 0.9553\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6541 - val_loss: 0.9544\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7209 - val_loss: 0.9540\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6624 - val_loss: 0.9539\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7166 - val_loss: 0.9535\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7022 - val_loss: 0.9534\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6744 - val_loss: 0.9533\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6643 - val_loss: 0.9531\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6664 - val_loss: 0.9529\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6584 - val_loss: 0.9529\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6822 - val_loss: 0.9527\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6379 - val_loss: 0.9527\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6707 - val_loss: 0.9527\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6728 - val_loss: 0.9525\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6717 - val_loss: 0.9525\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6870 - val_loss: 0.9524\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6618 - val_loss: 0.9525\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6647 - val_loss: 0.9524\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6853 - val_loss: 0.9522\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7099 - val_loss: 0.9522\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7067 - val_loss: 0.9521\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6785 - val_loss: 0.9522\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6676 - val_loss: 0.9522\n",
      "Epoch 26/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6731 - val_loss: 0.9521\n",
      "Epoch 27/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6867 - val_loss: 0.9522\n",
      "Epoch 28/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7023 - val_loss: 0.9521\n",
      "Epoch 29/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6647 - val_loss: 0.9521\n",
      "Epoch 30/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6443 - val_loss: 0.9522\n",
      "Epoch 31/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7039 - val_loss: 0.9522\n",
      "Epoch 32/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6576 - val_loss: 0.9520\n",
      "Epoch 33/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.7313 - val_loss: 0.9520\n",
      "Epoch 34/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6964 - val_loss: 0.9520\n",
      "Epoch 35/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6402 - val_loss: 0.9520\n",
      "Epoch 36/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6528 - val_loss: 0.9520\n",
      "Epoch 37/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6485 - val_loss: 0.9523\n",
      "Epoch 38/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6764 - val_loss: 0.9521\n",
      "Epoch 39/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.6751 - val_loss: 0.9522\n",
      "time: 36.76442742347717\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               23200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 115)               23115     \n",
      "=================================================================\n",
      "Total params: 46,315\n",
      "Trainable params: 46,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = sparse_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8809247810407007\n",
      "Precision 0.9984830608461149\n",
      "Recall 0.7630087583719732\n",
      "Confusion Matrix [[15510    18]\n",
      " [ 3680 11848]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8761269963936116\n",
      "Precision 0.9993160639480209\n",
      "Recall 0.7527691911385883\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 3839 11689]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8704598145285936\n",
      "Precision 0.999305615831959\n",
      "Recall 0.7414348274085523\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 4015 11513]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8632148377125193\n",
      "Precision 0.9992917847025495\n",
      "Recall 0.7269448737764039\n",
      "Confusion Matrix [[15520     8]\n",
      " [ 4240 11288]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8529108706852138\n",
      "Precision 0.9993621286677602\n",
      "Recall 0.7062725399278722\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4561 10967]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8495942812982998\n",
      "Precision 0.9993560849967804\n",
      "Recall 0.6996393611540443\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4664 10864]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8469538897475528\n",
      "Precision 0.9993511910278988\n",
      "Recall 0.6943585780525502\n",
      "Confusion Matrix [[15521     7]\n",
      " [ 4746 10782]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8444422977846471\n",
      "Precision 0.9994397235969745\n",
      "Recall 0.6892709943328181\n",
      "Confusion Matrix [[15522     6]\n",
      " [ 4825 10703]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8413511076764555\n",
      "Precision 0.9995287908773914\n",
      "Recall 0.6830242143225141\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 4922 10606]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8379701184956209\n",
      "Precision 0.9995240814772511\n",
      "Recall 0.6762622359608449\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 5027 10501]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8341383307573416\n",
      "Precision 0.9995186290555502\n",
      "Recall 0.6685986604842864\n",
      "Confusion Matrix [[15523     5]\n",
      " [ 5146 10382]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8314013395157136\n",
      "Precision 0.9997086812973393\n",
      "Recall 0.6629958784131891\n",
      "Confusion Matrix [[15525     3]\n",
      " [ 5233 10295]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.827827150953117\n",
      "Precision 0.9998036327933235\n",
      "Recall 0.6557831014940753\n",
      "Confusion Matrix [[15526     2]\n",
      " [ 5345 10183]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8242851622874807\n",
      "Precision 0.9999007247096198\n",
      "Recall 0.648634724368882\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5456 10072]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8200669757856774\n",
      "Precision 0.9998994166163749\n",
      "Recall 0.6401983513652756\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5587  9941]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8167825862957239\n",
      "Precision 0.9998983739837398\n",
      "Recall 0.6336295723853683\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5689  9839]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8151081916537867\n",
      "Precision 0.9998978340825501\n",
      "Recall 0.630280783101494\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5741  9787]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8132405976300876\n",
      "Precision 0.9998972250770812\n",
      "Recall 0.6265455950540958\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5799  9729]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.811920401854714\n",
      "Precision 0.9998967901744246\n",
      "Recall 0.6239052035033488\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5840  9688]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8092478104070067\n",
      "Precision 0.9998958983968353\n",
      "Recall 0.618560020607934\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5923  9605]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8070904173106646\n",
      "Precision 0.9998951672083027\n",
      "Recall 0.6142452344152499\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 5990  9538]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8053516228748068\n",
      "Precision 0.9998945703742752\n",
      "Recall 0.6107676455435342\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6044  9484]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8036772282328697\n",
      "Precision 0.9998939891868971\n",
      "Recall 0.60741885625966\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6096  9432]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8019706336939721\n",
      "Precision 0.9998933901918976\n",
      "Recall 0.604005667181865\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6149  9379]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8006504379185987\n",
      "Precision 0.9998929221544063\n",
      "Recall 0.601365275631118\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6190  9338]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.800006439979392\n",
      "Precision 0.9998926923489645\n",
      "Recall 0.6000772797527048\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6210  9318]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.7988150437918599\n",
      "Precision 0.999892264598147\n",
      "Recall 0.5976944873776404\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6247  9281]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.7973982483256054\n",
      "Precision 0.9998917514613552\n",
      "Recall 0.5948608964451314\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6291  9237]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.7959814528593508\n",
      "Precision 0.9998912334130955\n",
      "Recall 0.5920273055126224\n",
      "Confusion Matrix [[15527     1]\n",
      " [ 6335  9193]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 1\n",
      "Treshold  24.25414027696972\n",
      "Accuracy  0.8787107991499774\n",
      "Precision  0.997462358315006\n",
      "Recall 0.7593534677055831\n",
      "Confusion Matrix [[15499    30]\n",
      " [ 3737 11792]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "sparse_acc = accuracy_score(Y_test, Y_pred)\n",
    "sparse_precision = precision_score(Y_test, Y_pred)\n",
    "sparse_recall = recall_score(Y_test, Y_pred)\n",
    "sparse_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',sparse_acc)\n",
    "print('Precision ',sparse_precision)\n",
    "print(\"Recall\",sparse_recall)\n",
    "print('Confusion Matrix',sparse_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_model(input_dim):\n",
    "    input_size = input_dim\n",
    "    hidden_size = 44\n",
    "    code_size = 5\n",
    "\n",
    "    input_img = Input(shape=(input_size,))\n",
    "    hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "    code = Dense(code_size, activation='relu')(hidden_1)\n",
    "    hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "    output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "    autoencoder = Model(input_img, output_img)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 1.0583 - val_loss: 1.2292\n",
      "Epoch 2/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9244 - val_loss: 1.1939\n",
      "Epoch 3/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9182 - val_loss: 1.1761\n",
      "Epoch 4/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8552 - val_loss: 1.1710\n",
      "Epoch 5/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9256 - val_loss: 1.1682\n",
      "Epoch 6/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8882 - val_loss: 1.1673\n",
      "Epoch 7/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8936 - val_loss: 1.1661\n",
      "Epoch 8/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8543 - val_loss: 1.1660\n",
      "Epoch 9/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8491 - val_loss: 1.1657\n",
      "Epoch 10/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9145 - val_loss: 1.1654\n",
      "Epoch 11/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8994 - val_loss: 1.1653\n",
      "Epoch 12/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9357 - val_loss: 1.1651\n",
      "Epoch 13/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8570 - val_loss: 1.1648\n",
      "Epoch 14/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8662 - val_loss: 1.1645\n",
      "Epoch 15/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9248 - val_loss: 1.1643\n",
      "Epoch 16/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9042 - val_loss: 1.1641\n",
      "Epoch 17/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9839 - val_loss: 1.1642\n",
      "Epoch 18/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8776 - val_loss: 1.1642\n",
      "Epoch 19/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8582 - val_loss: 1.1636\n",
      "Epoch 20/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9026 - val_loss: 1.1647\n",
      "Epoch 21/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8738 - val_loss: 1.1639\n",
      "Epoch 22/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8786 - val_loss: 1.1636\n",
      "Epoch 23/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8719 - val_loss: 1.1629\n",
      "Epoch 24/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8202 - val_loss: 1.1628\n",
      "Epoch 25/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8659 - val_loss: 1.1621\n",
      "Epoch 26/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8582 - val_loss: 1.1632\n",
      "Epoch 27/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8606 - val_loss: 1.1618\n",
      "Epoch 28/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9162 - val_loss: 1.1613\n",
      "Epoch 29/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8749 - val_loss: 1.1610\n",
      "Epoch 30/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9334 - val_loss: 1.1605\n",
      "Epoch 31/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8581 - val_loss: 1.1616\n",
      "Epoch 32/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8630 - val_loss: 1.1604\n",
      "Epoch 33/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8691 - val_loss: 1.1601\n",
      "Epoch 34/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9070 - val_loss: 1.1600\n",
      "Epoch 35/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8759 - val_loss: 1.1617\n",
      "Epoch 36/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8728 - val_loss: 1.1597\n",
      "Epoch 37/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9357 - val_loss: 1.1599\n",
      "Epoch 38/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8973 - val_loss: 1.1599\n",
      "Epoch 39/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8720 - val_loss: 1.1592\n",
      "Epoch 40/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8846 - val_loss: 1.1598\n",
      "Epoch 41/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9085 - val_loss: 1.1589\n",
      "Epoch 42/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8755 - val_loss: 1.1592\n",
      "Epoch 43/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9310 - val_loss: 1.1591\n",
      "Epoch 44/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8611 - val_loss: 1.1585\n",
      "Epoch 45/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.9514 - val_loss: 1.1582\n",
      "Epoch 46/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8849 - val_loss: 1.1580\n",
      "Epoch 47/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8836 - val_loss: 1.1580\n",
      "Epoch 48/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8774 - val_loss: 1.1582\n",
      "Epoch 49/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8399 - val_loss: 1.1580\n",
      "Epoch 50/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8540 - val_loss: 1.1597\n",
      "Epoch 51/100\n",
      "486/486 [==============================] - 1s 2ms/step - loss: 0.8774 - val_loss: 1.1587\n",
      "time: 43.48489499092102\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 44)                5104      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 225       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 44)                264       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 115)               5175      \n",
      "=================================================================\n",
      "Total params: 10,768\n",
      "Trainable params: 10,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "x_opt_noisy = np.clip(x_opt_noisy, 0., 1.)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "#x_train_noisy = scaler.fit_transform(x_train_noisy)\n",
    "#x_opt_noisy = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#call function to create the model\n",
    "model = denoise_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(x_train_noisy, X_train,\n",
    "                    epochs=epochs, validation_data=(x_opt_noisy, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.7150631117980423\n",
      "Precision 0.6369938876810108\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 6679  8849]\n",
      " [    0 15528]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.7927614631633179\n",
      "Precision 0.7069750500819523\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 9092  6436]\n",
      " [    0 15528]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8550360638845955\n",
      "Precision 0.7752371442835746\n",
      "Recall 1.0\n",
      "Confusion Matrix [[11026  4502]\n",
      " [    0 15528]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8934827408552293\n",
      "Precision 0.8243788490125292\n",
      "Recall 1.0\n",
      "Confusion Matrix [[12220  3308]\n",
      " [    0 15528]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9202086553323029\n",
      "Precision 0.8624194623417019\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[13051  2477]\n",
      " [    1 15527]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.934473209685729\n",
      "Precision 0.8841751608678321\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[13494  2034]\n",
      " [    1 15527]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9431993817619784\n",
      "Precision 0.8980335454019664\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[13765  1763]\n",
      " [    1 15527]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9483513652756311\n",
      "Precision 0.9064214827787507\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[13925  1603]\n",
      " [    1 15527]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9519577537351881\n",
      "Precision 0.9123868844752615\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14037  1491]\n",
      " [    1 15527]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9536965481710459\n",
      "Precision 0.9152912049045037\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14091  1437]\n",
      " [    1 15527]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9547591447707368\n",
      "Precision 0.9170751875258402\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14124  1404]\n",
      " [    1 15527]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9557895414734673\n",
      "Precision 0.9188117640097048\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14156  1372]\n",
      " [    1 15527]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9562081401339516\n",
      "Precision 0.9195191282719413\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14169  1359]\n",
      " [    1 15527]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9564657393096342\n",
      "Precision 0.9199549709681242\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14177  1351]\n",
      " [    1 15527]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9570131375579598\n",
      "Precision 0.9208825099341676\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14194  1334]\n",
      " [    1 15527]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.9578181349819681\n",
      "Precision 0.9222499406034688\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14219  1309]\n",
      " [    1 15527]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.9587197320968572\n",
      "Precision 0.9237862922417897\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14247  1281]\n",
      " [    1 15527]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.9593637300360639\n",
      "Precision 0.924886823921849\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14267  1261]\n",
      " [    1 15527]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.9600399278722308\n",
      "Precision 0.9260452078487506\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14288  1240]\n",
      " [    1 15527]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.9607161257083977\n",
      "Precision 0.9272064970739281\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14309  1219]\n",
      " [    1 15527]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.9619719216898506\n",
      "Precision 0.9293709223678698\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14348  1180]\n",
      " [    1 15527]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.9626159196290572\n",
      "Precision 0.9304848085335891\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14368  1160]\n",
      " [    1 15527]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.9638395157135498\n",
      "Precision 0.9326085650789837\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14406  1122]\n",
      " [    1 15527]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.9650631117980423\n",
      "Precision 0.9347420384082836\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14444  1084]\n",
      " [    1 15527]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.9662545079855744\n",
      "Precision 0.9368287679498009\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14481  1047]\n",
      " [    1 15527]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.9676391035548686\n",
      "Precision 0.9392656221644183\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14524  1004]\n",
      " [    1 15527]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.9689592993302422\n",
      "Precision 0.9416009702850212\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14565   963]\n",
      " [    1 15527]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.9700540958268934\n",
      "Precision 0.9435464268351968\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14599   929]\n",
      " [    1 15527]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.9707946934569809\n",
      "Precision 0.944867035842512\n",
      "Recall 0.9999356002060793\n",
      "Confusion Matrix [[14622   906]\n",
      " [    1 15527]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(x_opt_noisy)\n",
    "mse = np.mean(np.power(x_opt_noisy - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "X_opt_scaled = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 29\n",
      "Treshold  6.144931528089354\n",
      "Accuracy  0.9996136261188744\n",
      "Precision  0.9992278489157712\n",
      "Recall 1.0\n",
      "Confusion Matrix [[15517    12]\n",
      " [    0 15529]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(x_test_noisy, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=20)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "X_test_scaled = scaler.transform(x_test_noisy)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "denoise_acc = accuracy_score(Y_test, Y_pred)\n",
    "denoise_precision = precision_score(Y_test, Y_pred)\n",
    "denoise_recall = recall_score(Y_test, Y_pred)\n",
    "denoise_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',denoise_acc)\n",
    "print('Precision ',denoise_precision)\n",
    "print(\"Recall\",denoise_recall)\n",
    "print('Confusion Matrix',denoise_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(80, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Dense(labels.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, callbacks=[monitor], patience=5) \n",
    "    model.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n",
    "          verbose=1,epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 1\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 0\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))\n",
    "\n",
    "X = df_ben.drop(columns=['class'])\n",
    "y = df_ben['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=17)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.0108\n",
      "Epoch 2/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.0016\n",
      "Epoch 3/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.0015\n",
      "Epoch 4/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 5.3902e-04\n",
      "Epoch 5/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 0.0018\n",
      "Epoch 6/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 4.9696e-04\n",
      "Epoch 7/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 9.9354e-04\n",
      "Epoch 8/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 7.6701e-04\n",
      "Epoch 9/100\n",
      "1657/1657 [==============================] - 2s 1ms/step - loss: 4.7829e-04\n",
      "time 15.716485977172852\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_dim=115, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "\n",
    "#compile and fit model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=15,callbacks=[es])\n",
    "\n",
    "end = time.time()\n",
    "print(\"time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9995170637475853\n",
      "Precision  0.999347045380346\n",
      "Recall 0.9996734160679295\n",
      "Confusion Matrix [[3148    2]\n",
      " [   1 3061]]\n"
     ]
    }
   ],
   "source": [
    "dnn_acc = accuracy_score(y_test, y_pred)\n",
    "dnn_precision = precision_score(y_test, y_pred)\n",
    "dnn_recall = recall_score(y_test, y_pred)\n",
    "dnn_cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy ',dnn_acc)\n",
    "print('Precision ',dnn_precision)\n",
    "print(\"Recall\",dnn_recall)\n",
    "print('Confusion Matrix',dnn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleHome_XCS7_1002_WHT_Security_Camera\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>CM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep AutoEncoder</td>\n",
       "      <td>0.804076</td>\n",
       "      <td>0.999894</td>\n",
       "      <td>0.608217</td>\n",
       "      <td>[[15528, 1], [6084, 9445]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse AutoEncoder</td>\n",
       "      <td>0.878711</td>\n",
       "      <td>0.997462</td>\n",
       "      <td>0.759353</td>\n",
       "      <td>[[15499, 30], [3737, 11792]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undercomplete Autoencoder</td>\n",
       "      <td>0.878807</td>\n",
       "      <td>0.997463</td>\n",
       "      <td>0.759547</td>\n",
       "      <td>[[15499, 30], [3734, 11795]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variational AutoEncoder</td>\n",
       "      <td>0.879033</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.759997</td>\n",
       "      <td>[[15499, 30], [3727, 11802]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denoising Autoendoer</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[[15517, 12], [0, 15529]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  \\\n",
       "0           Deep AutoEncoder  0.804076   0.999894  0.608217   \n",
       "2         Sparse AutoEncoder  0.878711   0.997462  0.759353   \n",
       "3  Undercomplete Autoencoder  0.878807   0.997463  0.759547   \n",
       "1    Variational AutoEncoder  0.879033   0.997465  0.759997   \n",
       "4       Denoising Autoendoer  0.999614   0.999228  1.000000   \n",
       "\n",
       "                             CM  \n",
       "0    [[15528, 1], [6084, 9445]]  \n",
       "2  [[15499, 30], [3737, 11792]]  \n",
       "3  [[15499, 30], [3734, 11795]]  \n",
       "1  [[15499, 30], [3727, 11802]]  \n",
       "4     [[15517, 12], [0, 15529]]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"SimpleHome_XCS7_1002_WHT_Security_Camera\")\n",
    "model_summary = pd.DataFrame({'Model' :['Deep AutoEncoder',\"Variational AutoEncoder\",\"Sparse AutoEncoder\",\"Undercomplete Autoencoder\",\"Denoising Autoendoer\"],\n",
    "                             'Accuracy':[deep_acc,vae_acc,sparse_acc,uc_acc,denoise_acc],\n",
    "                             'Precision':[deep_precision,vae_precision,sparse_precision,uc_precision,denoise_precision],\n",
    "                             'Recall':[deep_recall,vae_recall,sparse_recall,uc_recall,denoise_recall],\n",
    "                             'CM':[deep_cm,vae_cm,sparse_cm,uc_cm, denoise_cm]})\n",
    "model_summary.sort_values(by='Accuracy', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
