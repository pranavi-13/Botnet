{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=pd.read_csv(\"Camera737E/benign_traffic.csv\")\n",
    "x_train, x_opt, x_test = np.split(benign.sample(frac=1, random_state=20), [int(1/3*len(benign)), int(2/3*len(benign))])\n",
    "\n",
    "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('Camera737E/mirai/*.csv', recursive=False)), ignore_index=True)\n",
    "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('Camera737E/gafgyt/*.csv', recursive=False)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 'malicious'\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 'benign'\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting samples of benign and malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n = 2000\n",
    "atk = df_attack.sample(n=plot_n, random_state=76)\n",
    "nrm = x_train.sample(n=plot_n, random_state=42)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
    "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
    "\n",
    "plt.xlabel('MI_dir_L0.1_weight')\n",
    "plt.ylabel('MI_dir_L1_weight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'HH_jit_L0.01_mean', 'score': 0.8100151319652277},\n",
       " {'feature': 'HH_jit_L0.1_mean', 'score': 0.8052717647117524},\n",
       " {'feature': 'HH_jit_L1_mean', 'score': 0.7703158571117954},\n",
       " {'feature': 'HH_jit_L5_mean', 'score': 0.7627209177162049},\n",
       " {'feature': 'HH_jit_L3_mean', 'score': 0.7625725671879852}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['benign','malicious']\n",
    "scored = []\n",
    "indices = {}\n",
    "shps = {}\n",
    "\n",
    "#classifying benign as true and attack as false\n",
    "for cl in classes:\n",
    "    indices[cl] = df_ben['class'] == cl    \n",
    "    shps[cl] =  df_ben[indices[cl]].shape[0]\n",
    "        \n",
    "for col in df_ben.columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "    num = 0\n",
    "    den = 0\n",
    "    m = df_ben[col].mean()\n",
    "    \n",
    "    for cl in classes:\n",
    "        num += (shps[cl] / df_ben.shape[0]) * (m - df_ben[indices[cl]][col].mean())**2\n",
    "        den += (shps[cl] / df_ben.shape[0]) * df_ben[indices[cl]][col].var()\n",
    "    score = {'feature': col, 'score': num / den}\n",
    "    scored.append(score)\n",
    "    #print(score)\n",
    "scored.sort(key=lambda x: x['score'], reverse=True)\n",
    "scored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    #initialize model\n",
    "    def __init__(self, model, threshold, scaler):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #predict the outcome using treshold\n",
    "    def predict(self, x):\n",
    "        x_pred = self.model.predict(x)\n",
    "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
    "        y_pred = mse > self.threshold\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    #scale the classes\n",
    "    def scale_predict_classes(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.predict(x)\n",
    "        classes_arr = []\n",
    "        for e in y_pred:\n",
    "            el = [0,0]\n",
    "            el[e] = 1\n",
    "            classes_arr.append(el)\n",
    "        print(classes_arr)\n",
    "\n",
    "        return np.array(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation - Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
    "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    return Model(inp, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "648/648 [==============================] - 6s 5ms/step - loss: 0.3310 - val_loss: 0.0787\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0652 - val_loss: 0.0536\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0435 - val_loss: 0.0376\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0346 - val_loss: 0.0334\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0307 - val_loss: 0.0234\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0227 - val_loss: 0.0182\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0205 - val_loss: 0.0192\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0192 - val_loss: 0.0164\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0152 - val_loss: 0.0183\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0147 - val_loss: 0.0152\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0118 - val_loss: 0.0189\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.0158 - val_loss: 0.0133\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0075 - val_loss: 0.0137\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 31/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 32/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0077 - val_loss: 0.0144\n",
      "Epoch 33/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0094 - val_loss: 0.0071\n",
      "Epoch 34/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 35/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 36/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 37/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 38/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.0056 - val_loss: 0.0072\n",
      "Epoch 39/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0069 - val_loss: 0.0065\n",
      "Epoch 40/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 41/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 42/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 43/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 44/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 45/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 46/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 47/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.0059 - val_loss: 0.0068\n",
      "time: 95.73524522781372\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 87)                10092     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                5104      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                1711      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 87)                5133      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 115)               10120     \n",
      "=================================================================\n",
      "Total params: 33,900\n",
      "Trainable params: 33,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = deep_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",monitor='val_loss',save_best_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_opt, X_opt),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8581909450719182\n",
      "Precision 0.9867506231142594\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20516   202]\n",
      " [ 5674 15044]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8602181677768125\n",
      "Precision 0.9922173855691861\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20600   118]\n",
      " [ 5674 15044]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.8608939086784438\n",
      "Precision 0.9940531254129774\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20628    90]\n",
      " [ 5674 15044]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8613041799401486\n",
      "Precision 0.9951709995369452\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20645    73]\n",
      " [ 5674 15044]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8615455159764456\n",
      "Precision 0.9958297477990335\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20655    63]\n",
      " [ 5674 15044]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8618592528236316\n",
      "Precision 0.996687425467073\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20668    50]\n",
      " [ 5674 15044]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8619799208417801\n",
      "Precision 0.9970176950096097\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20673    45]\n",
      " [ 5674 15044]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8621247224635583\n",
      "Precision 0.9974143074985082\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20679    39]\n",
      " [ 5674 15044]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8622453904817067\n",
      "Precision 0.9977450590263961\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20684    34]\n",
      " [ 5674 15044]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8623660584998551\n",
      "Precision 0.9980760299873946\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20689    29]\n",
      " [ 5674 15044]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.862462592914374\n",
      "Precision 0.9983409648948172\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20693    25]\n",
      " [ 5674 15044]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.862462592914374\n",
      "Precision 0.9983409648948172\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20693    25]\n",
      " [ 5674 15044]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8625832609325225\n",
      "Precision 0.998672331386086\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20698    20]\n",
      " [ 5674 15044]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8626315281397818\n",
      "Precision 0.9988049395830567\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20700    18]\n",
      " [ 5674 15044]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8626315281397818\n",
      "Precision 0.9988049395830567\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20700    18]\n",
      " [ 5674 15044]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9990702616549343\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20704    14]\n",
      " [ 5674 15044]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9990702616549343\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20704    14]\n",
      " [ 5674 15044]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9990702616549343\n",
      "Recall 0.7261318660102326\n",
      "Confusion Matrix [[20704    14]\n",
      " [ 5674 15044]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.99907019990702\n",
      "Recall 0.7260835988029732\n",
      "Confusion Matrix [[20704    14]\n",
      " [ 5675 15043]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9991364995018266\n",
      "Recall 0.7260353315957139\n",
      "Confusion Matrix [[20705    13]\n",
      " [ 5676 15042]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9992028696691909\n",
      "Recall 0.7260353315957139\n",
      "Confusion Matrix [[20706    12]\n",
      " [ 5676 15042]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9992028696691909\n",
      "Recall 0.7260353315957139\n",
      "Confusion Matrix [[20706    12]\n",
      " [ 5676 15042]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.999335636460271\n",
      "Recall 0.7260353315957139\n",
      "Confusion Matrix [[20708    10]\n",
      " [ 5676 15042]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.999335636460271\n",
      "Recall 0.7260353315957139\n",
      "Confusion Matrix [[20708    10]\n",
      " [ 5676 15042]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8628004633651897\n",
      "Precision 0.9994020330875025\n",
      "Recall 0.7260353315957139\n",
      "Confusion Matrix [[20709     9]\n",
      " [ 5676 15042]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.9994019933554817\n",
      "Recall 0.7259870643884545\n",
      "Confusion Matrix [[20709     9]\n",
      " [ 5677 15041]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.9994019933554817\n",
      "Recall 0.7259870643884545\n",
      "Confusion Matrix [[20709     9]\n",
      " [ 5677 15041]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.9994019933554817\n",
      "Recall 0.7259870643884545\n",
      "Confusion Matrix [[20709     9]\n",
      " [ 5677 15041]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.9994019933554817\n",
      "Recall 0.7259870643884545\n",
      "Confusion Matrix [[20709     9]\n",
      " [ 5677 15041]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        \n",
    "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 25\n",
      "Treshold  1.578039503722731\n",
      "Accuracy  0.8619316536345207\n",
      "Precision  0.9996002398560864\n",
      "Recall 0.7241529105125978\n",
      "Confusion Matrix [[20712     6]\n",
      " [ 5715 15003]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "deep_tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "deep_acc = accuracy_score(Y_test, Y_pred)\n",
    "deep_precision = precision_score(Y_test, Y_pred)\n",
    "deep_recall = recall_score(Y_test, Y_pred)\n",
    "deep_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',deep_acc)\n",
    "print('Precision ',deep_precision)\n",
    "print(\"Recall\",deep_recall)\n",
    "print('Confusion Matrix',deep_cm)\n",
    "   \n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_dim):\n",
    "    original_dim = input_dim\n",
    "    intermediate_dim = 64\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    from keras import backend as K\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    return Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "648/648 [==============================] - 3s 3ms/step - loss: 0.7493 - val_loss: 0.5556\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5603 - val_loss: 0.5428\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5356 - val_loss: 0.5415\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5600 - val_loss: 0.5404\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5748 - val_loss: 0.5388\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5600 - val_loss: 0.5370\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5713 - val_loss: 0.5362\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5533 - val_loss: 0.5355\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5524 - val_loss: 0.5355\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5587 - val_loss: 0.5349\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5451 - val_loss: 0.5342\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5503 - val_loss: 0.5341\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5445 - val_loss: 0.5334\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5561 - val_loss: 0.5331\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5406 - val_loss: 0.5332\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5396 - val_loss: 0.5328\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5313 - val_loss: 0.5327\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5391 - val_loss: 0.5323\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5460 - val_loss: 0.5324\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5443 - val_loss: 0.5322\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.5322\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5669 - val_loss: 0.5319\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5487 - val_loss: 0.5321\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5666 - val_loss: 0.5316\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5429 - val_loss: 0.5317\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5746 - val_loss: 0.5316\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5558 - val_loss: 0.5314\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5453 - val_loss: 0.5318\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5557 - val_loss: 0.5313\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5407 - val_loss: 0.5315\n",
      "Epoch 31/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5383 - val_loss: 0.5312\n",
      "Epoch 32/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5649 - val_loss: 0.5316\n",
      "Epoch 33/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5701 - val_loss: 0.5313\n",
      "Epoch 34/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5309 - val_loss: 0.5312\n",
      "Epoch 35/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5585 - val_loss: 0.5314\n",
      "Epoch 36/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5448 - val_loss: 0.5315\n",
      "Epoch 37/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5581 - val_loss: 0.5311\n",
      "Epoch 38/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5551 - val_loss: 0.5311\n",
      "Epoch 39/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5405 - val_loss: 0.5312\n",
      "Epoch 40/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5779 - val_loss: 0.5310\n",
      "Epoch 41/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5470 - val_loss: 0.5310\n",
      "Epoch 42/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5455 - val_loss: 0.5309\n",
      "Epoch 43/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5420 - val_loss: 0.5310\n",
      "Epoch 44/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5418 - val_loss: 0.5309\n",
      "Epoch 45/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5310 - val_loss: 0.5311\n",
      "Epoch 46/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5669 - val_loss: 0.5311\n",
      "Epoch 47/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5572 - val_loss: 0.5309\n",
      "Epoch 48/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5614 - val_loss: 0.5311\n",
      "Epoch 49/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5535 - val_loss: 0.5311\n",
      "time: 81.31214737892151\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 2), (None, 2), (N 7684      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 115)               7667      \n",
      "=================================================================\n",
      "Total params: 15,351\n",
      "Trainable params: 15,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = vae_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_vae.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9898397528718988\n",
      "Precision 0.9800842045508302\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20297   421]\n",
      " [    0 20718]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9919393763876823\n",
      "Precision 0.9842725458519433\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20387   331]\n",
      " [    3 20715]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9936769958490201\n",
      "Precision 0.9876513778964432\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20459   259]\n",
      " [    3 20715]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9979003764842166\n",
      "Precision 0.9960567444097139\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20636    82]\n",
      " [    5 20713]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9979969108987354\n",
      "Precision 0.9962483767014574\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20640    78]\n",
      " [    5 20713]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9980934453132542\n",
      "Precision 0.9964400827440227\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20644    74]\n",
      " [    5 20713]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9981417125205135\n",
      "Precision 0.996583746331136\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20647    71]\n",
      " [    6 20712]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9981658461241433\n",
      "Precision 0.9966317005100568\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20648    70]\n",
      " [    6 20712]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9983589149531809\n",
      "Precision 0.9970155001444113\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20656    62]\n",
      " [    6 20712]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9985519837822183\n",
      "Precision 0.9974475052976305\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20665    53]\n",
      " [    7 20711]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9986002509894778\n",
      "Precision 0.9975435892495906\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20667    51]\n",
      " [    7 20711]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9986002509894778\n",
      "Precision 0.9975915221579962\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20668    50]\n",
      " [    8 20710]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9986243845931074\n",
      "Precision 0.9976395780143552\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20669    49]\n",
      " [    8 20710]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9987691862148856\n",
      "Precision 0.9979280104081337\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20675    43]\n",
      " [    8 20710]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9987450526112559\n",
      "Precision 0.9979279105628374\n",
      "Recall 0.9995655951346655\n",
      "Confusion Matrix [[20675    43]\n",
      " [    9 20709]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.999734007181806\n",
      "Recall 0.7256491939376387\n",
      "Confusion Matrix [[20714     4]\n",
      " [ 5684 15034]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.999733989492585\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20714     4]\n",
      " [ 5685 15033]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9998004655803127\n",
      "Recall 0.72555265952312\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5686 15032]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8626556617434116\n",
      "Precision 0.999800439034125\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5688 15030]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8626556617434116\n",
      "Precision 0.999800439034125\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5688 15030]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9999334708269576\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20717     1]\n",
      " [ 5688 15030]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9999334708269576\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20717     1]\n",
      " [ 5688 15030]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 14\n",
      "Treshold  21.932330019647857\n",
      "Accuracy  0.998503716574959\n",
      "Precision  0.9973514398536069\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20663    55]\n",
      " [    7 20711]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "vae_acc = accuracy_score(Y_test, Y_pred)\n",
    "vae_precision = precision_score(Y_test, Y_pred)\n",
    "vae_recall = recall_score(Y_test, Y_pred)\n",
    "vae_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',vae_acc)\n",
    "print('Precision ',vae_precision)\n",
    "print(\"Recall\",vae_recall)\n",
    "print('Confusion Matrix',vae_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(15, activation='relu')(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.7740 - val_loss: 0.5488\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5512 - val_loss: 0.5362\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5470 - val_loss: 0.5309\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5490 - val_loss: 0.5279\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5408 - val_loss: 0.5268\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5428 - val_loss: 0.5259\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5487 - val_loss: 0.5254\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5469 - val_loss: 0.5250\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5497 - val_loss: 0.5248\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5579 - val_loss: 0.5246\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5640 - val_loss: 0.5244\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5571 - val_loss: 0.5243\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5527 - val_loss: 0.5242\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5395 - val_loss: 0.5241\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5452 - val_loss: 0.5238\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5290 - val_loss: 0.5237\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5783 - val_loss: 0.5237\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5309 - val_loss: 0.5237\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5408 - val_loss: 0.5236\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5474 - val_loss: 0.5236\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5276 - val_loss: 0.5236\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5377 - val_loss: 0.5236\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5430 - val_loss: 0.5235\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5367 - val_loss: 0.5235\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5529 - val_loss: 0.5235\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5220 - val_loss: 0.5234\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5337 - val_loss: 0.5234\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5324 - val_loss: 0.5234\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5436 - val_loss: 0.5234\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5112 - val_loss: 0.5234\n",
      "Epoch 31/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5627 - val_loss: 0.5234\n",
      "Epoch 32/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5575 - val_loss: 0.5234\n",
      "Epoch 33/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5355 - val_loss: 0.5233\n",
      "Epoch 34/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5612 - val_loss: 0.5233\n",
      "Epoch 35/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5314 - val_loss: 0.5232\n",
      "Epoch 36/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5478 - val_loss: 0.5232\n",
      "Epoch 37/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5413 - val_loss: 0.5232\n",
      "Epoch 38/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5480 - val_loss: 0.5232\n",
      "Epoch 39/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5533 - val_loss: 0.5232\n",
      "Epoch 40/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5326 - val_loss: 0.5231\n",
      "Epoch 41/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5514 - val_loss: 0.5231\n",
      "Epoch 42/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5501 - val_loss: 0.5231\n",
      "Epoch 43/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5485 - val_loss: 0.5231\n",
      "Epoch 44/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5450 - val_loss: 0.5231\n",
      "Epoch 45/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5498 - val_loss: 0.5231\n",
      "Epoch 46/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5731 - val_loss: 0.5230\n",
      "Epoch 47/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5428 - val_loss: 0.5230\n",
      "Epoch 48/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5361 - val_loss: 0.5230\n",
      "Epoch 49/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5189 - val_loss: 0.5230\n",
      "Epoch 50/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5587 - val_loss: 0.5230\n",
      "Epoch 51/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5362 - val_loss: 0.5230\n",
      "Epoch 52/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5441 - val_loss: 0.5230\n",
      "Epoch 53/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5329 - val_loss: 0.5230\n",
      "Epoch 54/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5402 - val_loss: 0.5230\n",
      "Epoch 55/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5327 - val_loss: 0.5230\n",
      "Epoch 56/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5447 - val_loss: 0.5230\n",
      "Epoch 57/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5597 - val_loss: 0.5230\n",
      "Epoch 58/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5409 - val_loss: 0.5230\n",
      "Epoch 59/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5414 - val_loss: 0.5230\n",
      "Epoch 60/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5246 - val_loss: 0.5230\n",
      "Epoch 61/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5157 - val_loss: 0.5230\n",
      "Epoch 62/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5468 - val_loss: 0.5230\n",
      "Epoch 63/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5385 - val_loss: 0.5229\n",
      "Epoch 64/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.5229\n",
      "Epoch 65/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5591 - val_loss: 0.5230\n",
      "Epoch 66/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.5229\n",
      "Epoch 67/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5370 - val_loss: 0.5229\n",
      "Epoch 68/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.5229\n",
      "Epoch 69/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5387 - val_loss: 0.5230\n",
      "Epoch 70/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5261 - val_loss: 0.5229\n",
      "Epoch 71/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5372 - val_loss: 0.5229\n",
      "Epoch 72/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5409 - val_loss: 0.5229\n",
      "Epoch 73/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5558 - val_loss: 0.5229\n",
      "Epoch 74/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5465 - val_loss: 0.5229\n",
      "Epoch 75/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5452 - val_loss: 0.5229\n",
      "Epoch 76/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5352 - val_loss: 0.5229\n",
      "Epoch 77/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5310 - val_loss: 0.5229\n",
      "time: 120.64482426643372\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                1740      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 115)               1840      \n",
      "=================================================================\n",
      "Total params: 3,580\n",
      "Trainable params: 3,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = uc_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_undercomplete.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9898397528718988\n",
      "Precision 0.9800842045508302\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20297   421]\n",
      " [    0 20718]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9919393763876823\n",
      "Precision 0.9842725458519433\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20387   331]\n",
      " [    3 20715]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9935563278308717\n",
      "Precision 0.9874624588835391\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20455   263]\n",
      " [    4 20714]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9979727772951057\n",
      "Precision 0.9962004617160446\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20639    79]\n",
      " [    5 20713]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9979969108987354\n",
      "Precision 0.9962483767014574\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20640    78]\n",
      " [    5 20713]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9980693117096244\n",
      "Precision 0.99643991147888\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20644    74]\n",
      " [    6 20712]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9981658461241433\n",
      "Precision 0.9966317005100568\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20648    70]\n",
      " [    6 20712]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9981658461241433\n",
      "Precision 0.9966317005100568\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20648    70]\n",
      " [    6 20712]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9983830485568105\n",
      "Precision 0.9970634958840803\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20657    61]\n",
      " [    6 20712]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9985519837822183\n",
      "Precision 0.9974475052976305\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20665    53]\n",
      " [    7 20711]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9985761173858481\n",
      "Precision 0.9975434709310727\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20667    51]\n",
      " [    8 20710]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9986243845931074\n",
      "Precision 0.9976395780143552\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20669    49]\n",
      " [    8 20710]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9986726518003668\n",
      "Precision 0.9977357036180565\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20671    47]\n",
      " [    8 20710]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9987691862148856\n",
      "Precision 0.9979280104081337\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20675    43]\n",
      " [    8 20710]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9987209190076263\n",
      "Precision 0.9979278107079177\n",
      "Recall 0.9995173279274061\n",
      "Confusion Matrix [[20675    43]\n",
      " [   10 20708]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.999734007181806\n",
      "Recall 0.7256491939376387\n",
      "Confusion Matrix [[20714     4]\n",
      " [ 5684 15034]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.999733989492585\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20714     4]\n",
      " [ 5685 15033]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9998004655803127\n",
      "Recall 0.72555265952312\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5686 15032]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8626556617434116\n",
      "Precision 0.999800439034125\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5688 15030]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.999866950505588\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20716     2]\n",
      " [ 5688 15030]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9999334708269576\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20717     1]\n",
      " [ 5688 15030]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9999334708269576\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20717     1]\n",
      " [ 5688 15030]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 14\n",
      "Treshold  21.84994911197151\n",
      "Accuracy  0.998503716574959\n",
      "Precision  0.9973514398536069\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20663    55]\n",
      " [    7 20711]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "uc_acc = accuracy_score(Y_test, Y_pred)\n",
    "uc_precision = precision_score(Y_test, Y_pred)\n",
    "uc_recall = recall_score(Y_test, Y_pred)\n",
    "uc_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',uc_acc)\n",
    "print('Precision ',uc_precision)\n",
    "print(\"Recall\",uc_recall)\n",
    "print('Confusion Matrix',uc_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(200, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-6))(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.6424 - val_loss: 0.5300\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 3s 5ms/step - loss: 0.5368 - val_loss: 0.5266\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5298 - val_loss: 0.5255\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5580 - val_loss: 0.5249\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5456 - val_loss: 0.5245\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5318 - val_loss: 0.5241\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5296 - val_loss: 0.5239\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5278 - val_loss: 0.5236\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5529 - val_loss: 0.5235\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5399 - val_loss: 0.5234\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5436 - val_loss: 0.5233\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5332 - val_loss: 0.5232\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5376 - val_loss: 0.5231\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5413 - val_loss: 0.5231\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5356 - val_loss: 0.5231\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5435 - val_loss: 0.5231\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5305 - val_loss: 0.5230\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5495 - val_loss: 0.5229\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5430 - val_loss: 0.5229\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5629 - val_loss: 0.5229\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5336 - val_loss: 0.5229\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5479 - val_loss: 0.5228\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5604 - val_loss: 0.5228\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5374 - val_loss: 0.5230\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5436 - val_loss: 0.5228\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5291 - val_loss: 0.5227\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5327 - val_loss: 0.5227\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 3s 5ms/step - loss: 0.5548 - val_loss: 0.5227\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5504 - val_loss: 0.5228\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5191 - val_loss: 0.5227\n",
      "Epoch 31/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5222 - val_loss: 0.5228\n",
      "Epoch 32/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5477 - val_loss: 0.5227\n",
      "Epoch 33/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5432 - val_loss: 0.5229\n",
      "Epoch 34/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5216 - val_loss: 0.5227\n",
      "Epoch 35/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5438 - val_loss: 0.5227\n",
      "Epoch 36/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5322 - val_loss: 0.5226\n",
      "Epoch 37/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5520 - val_loss: 0.5226\n",
      "Epoch 38/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5354 - val_loss: 0.5226\n",
      "Epoch 39/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5399 - val_loss: 0.5226\n",
      "Epoch 40/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5229 - val_loss: 0.5227\n",
      "Epoch 41/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5493 - val_loss: 0.5226\n",
      "Epoch 42/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5205 - val_loss: 0.5226\n",
      "Epoch 43/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5528 - val_loss: 0.5226\n",
      "Epoch 44/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5362 - val_loss: 0.5226\n",
      "Epoch 45/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5324 - val_loss: 0.5226\n",
      "Epoch 46/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5454 - val_loss: 0.5226\n",
      "Epoch 47/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5472 - val_loss: 0.5226\n",
      "Epoch 48/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.5533 - val_loss: 0.5226\n",
      "Epoch 49/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5505 - val_loss: 0.5226\n",
      "Epoch 50/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5443 - val_loss: 0.5227\n",
      "Epoch 51/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5580 - val_loss: 0.5226\n",
      "Epoch 52/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5301 - val_loss: 0.5226\n",
      "Epoch 53/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5527 - val_loss: 0.5225\n",
      "Epoch 54/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5430 - val_loss: 0.5226\n",
      "Epoch 55/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5469 - val_loss: 0.5225\n",
      "Epoch 56/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5482 - val_loss: 0.5225\n",
      "Epoch 57/100\n",
      "648/648 [==============================] - 2s 2ms/step - loss: 0.5457 - val_loss: 0.5225\n",
      "Epoch 58/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5479 - val_loss: 0.5225\n",
      "Epoch 59/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5179 - val_loss: 0.5225\n",
      "Epoch 60/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5519 - val_loss: 0.5225\n",
      "Epoch 61/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5444 - val_loss: 0.5225\n",
      "Epoch 62/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5308 - val_loss: 0.5229\n",
      "Epoch 63/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5337 - val_loss: 0.5225\n",
      "Epoch 64/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5557 - val_loss: 0.5227\n",
      "Epoch 65/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.5490 - val_loss: 0.5225\n",
      "Epoch 66/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5513 - val_loss: 0.5225\n",
      "time: 139.64111018180847\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               23200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 115)               23115     \n",
      "=================================================================\n",
      "Total params: 46,315\n",
      "Trainable params: 46,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = sparse_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9899604208900473\n",
      "Precision 0.9803160783571496\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20302   416]\n",
      " [    0 20718]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9919876435949416\n",
      "Precision 0.9843660900969398\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20389   329]\n",
      " [    3 20715]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9938217974707984\n",
      "Precision 0.9879339946585273\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20465   253]\n",
      " [    3 20715]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9979727772951057\n",
      "Precision 0.9962004617160446\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20639    79]\n",
      " [    5 20713]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9979969108987354\n",
      "Precision 0.9962483767014574\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20640    78]\n",
      " [    5 20713]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9980934453132542\n",
      "Precision 0.9964400827440227\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20644    74]\n",
      " [    5 20713]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9981658461241433\n",
      "Precision 0.9966317005100568\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20648    70]\n",
      " [    6 20712]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9981658461241433\n",
      "Precision 0.9966317005100568\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20648    70]\n",
      " [    6 20712]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9984554493676996\n",
      "Precision 0.9972075108329321\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20660    58]\n",
      " [    6 20712]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9985761173858481\n",
      "Precision 0.9974476282205634\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20665    53]\n",
      " [    6 20712]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9986243845931074\n",
      "Precision 0.9975437075567115\n",
      "Recall 0.9997103967564437\n",
      "Confusion Matrix [[20667    51]\n",
      " [    6 20712]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9986485181967372\n",
      "Precision 0.9976396917148362\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20669    49]\n",
      " [    7 20711]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9986726518003668\n",
      "Precision 0.9977357036180565\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20671    47]\n",
      " [    8 20710]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9987691862148856\n",
      "Precision 0.9979280104081337\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20675    43]\n",
      " [    8 20710]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.9987691862148856\n",
      "Precision 0.9979280104081337\n",
      "Recall 0.9996138623419248\n",
      "Confusion Matrix [[20675    43]\n",
      " [    8 20710]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.86277632976156\n",
      "Precision 0.9997340425531915\n",
      "Recall 0.7257457283521576\n",
      "Confusion Matrix [[20714     4]\n",
      " [ 5682 15036]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.999734007181806\n",
      "Recall 0.7256491939376387\n",
      "Confusion Matrix [[20714     4]\n",
      " [ 5684 15034]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8627521961579303\n",
      "Precision 0.9998004921194387\n",
      "Recall 0.7256491939376387\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5684 15034]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9998004788507582\n",
      "Recall 0.7256009267303793\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5685 15033]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9998004655803127\n",
      "Recall 0.72555265952312\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5686 15032]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8626797953470412\n",
      "Precision 0.9998004523081017\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20715     3]\n",
      " [ 5687 15031]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9998669593560833\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20716     2]\n",
      " [ 5687 15031]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8627280625543006\n",
      "Precision 0.9999334752527941\n",
      "Recall 0.7255043923158606\n",
      "Confusion Matrix [[20717     1]\n",
      " [ 5687 15031]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8627039289506709\n",
      "Precision 0.9999334708269576\n",
      "Recall 0.7254561251086012\n",
      "Confusion Matrix [[20717     1]\n",
      " [ 5688 15030]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 14\n",
      "Treshold  22.015404721704265\n",
      "Accuracy  0.998503716574959\n",
      "Precision  0.9973514398536069\n",
      "Recall 0.9996621295491843\n",
      "Confusion Matrix [[20663    55]\n",
      " [    7 20711]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "sparse_acc = accuracy_score(Y_test, Y_pred)\n",
    "sparse_precision = precision_score(Y_test, Y_pred)\n",
    "sparse_recall = recall_score(Y_test, Y_pred)\n",
    "sparse_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',sparse_acc)\n",
    "print('Precision ',sparse_precision)\n",
    "print(\"Recall\",sparse_recall)\n",
    "print('Confusion Matrix',sparse_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_model(input_dim):\n",
    "    input_size = input_dim\n",
    "    hidden_size = 44\n",
    "    code_size = 5\n",
    "\n",
    "    input_img = Input(shape=(input_size,))\n",
    "    hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "    code = Dense(code_size, activation='relu')(hidden_1)\n",
    "    hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "    output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "    autoencoder = Model(input_img, output_img)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "648/648 [==============================] - 4s 5ms/step - loss: 0.8911 - val_loss: 0.6272\n",
      "Epoch 2/100\n",
      "648/648 [==============================] - 3s 4ms/step - loss: 0.6542 - val_loss: 0.6161\n",
      "Epoch 3/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.6165 - val_loss: 0.5908\n",
      "Epoch 4/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.6033 - val_loss: 0.5879\n",
      "Epoch 5/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5890 - val_loss: 0.5844\n",
      "Epoch 6/100\n",
      "648/648 [==============================] - 2s 4ms/step - loss: 0.5937 - val_loss: 0.5831\n",
      "Epoch 7/100\n",
      "648/648 [==============================] - 2s 3ms/step - loss: 0.6152 - val_loss: 0.5818\n",
      "Epoch 8/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.5816\n",
      "Epoch 9/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6093 - val_loss: 0.5812\n",
      "Epoch 10/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5984 - val_loss: 0.5811\n",
      "Epoch 11/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5796 - val_loss: 0.5830\n",
      "Epoch 12/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5928 - val_loss: 0.5811\n",
      "Epoch 13/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6015 - val_loss: 0.5839\n",
      "Epoch 14/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6041 - val_loss: 0.5846\n",
      "Epoch 15/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6010 - val_loss: 0.5798\n",
      "Epoch 16/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6095 - val_loss: 0.5808\n",
      "Epoch 17/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6100 - val_loss: 0.5797\n",
      "Epoch 18/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5728 - val_loss: 0.5782\n",
      "Epoch 19/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5719 - val_loss: 0.5767\n",
      "Epoch 20/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6042 - val_loss: 0.5769\n",
      "Epoch 21/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6086 - val_loss: 0.5763\n",
      "Epoch 22/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5782 - val_loss: 0.5812\n",
      "Epoch 23/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5942 - val_loss: 0.5778\n",
      "Epoch 24/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6188 - val_loss: 0.5780\n",
      "Epoch 25/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5984 - val_loss: 0.5760\n",
      "Epoch 26/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5687 - val_loss: 0.5761\n",
      "Epoch 27/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.5761\n",
      "Epoch 28/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5838 - val_loss: 0.5765\n",
      "Epoch 29/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.6131 - val_loss: 0.5763\n",
      "Epoch 30/100\n",
      "648/648 [==============================] - 1s 2ms/step - loss: 0.5986 - val_loss: 0.5835\n",
      "time: 49.46366810798645\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 44)                5104      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 225       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 44)                264       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 115)               5175      \n",
      "=================================================================\n",
      "Total params: 10,768\n",
      "Trainable params: 10,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "x_opt_noisy = np.clip(x_opt_noisy, 0., 1.)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "#x_train_noisy = scaler.fit_transform(x_train_noisy)\n",
    "#x_opt_noisy = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#call function to create the model\n",
    "model = denoise_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(x_train_noisy, X_train,\n",
    "                    epochs=epochs, validation_data=(x_opt_noisy, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.5544454097885896\n",
      "Precision 0.5287901990811639\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 2256 18462]\n",
      " [    0 20718]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.635172313929916\n",
      "Precision 0.5781498534951862\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 5601 15117]\n",
      " [    0 20718]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.7308861859252823\n",
      "Precision 0.6500988421349901\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 9567 11151]\n",
      " [    0 20718]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.81151655565209\n",
      "Precision 0.7262338754907459\n",
      "Recall 1.0\n",
      "Confusion Matrix [[12908  7810]\n",
      " [    0 20718]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.870812819770248\n",
      "Precision 0.794676076867017\n",
      "Recall 1.0\n",
      "Confusion Matrix [[15365  5353]\n",
      " [    0 20718]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9128052900859156\n",
      "Precision 0.8515063088241338\n",
      "Recall 1.0\n",
      "Confusion Matrix [[17105  3613]\n",
      " [    0 20718]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9401245293947292\n",
      "Precision 0.8930557351609983\n",
      "Recall 1.0\n",
      "Confusion Matrix [[18237  2481]\n",
      " [    0 20718]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9594555459021141\n",
      "Precision 0.9249933029734798\n",
      "Recall 1.0\n",
      "Confusion Matrix [[19038  1680]\n",
      " [    0 20718]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9728979631238537\n",
      "Precision 0.9485829403415594\n",
      "Recall 1.0\n",
      "Confusion Matrix [[19595  1123]\n",
      " [    0 20718]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9813688579978762\n",
      "Precision 0.9640763145649139\n",
      "Recall 1.0\n",
      "Confusion Matrix [[19946   772]\n",
      " [    0 20718]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.9860749107056666\n",
      "Precision 0.9729044376614229\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20141   577]\n",
      " [    0 20718]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.9887778743121923\n",
      "Precision 0.9780484350658547\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20253   465]\n",
      " [    0 20718]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.9903224249444927\n",
      "Precision 0.9810123585397036\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20317   401]\n",
      " [    0 20718]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.9910705666570132\n",
      "Precision 0.9824544764795144\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20348   370]\n",
      " [    0 20718]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.991480837918718\n",
      "Precision 0.983247116890513\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20365   353]\n",
      " [    0 20718]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.9916015059368665\n",
      "Precision 0.9834804898889206\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20370   348]\n",
      " [    0 20718]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.9917463075586447\n",
      "Precision 0.9837606837606837\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20376   342]\n",
      " [    0 20718]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.9918187083695338\n",
      "Precision 0.9839468059843267\n",
      "Recall 0.9999517327927406\n",
      "Confusion Matrix [[20380   338]\n",
      " [    1 20717]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.9921807124239791\n",
      "Precision 0.9846482889733841\n",
      "Recall 0.9999517327927406\n",
      "Confusion Matrix [[20395   323]\n",
      " [    1 20717]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.9924944492711651\n",
      "Precision 0.9853493792512962\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20410   308]\n",
      " [    3 20715]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.9928564533256106\n",
      "Precision 0.9860529322162985\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20425   293]\n",
      " [    3 20715]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.9936528622453905\n",
      "Precision 0.9876042908224076\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20458   260]\n",
      " [    3 20715]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.9944492711651703\n",
      "Precision 0.9891605386305033\n",
      "Recall 0.9998551983782218\n",
      "Confusion Matrix [[20491   227]\n",
      " [    3 20715]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.994956076841394\n",
      "Precision 0.9902002963812802\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20513   205]\n",
      " [    4 20714]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.9956076841393957\n",
      "Precision 0.9914799923415661\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20540   178]\n",
      " [    4 20714]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.9961144898156192\n",
      "Precision 0.992477600498299\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20561   157]\n",
      " [    4 20714]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.9966212954918429\n",
      "Precision 0.9934772182254197\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20582   136]\n",
      " [    4 20714]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.996766097113621\n",
      "Precision 0.9937631932450586\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20588   130]\n",
      " [    4 20714]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.9970557003571774\n",
      "Precision 0.9943356374807988\n",
      "Recall 0.9998069311709624\n",
      "Confusion Matrix [[20600   118]\n",
      " [    4 20714]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(x_opt_noisy)\n",
    "mse = np.mean(np.power(x_opt_noisy - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "X_opt_scaled = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 29\n",
      "Treshold  6.948382496385761\n",
      "Accuracy  0.9998551983782218\n",
      "Precision  0.9999517234720479\n",
      "Recall 0.999758663963703\n",
      "Confusion Matrix [[20717     1]\n",
      " [    5 20713]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(x_test_noisy, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=20)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "X_test_scaled = scaler.transform(x_test_noisy)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "denoise_acc = accuracy_score(Y_test, Y_pred)\n",
    "denoise_precision = precision_score(Y_test, Y_pred)\n",
    "denoise_recall = recall_score(Y_test, Y_pred)\n",
    "denoise_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',denoise_acc)\n",
    "print('Precision ',denoise_precision)\n",
    "print(\"Recall\",denoise_recall)\n",
    "print('Confusion Matrix',denoise_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(80, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Dense(labels.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, callbacks=[monitor], patience=5) \n",
    "    model.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n",
    "          verbose=1,epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 1\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 0\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))\n",
    "\n",
    "X = df_ben.drop(columns=['class'])\n",
    "y = df_ben['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=17)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2210/2210 [==============================] - 6s 2ms/step - loss: 0.0079\n",
      "Epoch 2/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 9.4961e-04A\n",
      "Epoch 3/100\n",
      "2210/2210 [==============================] - 4s 2ms/step - loss: 0.0010\n",
      "Epoch 4/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 4.0130e-04\n",
      "Epoch 5/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 7.5083e-04\n",
      "Epoch 6/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 6.8843e-04\n",
      "Epoch 7/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 0.0012\n",
      "Epoch 8/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 7.9905e-04\n",
      "Epoch 9/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 8.9063e-04\n",
      "Epoch 10/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 8.3752e-04\n",
      "Epoch 11/100\n",
      "2210/2210 [==============================] - 5s 2ms/step - loss: 0.0011\n",
      "Epoch 12/100\n",
      "2210/2210 [==============================] - 4s 2ms/step - loss: 4.5061e-04\n",
      "Epoch 13/100\n",
      "2210/2210 [==============================] - 3s 1ms/step - loss: 8.5606e-04\n",
      "Epoch 14/100\n",
      "2210/2210 [==============================] - 3s 1ms/step - loss: 6.6964e-04\n",
      "Epoch 15/100\n",
      "2210/2210 [==============================] - 4s 2ms/step - loss: 0.0015\n",
      "Epoch 16/100\n",
      "2210/2210 [==============================] - 3s 1ms/step - loss: 9.3076e-04\n",
      "Epoch 17/100\n",
      "2210/2210 [==============================] - 3s 1ms/step - loss: 4.8572e-04\n",
      "time 73.55029034614563\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_dim=115, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "\n",
    "#compile and fit model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=15,callbacks=[es])\n",
    "\n",
    "end = time.time()\n",
    "print(\"time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9987934362934363\n",
      "Precision  0.9978406909788867\n",
      "Recall 0.9997596153846153\n",
      "Confusion Matrix [[4119    9]\n",
      " [   1 4159]]\n"
     ]
    }
   ],
   "source": [
    "dnn_acc = accuracy_score(y_test, y_pred)\n",
    "dnn_precision = precision_score(y_test, y_pred)\n",
    "dnn_recall = recall_score(y_test, y_pred)\n",
    "dnn_cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy ',dnn_acc)\n",
    "print('Precision ',dnn_precision)\n",
    "print(\"Recall\",dnn_recall)\n",
    "print('Confusion Matrix',dnn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provision PT_737E Security Camera\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>CM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep AutoEncoder</td>\n",
       "      <td>0.861932</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.724153</td>\n",
       "      <td>[[20712, 6], [5715, 15003]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variational AutoEncoder</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.997351</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>[[20663, 55], [7, 20711]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse AutoEncoder</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.997351</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>[[20663, 55], [7, 20711]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undercomplete Autoencoder</td>\n",
       "      <td>0.998504</td>\n",
       "      <td>0.997351</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>[[20663, 55], [7, 20711]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denoising Autoendoer</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.999759</td>\n",
       "      <td>[[20717, 1], [5, 20713]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  \\\n",
       "0           Deep AutoEncoder  0.861932   0.999600  0.724153   \n",
       "1    Variational AutoEncoder  0.998504   0.997351  0.999662   \n",
       "2         Sparse AutoEncoder  0.998504   0.997351  0.999662   \n",
       "3  Undercomplete Autoencoder  0.998504   0.997351  0.999662   \n",
       "4       Denoising Autoendoer  0.999855   0.999952  0.999759   \n",
       "\n",
       "                            CM  \n",
       "0  [[20712, 6], [5715, 15003]]  \n",
       "1    [[20663, 55], [7, 20711]]  \n",
       "2    [[20663, 55], [7, 20711]]  \n",
       "3    [[20663, 55], [7, 20711]]  \n",
       "4     [[20717, 1], [5, 20713]]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Provision PT_737E Security Camera\")\n",
    "model_summary = pd.DataFrame({'Model' :['Deep AutoEncoder',\"Variational AutoEncoder\",\"Sparse AutoEncoder\",\"Undercomplete Autoencoder\",\"Denoising Autoendoer\"],\n",
    "                             'Accuracy':[deep_acc,vae_acc,sparse_acc,uc_acc,denoise_acc],\n",
    "                             'Precision':[deep_precision,vae_precision,sparse_precision,uc_precision,denoise_precision],\n",
    "                             'Recall':[deep_recall,vae_recall,sparse_recall,uc_recall,denoise_recall],\n",
    "                             'CM':[deep_cm,vae_cm,sparse_cm,uc_cm, denoise_cm]})\n",
    "model_summary.sort_values(by='Accuracy', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
