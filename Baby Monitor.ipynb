{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=pd.read_csv(\"BabyMonitor/benign_traffic.csv\")\n",
    "x_train, x_opt, x_test = np.split(benign.sample(frac=1, random_state=20), [int(1/3*len(benign)), int(2/3*len(benign))])\n",
    "\n",
    "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('BabyMonitor/mirai/*.csv', recursive=False)), ignore_index=True)\n",
    "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('BabyMonitor/gafgyt/*.csv', recursive=False)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 'malicious'\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 'benign'\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting samples of benign and malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n = 2000\n",
    "atk = df_attack.sample(n=plot_n, random_state=76)\n",
    "nrm = x_train.sample(n=plot_n, random_state=42)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
    "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
    "\n",
    "plt.xlabel('MI_dir_L0.1_weight')\n",
    "plt.ylabel('MI_dir_L1_weight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'MI_dir_L0.1_weight', 'score': 1.2260028446133084},\n",
       " {'feature': 'H_L0.1_weight', 'score': 1.2260027979952752},\n",
       " {'feature': 'MI_dir_L1_weight', 'score': 1.2051623975391526},\n",
       " {'feature': 'H_L1_weight', 'score': 1.2051620764007813},\n",
       " {'feature': 'MI_dir_L3_weight', 'score': 1.202508947596725}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['benign','malicious']\n",
    "scored = []\n",
    "indices = {}\n",
    "shps = {}\n",
    "\n",
    "#classifying benign as true and attack as false\n",
    "for cl in classes:\n",
    "    indices[cl] = df_ben['class'] == cl    \n",
    "    shps[cl] =  df_ben[indices[cl]].shape[0]\n",
    "        \n",
    "for col in df_ben.columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "    num = 0\n",
    "    den = 0\n",
    "    m = df_ben[col].mean()\n",
    "    \n",
    "    for cl in classes:\n",
    "        num += (shps[cl] / df_ben.shape[0]) * (m - df_ben[indices[cl]][col].mean())**2\n",
    "        den += (shps[cl] / df_ben.shape[0]) * df_ben[indices[cl]][col].var()\n",
    "    score = {'feature': col, 'score': num / den}\n",
    "    scored.append(score)\n",
    "    #print(score)\n",
    "scored.sort(key=lambda x: x['score'], reverse=True)\n",
    "scored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    #initialize model\n",
    "    def __init__(self, model, threshold, scaler):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #predict the outcome using treshold\n",
    "    def predict(self, x):\n",
    "        x_pred = self.model.predict(x)\n",
    "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
    "        y_pred = mse > self.threshold\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    #scale the classes\n",
    "    def scale_predict_classes(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.predict(x)\n",
    "        classes_arr = []\n",
    "        for e in y_pred:\n",
    "            el = [0,0]\n",
    "            el[e] = 1\n",
    "            classes_arr.append(el)\n",
    "        print(classes_arr)\n",
    "\n",
    "        return np.array(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation - Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
    "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    return Model(inp, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 9s 4ms/step - loss: 0.4969 - val_loss: 0.1948\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.1651 - val_loss: 0.1582\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.1276 - val_loss: 0.1169\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0982 - val_loss: 0.1005\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0825 - val_loss: 0.0885\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0704 - val_loss: 0.0671\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.0610 - val_loss: 0.0778\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0562 - val_loss: 0.0655\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.0609 - val_loss: 0.0553\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0494 - val_loss: 0.0618\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0596 - val_loss: 0.0530\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0472 - val_loss: 0.0493\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0465 - val_loss: 0.0498\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0429 - val_loss: 0.0544\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0444 - val_loss: 0.0518\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0436 - val_loss: 0.0486\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0421 - val_loss: 0.0494\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0455 - val_loss: 0.0463\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0425 - val_loss: 0.0510\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0394 - val_loss: 0.0473\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 5s 2ms/step - loss: 0.0440 - val_loss: 0.0450\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0385 - val_loss: 0.0541\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0406 - val_loss: 0.0470\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0401 - val_loss: 0.0442\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0394 - val_loss: 0.0468\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0397 - val_loss: 0.0412\n",
      "Epoch 27/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0360 - val_loss: 0.0468\n",
      "Epoch 28/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0341 - val_loss: 0.0425\n",
      "Epoch 29/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0355 - val_loss: 0.0420\n",
      "Epoch 30/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.0341 - val_loss: 0.0421\n",
      "Epoch 31/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0328 - val_loss: 0.0406\n",
      "Epoch 32/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.0352 - val_loss: 0.0392\n",
      "Epoch 33/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0337 - val_loss: 0.0461\n",
      "Epoch 34/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0329 - val_loss: 0.0450\n",
      "Epoch 35/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0358 - val_loss: 0.0399\n",
      "Epoch 36/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0345 - val_loss: 0.0399\n",
      "Epoch 37/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0319 - val_loss: 0.0394\n",
      "time: 228.23825478553772\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 87)                10092     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 58)                5104      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 29)                1711      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 87)                5133      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 115)               10120     \n",
      "=================================================================\n",
      "Total params: 33,900\n",
      "Trainable params: 33,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = deep_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",monitor='val_loss',save_best_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_opt, X_opt),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9886155479088559\n",
      "Precision 0.9777699660188487\n",
      "Recall 0.9999657610463424\n",
      "Confusion Matrix [[57085  1328]\n",
      " [    2 58411]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8855819766147947\n",
      "Precision 0.9837621890974698\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[57657   756]\n",
      " [12611 45802]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.887893105986681\n",
      "Precision 0.989500518492914\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[57927   486]\n",
      " [12611 45802]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.8892712238713985\n",
      "Precision 0.9929756097560976\n",
      "Recall 0.7840891582353243\n",
      "Confusion Matrix [[58089   324]\n",
      " [12612 45801]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8901443171896667\n",
      "Precision 0.9951978444623106\n",
      "Recall 0.7840720387584955\n",
      "Confusion Matrix [[58192   221]\n",
      " [12613 45800]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8905637443719719\n",
      "Precision 0.9962585921865483\n",
      "Recall 0.7840720387584955\n",
      "Confusion Matrix [[58241   172]\n",
      " [12613 45800]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8909403728622053\n",
      "Precision 0.9972130290890089\n",
      "Recall 0.7840720387584955\n",
      "Confusion Matrix [[58285   128]\n",
      " [12613 45800]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8911372468457364\n",
      "Precision 0.9977126674654178\n",
      "Recall 0.7840720387584955\n",
      "Confusion Matrix [[58308   105]\n",
      " [12613 45800]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8913683597829251\n",
      "Precision 0.9982998387026462\n",
      "Recall 0.7840720387584955\n",
      "Confusion Matrix [[58335    78]\n",
      " [12613 45800]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8914796363823122\n",
      "Precision 0.9986045396070907\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58349    64]\n",
      " [12614 45799]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8915737935048705\n",
      "Precision 0.99886586695747\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58361    52]\n",
      " [12615 45798]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8916337116737713\n",
      "Precision 0.9990183888488974\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58368    45]\n",
      " [12615 45798]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8917021895810864\n",
      "Precision 0.9991927566270318\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58376    37]\n",
      " [12615 45798]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8917792272268159\n",
      "Precision 0.9993889931479946\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58385    28]\n",
      " [12615 45798]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8918391453957167\n",
      "Precision 0.9995416748510443\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58392    21]\n",
      " [12615 45798]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 0.9995634903313109\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58393    20]\n",
      " [12615 45798]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8918733843493742\n",
      "Precision 0.9996289424860854\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58396    17]\n",
      " [12615 45798]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918819440877886\n",
      "Precision 0.9996507617758764\n",
      "Recall 0.784037799804838\n",
      "Confusion Matrix [[58397    16]\n",
      " [12615 45798]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918990635646175\n",
      "Precision 0.9997380370241006\n",
      "Recall 0.7840035608511804\n",
      "Confusion Matrix [[58401    12]\n",
      " [12617 45796]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8919076233030319\n",
      "Precision 0.9997598620298208\n",
      "Recall 0.7840035608511804\n",
      "Confusion Matrix [[58402    11]\n",
      " [12617 45796]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8919076233030319\n",
      "Precision 0.9997598620298208\n",
      "Recall 0.7840035608511804\n",
      "Confusion Matrix [[58402    11]\n",
      " [12617 45796]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8919161830414463\n",
      "Precision 0.9997816879884731\n",
      "Recall 0.7840035608511804\n",
      "Confusion Matrix [[58403    10]\n",
      " [12617 45796]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8919161830414463\n",
      "Precision 0.9997816879884731\n",
      "Recall 0.7840035608511804\n",
      "Confusion Matrix [[58403    10]\n",
      " [12617 45796]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8919247427798607\n",
      "Precision 0.9998253389515971\n",
      "Recall 0.7839864413743516\n",
      "Confusion Matrix [[58405     8]\n",
      " [12618 45795]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8919161830414463\n",
      "Precision 0.9998253351382036\n",
      "Recall 0.7839693218975228\n",
      "Confusion Matrix [[58405     8]\n",
      " [12619 45794]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8919333025182751\n",
      "Precision 0.9998689956331878\n",
      "Recall 0.7839693218975228\n",
      "Confusion Matrix [[58407     6]\n",
      " [12619 45794]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8919333025182751\n",
      "Precision 0.9998689956331878\n",
      "Recall 0.7839693218975228\n",
      "Confusion Matrix [[58407     6]\n",
      " [12619 45794]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8919333025182751\n",
      "Precision 0.9998689956331878\n",
      "Recall 0.7839693218975228\n",
      "Confusion Matrix [[58407     6]\n",
      " [12619 45794]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8919333025182751\n",
      "Precision 0.9998689956331878\n",
      "Recall 0.7839693218975228\n",
      "Confusion Matrix [[58407     6]\n",
      " [12619 45794]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        \n",
    "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 1\n",
      "Treshold  9.942927792274865\n",
      "Accuracy  0.8926028006984627\n",
      "Precision  0.9999128065395095\n",
      "Recall 0.7852740781319547\n",
      "Confusion Matrix [[58410     4]\n",
      " [12543 45871]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "deep_tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "deep_acc = accuracy_score(Y_test, Y_pred)\n",
    "deep_precision = precision_score(Y_test, Y_pred)\n",
    "deep_recall = recall_score(Y_test, Y_pred)\n",
    "deep_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',deep_acc)\n",
    "print('Precision ',deep_precision)\n",
    "print(\"Recall\",deep_recall)\n",
    "print('Confusion Matrix',deep_cm)\n",
    "   \n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_dim):\n",
    "    original_dim = input_dim\n",
    "    intermediate_dim = 64\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    from keras import backend as K\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    return Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8962 - val_loss: 0.8865\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8140 - val_loss: 0.8826\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7743 - val_loss: 0.8802\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8716 - val_loss: 0.8787\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8040 - val_loss: 0.8793\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8081 - val_loss: 0.8781\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8103 - val_loss: 0.8766\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8573 - val_loss: 0.8763\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8087 - val_loss: 0.8754\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8611 - val_loss: 0.8739\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8136 - val_loss: 0.8737\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8170 - val_loss: 0.8734\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8416 - val_loss: 0.8731\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8367 - val_loss: 0.8730\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7948 - val_loss: 0.8722\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 5s 2ms/step - loss: 0.8777 - val_loss: 0.8722\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7846 - val_loss: 0.8717\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8312 - val_loss: 0.8716\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8699 - val_loss: 0.8727\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7904 - val_loss: 0.8718\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8174 - val_loss: 0.8715\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8304 - val_loss: 0.8723\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7938 - val_loss: 0.8716\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8297 - val_loss: 0.8725\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7998 - val_loss: 0.8716\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8293 - val_loss: 0.8715\n",
      "time: 136.66438555717468\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 2), (None, 2), (N 7684      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 115)               7667      \n",
      "=================================================================\n",
      "Total params: 15,351\n",
      "Trainable params: 15,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = vae_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_vae.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9881875609881362\n",
      "Precision 0.9770320681175664\n",
      "Recall 0.9998801636621985\n",
      "Confusion Matrix [[57040  1373]\n",
      " [    7 58406]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9911492304795165\n",
      "Precision 0.9828012722346566\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57391  1022]\n",
      " [   12 58401]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9927927002550802\n",
      "Precision 0.9859870675828536\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57583   830]\n",
      " [   12 58401]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9942906544775991\n",
      "Precision 0.9889253903207234\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57759   654]\n",
      " [   13 58400]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9957458100080462\n",
      "Precision 0.9917804496977107\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57929   484]\n",
      " [   13 58400]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9965932241110712\n",
      "Precision 0.9934507102151909\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58028   385]\n",
      " [   13 58400]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9968928149555749\n",
      "Precision 0.9940425531914894\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58063   350]\n",
      " [   13 58400]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9971410473695924\n",
      "Precision 0.9945334718414196\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58092   321]\n",
      " [   13 58400]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9973208018762947\n",
      "Precision 0.9948892674616695\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58113   300]\n",
      " [   13 58400]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9975519148134833\n",
      "Precision 0.9953470932115283\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58140   273]\n",
      " [   13 58400]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8904524677725849\n",
      "Precision 0.9961711662714556\n",
      "Recall 0.7839179634670365\n",
      "Confusion Matrix [[58237   176]\n",
      " [12622 45791]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8910773286768356\n",
      "Precision 0.9977990847679233\n",
      "Recall 0.7838837245133788\n",
      "Confusion Matrix [[58312   101]\n",
      " [12624 45789]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8914881961207266\n",
      "Precision 0.9988873860116061\n",
      "Recall 0.7838494855597213\n",
      "Confusion Matrix [[58362    51]\n",
      " [12626 45787]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8916165921969424\n",
      "Precision 0.9992797433267128\n",
      "Recall 0.7837981271292349\n",
      "Confusion Matrix [[58380    33]\n",
      " [12629 45784]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8916765103658432\n",
      "Precision 0.9995196716300598\n",
      "Recall 0.7837296492219198\n",
      "Confusion Matrix [[58391    22]\n",
      " [12633 45780]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8917621077499872\n",
      "Precision 0.9997597728761738\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58402    11]\n",
      " [12634 45779]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8918305856573023\n",
      "Precision 0.9999344720632563\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58410     3]\n",
      " [12634 45779]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918562648725455\n",
      "Precision 1.0\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58413     0]\n",
      " [12634 45779]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8918220259188879\n",
      "Precision 1.0\n",
      "Recall 0.7836440518377759\n",
      "Confusion Matrix [[58413     0]\n",
      " [12638 45775]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8917877869652303\n",
      "Precision 1.0\n",
      "Recall 0.7835755739304607\n",
      "Confusion Matrix [[58413     0]\n",
      " [12642 45771]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8917278687963296\n",
      "Precision 1.0\n",
      "Recall 0.7834557375926592\n",
      "Confusion Matrix [[58413     0]\n",
      " [12649 45764]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8916251519353569\n",
      "Precision 1.0\n",
      "Recall 0.7832503038707137\n",
      "Confusion Matrix [[58413     0]\n",
      " [12661 45752]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8915138753359697\n",
      "Precision 1.0\n",
      "Recall 0.7830277506719394\n",
      "Confusion Matrix [[58413     0]\n",
      " [12674 45739]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8913683597829251\n",
      "Precision 1.0\n",
      "Recall 0.7827367195658501\n",
      "Confusion Matrix [[58413     0]\n",
      " [12691 45722]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8911971650146372\n",
      "Precision 1.0\n",
      "Recall 0.7823943300292743\n",
      "Confusion Matrix [[58413     0]\n",
      " [12711 45702]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8911115676304933\n",
      "Precision 1.0\n",
      "Recall 0.7822231352609864\n",
      "Confusion Matrix [[58413     0]\n",
      " [12721 45692]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 10\n",
      "Treshold  61.796758290182765\n",
      "Accuracy  0.9977488273359126\n",
      "Precision  0.9958051259314837\n",
      "Recall 0.9997089738761256\n",
      "Confusion Matrix [[58168   246]\n",
      " [   17 58397]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "vae_acc = accuracy_score(Y_test, Y_pred)\n",
    "vae_precision = precision_score(Y_test, Y_pred)\n",
    "vae_recall = recall_score(Y_test, Y_pred)\n",
    "vae_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',vae_acc)\n",
    "print('Precision ',vae_precision)\n",
    "print(\"Recall\",vae_recall)\n",
    "print('Confusion Matrix',vae_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uc_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(15, activation='relu')(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.9357 - val_loss: 0.8673\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8242 - val_loss: 0.8580\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 5s 2ms/step - loss: 0.8108 - val_loss: 0.8550\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7864 - val_loss: 0.8533\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8160 - val_loss: 0.8525\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7690 - val_loss: 0.8519\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8033 - val_loss: 0.8515\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8282 - val_loss: 0.8512\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7776 - val_loss: 0.8510\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8040 - val_loss: 0.8509\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7959 - val_loss: 0.8507\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7716 - val_loss: 0.8506\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7400 - val_loss: 0.8506\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8019 - val_loss: 0.8504\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8306 - val_loss: 0.8504\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8019 - val_loss: 0.8503\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8367 - val_loss: 0.8503\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7827 - val_loss: 0.8503\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7878 - val_loss: 0.8502\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8326 - val_loss: 0.8501\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8060 - val_loss: 0.8501\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8117 - val_loss: 0.8501\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7669 - val_loss: 0.8501\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8204 - val_loss: 0.8500\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8339 - val_loss: 0.8501\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8312 - val_loss: 0.8501\n",
      "Epoch 27/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8115 - val_loss: 0.8500\n",
      "Epoch 28/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8011 - val_loss: 0.8500\n",
      "Epoch 29/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7944 - val_loss: 0.8499\n",
      "Epoch 30/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8178 - val_loss: 0.8499\n",
      "Epoch 31/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8012 - val_loss: 0.8493\n",
      "Epoch 32/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7877 - val_loss: 0.8493\n",
      "Epoch 33/100\n",
      "1826/1826 [==============================] - 5s 2ms/step - loss: 0.8333 - val_loss: 0.8492\n",
      "Epoch 34/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7912 - val_loss: 0.8492\n",
      "Epoch 35/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7619 - val_loss: 0.8492\n",
      "Epoch 36/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8409 - val_loss: 0.8491\n",
      "Epoch 37/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7792 - val_loss: 0.8491\n",
      "Epoch 38/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8005 - val_loss: 0.8491\n",
      "Epoch 39/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7644 - val_loss: 0.8491\n",
      "Epoch 40/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8260 - val_loss: 0.8491\n",
      "Epoch 41/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8185 - val_loss: 0.8491\n",
      "Epoch 42/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8212 - val_loss: 0.8490\n",
      "Epoch 43/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8012 - val_loss: 0.8491\n",
      "Epoch 44/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8242 - val_loss: 0.8490\n",
      "Epoch 45/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8195 - val_loss: 0.8490\n",
      "Epoch 46/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8360 - val_loss: 0.8491\n",
      "Epoch 47/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8512 - val_loss: 0.8490\n",
      "Epoch 48/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8000 - val_loss: 0.8490\n",
      "Epoch 49/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7860 - val_loss: 0.8490\n",
      "Epoch 50/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7506 - val_loss: 0.8490\n",
      "Epoch 51/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8190 - val_loss: 0.8490\n",
      "Epoch 52/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8160 - val_loss: 0.8490\n",
      "Epoch 53/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7879 - val_loss: 0.8490\n",
      "Epoch 54/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7624 - val_loss: 0.8489\n",
      "Epoch 55/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7640 - val_loss: 0.8490\n",
      "Epoch 56/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7956 - val_loss: 0.8489\n",
      "Epoch 57/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7826 - val_loss: 0.8490\n",
      "Epoch 58/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.7953 - val_loss: 0.8489\n",
      "Epoch 59/100\n",
      "1826/1826 [==============================] - 1082s 593ms/step - loss: 0.7656 - val_loss: 0.8489\n",
      "Epoch 60/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8073 - val_loss: 0.8489\n",
      "Epoch 61/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8255 - val_loss: 0.8489\n",
      "time: 1323.796669960022\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 15)                1740      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 115)               1840      \n",
      "=================================================================\n",
      "Total params: 3,580\n",
      "Trainable params: 3,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = uc_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_undercomplete.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9883330765411809\n",
      "Precision 0.977309996318731\n",
      "Recall 0.9998801636621985\n",
      "Confusion Matrix [[57057  1356]\n",
      " [    7 58406]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9913033057709756\n",
      "Precision 0.9830990657352074\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57409  1004]\n",
      " [   12 58401]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.992809819731909\n",
      "Precision 0.9860203616471661\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57585   828]\n",
      " [   12 58401]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9943505726465\n",
      "Precision 0.9890426270597998\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57766   647]\n",
      " [   13 58400]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9957372502696318\n",
      "Precision 0.9917636070306529\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57928   485]\n",
      " [   13 58400]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9966103435878999\n",
      "Precision 0.9934845108279604\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58030   383]\n",
      " [   13 58400]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9968842552171605\n",
      "Precision 0.9940256336062365\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58062   351]\n",
      " [   13 58400]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.997132487631178\n",
      "Precision 0.9945165355403426\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58091   322]\n",
      " [   13 58400]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9973122421378803\n",
      "Precision 0.9948723190405615\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58112   301]\n",
      " [   13 58400]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9975604745518977\n",
      "Precision 0.9953640578129261\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58141   272]\n",
      " [   13 58400]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8904439080341705\n",
      "Precision 0.9961279095061997\n",
      "Recall 0.7839350829438653\n",
      "Confusion Matrix [[58235   178]\n",
      " [12621 45792]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8910773286768356\n",
      "Precision 0.9977990847679233\n",
      "Recall 0.7838837245133788\n",
      "Confusion Matrix [[58312   101]\n",
      " [12624 45789]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8914710766438978\n",
      "Precision 0.9988438045375219\n",
      "Recall 0.7838494855597213\n",
      "Confusion Matrix [[58360    53]\n",
      " [12626 45787]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.891608032458528\n",
      "Precision 0.9993015235517527\n",
      "Recall 0.7837638881755774\n",
      "Confusion Matrix [[58381    32]\n",
      " [12631 45782]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8917021895810864\n",
      "Precision 0.9995851437804318\n",
      "Recall 0.7837296492219198\n",
      "Confusion Matrix [[58394    19]\n",
      " [12633 45780]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8917535480115728\n",
      "Precision 0.9997379397698237\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58401    12]\n",
      " [12634 45779]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8918305856573023\n",
      "Precision 0.9999344720632563\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58410     3]\n",
      " [12634 45779]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 0.9999781564001747\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58412     1]\n",
      " [12634 45779]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8918391453957167\n",
      "Precision 1.0\n",
      "Recall 0.7836782907914334\n",
      "Confusion Matrix [[58413     0]\n",
      " [12636 45777]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8918220259188879\n",
      "Precision 1.0\n",
      "Recall 0.7836440518377759\n",
      "Confusion Matrix [[58413     0]\n",
      " [12638 45775]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8917706674884015\n",
      "Precision 1.0\n",
      "Recall 0.7835413349768031\n",
      "Confusion Matrix [[58413     0]\n",
      " [12644 45769]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.891736428534744\n",
      "Precision 1.0\n",
      "Recall 0.783472857069488\n",
      "Confusion Matrix [[58413     0]\n",
      " [12648 45765]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8916165921969424\n",
      "Precision 1.0\n",
      "Recall 0.7832331843938849\n",
      "Confusion Matrix [[58413     0]\n",
      " [12662 45751]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8915138753359697\n",
      "Precision 1.0\n",
      "Recall 0.7830277506719394\n",
      "Confusion Matrix [[58413     0]\n",
      " [12674 45739]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.891325561090853\n",
      "Precision 1.0\n",
      "Recall 0.7826511221817062\n",
      "Confusion Matrix [[58413     0]\n",
      " [12696 45717]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8911971650146372\n",
      "Precision 1.0\n",
      "Recall 0.7823943300292743\n",
      "Confusion Matrix [[58413     0]\n",
      " [12711 45702]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8911115676304933\n",
      "Precision 1.0\n",
      "Recall 0.7822231352609864\n",
      "Confusion Matrix [[58413     0]\n",
      " [12721 45692]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 10\n",
      "Treshold  61.10248873964882\n",
      "Accuracy  0.99776594651967\n",
      "Precision  0.9958390886922119\n",
      "Recall 0.9997089738761256\n",
      "Confusion Matrix [[58170   244]\n",
      " [   17 58397]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "uc_acc = accuracy_score(Y_test, Y_pred)\n",
    "uc_precision = precision_score(Y_test, Y_pred)\n",
    "uc_recall = recall_score(Y_test, Y_pred)\n",
    "uc_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',uc_acc)\n",
    "print('Precision ',uc_precision)\n",
    "print(\"Recall\",uc_recall)\n",
    "print('Confusion Matrix',uc_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_model(input_dim):\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoded = Dense(200, activation='relu',\n",
    "                activity_regularizer=regularizers.l1(10e-6))(input_img)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 7s 3ms/step - loss: 0.8942 - val_loss: 0.8526\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7940 - val_loss: 0.8505\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8145 - val_loss: 0.8499\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8131 - val_loss: 0.8485\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8054 - val_loss: 0.8483\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7885 - val_loss: 0.8481\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7684 - val_loss: 0.8481\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8085 - val_loss: 0.8478\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8571 - val_loss: 0.8478\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7574 - val_loss: 0.8477\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8184 - val_loss: 0.8476\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7860 - val_loss: 0.8477\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8418 - val_loss: 0.8476\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7967 - val_loss: 0.8477\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8003 - val_loss: 0.8475\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8248 - val_loss: 0.8475\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8376 - val_loss: 0.8475\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7876 - val_loss: 0.8475\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7952 - val_loss: 0.8470\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.7970 - val_loss: 0.8466\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8162 - val_loss: 0.8465\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8169 - val_loss: 0.8465\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8048 - val_loss: 0.8466\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8243 - val_loss: 0.8465\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7686 - val_loss: 0.8465\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8054 - val_loss: 0.8465\n",
      "Epoch 27/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7746 - val_loss: 0.8465\n",
      "Epoch 28/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8487 - val_loss: 0.8464\n",
      "Epoch 29/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7748 - val_loss: 0.8464\n",
      "Epoch 30/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7965 - val_loss: 0.8464\n",
      "Epoch 31/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8185 - val_loss: 0.8464\n",
      "Epoch 32/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8197 - val_loss: 0.8464\n",
      "Epoch 33/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.7933 - val_loss: 0.8465\n",
      "Epoch 34/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8342 - val_loss: 0.8466\n",
      "Epoch 35/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8069 - val_loss: 0.8464\n",
      "Epoch 36/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7943 - val_loss: 0.8464\n",
      "Epoch 37/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7956 - val_loss: 0.8464\n",
      "Epoch 38/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7789 - val_loss: 0.8464\n",
      "Epoch 39/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7730 - val_loss: 0.8464\n",
      "Epoch 40/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8006 - val_loss: 0.8463\n",
      "Epoch 41/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8035 - val_loss: 0.8464\n",
      "Epoch 42/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8203 - val_loss: 0.8463\n",
      "Epoch 43/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7759 - val_loss: 0.8463\n",
      "Epoch 44/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7908 - val_loss: 0.8463\n",
      "Epoch 45/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7832 - val_loss: 0.8463\n",
      "Epoch 46/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8182 - val_loss: 0.8463\n",
      "Epoch 47/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8165 - val_loss: 0.8463\n",
      "Epoch 48/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8362 - val_loss: 0.8463\n",
      "Epoch 49/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8243 - val_loss: 0.8463\n",
      "Epoch 50/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7669 - val_loss: 0.8463\n",
      "Epoch 51/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8066 - val_loss: 0.8463\n",
      "Epoch 52/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8199 - val_loss: 0.8463\n",
      "Epoch 53/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7905 - val_loss: 0.8463\n",
      "Epoch 54/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7561 - val_loss: 0.8463\n",
      "Epoch 55/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8034 - val_loss: 0.8463\n",
      "time: 325.1952152252197\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               23200     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 115)               23115     \n",
      "=================================================================\n",
      "Total params: 46,315\n",
      "Trainable params: 46,315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = sparse_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9883416362795953\n",
      "Precision 0.9773263499606767\n",
      "Recall 0.9998801636621985\n",
      "Confusion Matrix [[57058  1355]\n",
      " [    7 58406]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9913033057709756\n",
      "Precision 0.9830990657352074\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57409  1004]\n",
      " [   12 58401]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.992809819731909\n",
      "Precision 0.9860203616471661\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57585   828]\n",
      " [   12 58401]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9943676921233288\n",
      "Precision 0.9890761283766619\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57768   645]\n",
      " [   13 58400]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.995720130792803\n",
      "Precision 0.9917299234126378\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57926   487]\n",
      " [   13 58400]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9966103435878999\n",
      "Precision 0.9934845108279604\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58030   383]\n",
      " [   13 58400]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9968842552171605\n",
      "Precision 0.9940256336062365\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58062   351]\n",
      " [   13 58400]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9971239278927636\n",
      "Precision 0.9944995998160857\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58090   323]\n",
      " [   13 58400]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.9973122421378803\n",
      "Precision 0.9948723190405615\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58112   301]\n",
      " [   13 58400]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.9975604745518977\n",
      "Precision 0.9953640578129261\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58141   272]\n",
      " [   13 58400]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8904353482957561\n",
      "Precision 0.9961278252735539\n",
      "Recall 0.7839179634670365\n",
      "Confusion Matrix [[58235   178]\n",
      " [12622 45791]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8910773286768356\n",
      "Precision 0.9977990847679233\n",
      "Recall 0.7838837245133788\n",
      "Confusion Matrix [[58312   101]\n",
      " [12624 45789]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8914796363823122\n",
      "Precision 0.9988655947991885\n",
      "Recall 0.7838494855597213\n",
      "Confusion Matrix [[58361    52]\n",
      " [12626 45787]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.891608032458528\n",
      "Precision 0.9993015235517527\n",
      "Recall 0.7837638881755774\n",
      "Confusion Matrix [[58381    32]\n",
      " [12631 45782]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.891693629842672\n",
      "Precision 0.9995633187772925\n",
      "Recall 0.7837296492219198\n",
      "Confusion Matrix [[58393    20]\n",
      " [12633 45780]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8917535480115728\n",
      "Precision 0.9997379397698237\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58401    12]\n",
      " [12634 45779]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8918305856573023\n",
      "Precision 0.9999344720632563\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58410     3]\n",
      " [12634 45779]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 0.9999781564001747\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58412     1]\n",
      " [12634 45779]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 1.0\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58413     0]\n",
      " [12635 45778]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8918391453957167\n",
      "Precision 1.0\n",
      "Recall 0.7836782907914334\n",
      "Confusion Matrix [[58413     0]\n",
      " [12636 45777]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8918305856573023\n",
      "Precision 1.0\n",
      "Recall 0.7836611713146047\n",
      "Confusion Matrix [[58413     0]\n",
      " [12637 45776]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8917792272268159\n",
      "Precision 1.0\n",
      "Recall 0.7835584544536319\n",
      "Confusion Matrix [[58413     0]\n",
      " [12643 45770]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.891736428534744\n",
      "Precision 1.0\n",
      "Recall 0.783472857069488\n",
      "Confusion Matrix [[58413     0]\n",
      " [12648 45765]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8916422714121857\n",
      "Precision 1.0\n",
      "Recall 0.7832845428243713\n",
      "Confusion Matrix [[58413     0]\n",
      " [12659 45754]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8915138753359697\n",
      "Precision 1.0\n",
      "Recall 0.7830277506719394\n",
      "Confusion Matrix [[58413     0]\n",
      " [12674 45739]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8913512403060962\n",
      "Precision 1.0\n",
      "Recall 0.7827024806121925\n",
      "Confusion Matrix [[58413     0]\n",
      " [12693 45720]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8912399637067091\n",
      "Precision 1.0\n",
      "Recall 0.7824799274134182\n",
      "Confusion Matrix [[58413     0]\n",
      " [12706 45707]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.891128687107322\n",
      "Precision 1.0\n",
      "Recall 0.782257374214644\n",
      "Confusion Matrix [[58413     0]\n",
      " [12719 45694]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 10\n",
      "Treshold  61.01710258299022\n",
      "Accuracy  0.9977488273359126\n",
      "Precision  0.9958051259314837\n",
      "Recall 0.9997089738761256\n",
      "Confusion Matrix [[58168   246]\n",
      " [   17 58397]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "sparse_acc = accuracy_score(Y_test, Y_pred)\n",
    "sparse_precision = precision_score(Y_test, Y_pred)\n",
    "sparse_recall = recall_score(Y_test, Y_pred)\n",
    "sparse_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',sparse_acc)\n",
    "print('Precision ',sparse_precision)\n",
    "print(\"Recall\",sparse_recall)\n",
    "print('Confusion Matrix',sparse_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_model(input_dim):\n",
    "    input_size = input_dim\n",
    "    hidden_size = 44\n",
    "    code_size = 5\n",
    "\n",
    "    input_img = Input(shape=(input_size,))\n",
    "    hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "    code = Dense(code_size, activation='relu')(hidden_1)\n",
    "    hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "    output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "    autoencoder = Model(input_img, output_img)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 7s 3ms/step - loss: 0.9977 - val_loss: 0.9274\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8990 - val_loss: 0.9218\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8594 - val_loss: 0.9193\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8445 - val_loss: 0.9322\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8617 - val_loss: 0.9145\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8484 - val_loss: 0.9122\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8731 - val_loss: 0.9106\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8590 - val_loss: 0.9098\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8800 - val_loss: 0.9097\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.9105 - val_loss: 0.9159\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8869 - val_loss: 0.9119\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8515 - val_loss: 0.9067\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 3s 2ms/step - loss: 0.8547 - val_loss: 0.9134\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8875 - val_loss: 0.9088\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8740 - val_loss: 0.9110\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8527 - val_loss: 0.9051\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8605 - val_loss: 0.9040\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8375 - val_loss: 0.9040\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8541 - val_loss: 0.9044\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8616 - val_loss: 0.9031\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7976 - val_loss: 0.9041\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8541 - val_loss: 0.9069\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8586 - val_loss: 0.9034\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8288 - val_loss: 0.9022\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8260 - val_loss: 0.9032\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8542 - val_loss: 0.9023\n",
      "Epoch 27/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8563 - val_loss: 0.9023\n",
      "Epoch 28/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8653 - val_loss: 0.9006\n",
      "Epoch 29/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8388 - val_loss: 0.8997\n",
      "Epoch 30/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8825 - val_loss: 0.9022\n",
      "Epoch 31/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8148 - val_loss: 0.8989\n",
      "Epoch 32/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8694 - val_loss: 0.8994\n",
      "Epoch 33/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8436 - val_loss: 0.9055\n",
      "Epoch 34/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8251 - val_loss: 0.8988\n",
      "Epoch 35/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8160 - val_loss: 0.8984\n",
      "Epoch 36/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8556 - val_loss: 0.8985\n",
      "Epoch 37/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8678 - val_loss: 0.8979\n",
      "Epoch 38/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8441 - val_loss: 0.8979\n",
      "Epoch 39/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8810 - val_loss: 0.8976\n",
      "Epoch 40/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8631 - val_loss: 0.8971\n",
      "Epoch 41/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8622 - val_loss: 0.8965\n",
      "Epoch 42/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8779 - val_loss: 0.9012\n",
      "Epoch 43/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8485 - val_loss: 0.8971\n",
      "Epoch 44/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8851 - val_loss: 0.8974\n",
      "Epoch 45/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8351 - val_loss: 0.8990\n",
      "Epoch 46/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8102 - val_loss: 0.8962\n",
      "Epoch 47/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8173 - val_loss: 0.8966\n",
      "Epoch 48/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8125 - val_loss: 0.8975\n",
      "Epoch 49/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8505 - val_loss: 0.8984\n",
      "Epoch 50/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8210 - val_loss: 0.8956\n",
      "Epoch 51/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8424 - val_loss: 0.8954\n",
      "Epoch 52/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8164 - val_loss: 0.8987\n",
      "Epoch 53/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8724 - val_loss: 0.8965\n",
      "Epoch 54/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8553 - val_loss: 0.8954\n",
      "Epoch 55/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8337 - val_loss: 0.9010\n",
      "Epoch 56/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8462 - val_loss: 0.8998\n",
      "time: 301.92048501968384\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 44)                5104      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 225       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 44)                264       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 115)               5175      \n",
      "=================================================================\n",
      "Total params: 10,768\n",
      "Trainable params: 10,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_train.shape) \n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "x_opt_noisy = np.clip(x_opt_noisy, 0., 1.)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "#x_train_noisy = scaler.fit_transform(x_train_noisy)\n",
    "#x_opt_noisy = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#call function to create the model\n",
    "model = denoise_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(x_train_noisy, X_train,\n",
    "                    epochs=epochs, validation_data=(x_opt_noisy, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.5042541899919538\n",
      "Precision 0.5021361827231386\n",
      "Recall 1.0\n",
      "Confusion Matrix [[  497 57916]\n",
      " [    0 58413]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.5077380035266122\n",
      "Precision 0.5038991735822363\n",
      "Recall 1.0\n",
      "Confusion Matrix [[  904 57509]\n",
      " [    0 58413]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.5122233064557548\n",
      "Precision 0.5061872822752561\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 1428 56985]\n",
      " [    0 58413]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.5190282984951979\n",
      "Precision 0.5096986989869375\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 2223 56190]\n",
      " [    0 58413]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.5281444199065276\n",
      "Precision 0.5144797336574539\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 3288 55125]\n",
      " [    0 58413]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.5399140602263195\n",
      "Precision 0.5207867121956439\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 4663 53750]\n",
      " [    0 58413]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.5561433242600106\n",
      "Precision 0.529741445763465\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 6559 51854]\n",
      " [    0 58413]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.5747778747881465\n",
      "Precision 0.5404107688037746\n",
      "Recall 1.0\n",
      "Confusion Matrix [[ 8736 49677]\n",
      " [    0 58413]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.5971359115265438\n",
      "Precision 0.5537932080623448\n",
      "Recall 1.0\n",
      "Confusion Matrix [[11348 47065]\n",
      " [    0 58413]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.6213599712392789\n",
      "Precision 0.5690612578910451\n",
      "Recall 1.0\n",
      "Confusion Matrix [[14178 44235]\n",
      " [    0 58413]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.6470391864824611\n",
      "Precision 0.5861934007707129\n",
      "Recall 1.0\n",
      "Confusion Matrix [[17178 41235]\n",
      " [    0 58413]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.6745501857463236\n",
      "Precision 0.6057303440695191\n",
      "Recall 1.0\n",
      "Confusion Matrix [[20392 38021]\n",
      " [    0 58413]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.7014534435827641\n",
      "Precision 0.6261429781212816\n",
      "Recall 0.9999657610463424\n",
      "Confusion Matrix [[23537 34876]\n",
      " [    2 58411]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.7285792546179789\n",
      "Precision 0.6481645878645301\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[26707 31706]\n",
      " [    3 58410]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.7543868659373769\n",
      "Precision 0.6706007967761565\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[29722 28691]\n",
      " [    3 58410]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.7783541334976803\n",
      "Precision 0.6928743431276023\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[32522 25891]\n",
      " [    3 58410]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8006180131135192\n",
      "Precision 0.7149326805385557\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[35123 23290]\n",
      " [    3 58410]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8213411398147673\n",
      "Precision 0.7367650954224952\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[37544 20869]\n",
      " [    3 58410]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8403180798794789\n",
      "Precision 0.7579611222132828\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[39761 18652]\n",
      " [    3 58410]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8577885059832572\n",
      "Precision 0.7785819970408285\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[41802 16611]\n",
      " [    3 58410]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8732987519901392\n",
      "Precision 0.7978527230258575\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[43614 14799]\n",
      " [    3 58410]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8867717802543954\n",
      "Precision 0.8153835415648775\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[45188 13225]\n",
      " [    3 58410]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.899166281478438\n",
      "Precision 0.8322053941613119\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[46636 11777]\n",
      " [    3 58410]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.9101741050793488\n",
      "Precision 0.8477380589541517\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[47922 10491]\n",
      " [    3 58410]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.9199493263485868\n",
      "Precision 0.8620257087619357\n",
      "Recall 0.9999486415695137\n",
      "Confusion Matrix [[49064  9349]\n",
      " [    3 58410]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.9282779518257922\n",
      "Precision 0.8746069300110808\n",
      "Recall 0.9999144026158561\n",
      "Confusion Matrix [[50039  8374]\n",
      " [    5 58408]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.9357591631999727\n",
      "Precision 0.8862050130484919\n",
      "Recall 0.9999144026158561\n",
      "Confusion Matrix [[50913  7500]\n",
      " [    5 58408]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.9423758409942992\n",
      "Precision 0.8967221923696937\n",
      "Recall 0.9999144026158561\n",
      "Confusion Matrix [[51686  6727]\n",
      " [    5 58408]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.948367657884375\n",
      "Precision 0.9064764949637608\n",
      "Recall 0.9998972831390273\n",
      "Confusion Matrix [[52387  6026]\n",
      " [    6 58407]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(x_opt_noisy)\n",
    "mse = np.mean(np.power(x_opt_noisy - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "x_opt_noisy = X_opt + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_opt.shape) \n",
    "X_opt_scaled = scaler.transform(x_opt_noisy)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 29\n",
      "Treshold  4.0820861375619435\n",
      "Accuracy  0.787277022631561\n",
      "Precision  0.7015638888221587\n",
      "Recall 0.9998972848974561\n",
      "Confusion Matrix [[33568 24846]\n",
      " [    6 58408]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(x_test_noisy, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=20)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "x_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape) \n",
    "X_test_scaled = scaler.transform(x_test_noisy)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "denoise_acc = accuracy_score(Y_test, Y_pred)\n",
    "denoise_precision = precision_score(Y_test, Y_pred)\n",
    "denoise_recall = recall_score(Y_test, Y_pred)\n",
    "denoise_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',denoise_acc)\n",
    "print('Precision ',denoise_precision)\n",
    "print(\"Recall\",denoise_recall)\n",
    "print('Confusion Matrix',denoise_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(80, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Dense(labels.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, callbacks=[monitor], patience=5) \n",
    "    model.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n",
    "          verbose=1,epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 1\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 0\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))\n",
    "\n",
    "X = df_ben.drop(columns=['class'])\n",
    "y = df_ben['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=17)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6231/6231 [==============================] - 15s 2ms/step - loss: 0.0042\n",
      "Epoch 2/100\n",
      "6231/6231 [==============================] - 13s 2ms/step - loss: 7.6574e-04\n",
      "Epoch 3/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 0.0011A: 0s -\n",
      "Epoch 4/100\n",
      "6231/6231 [==============================] - 14s 2ms/step - loss: 0.0018\n",
      "Epoch 5/100\n",
      "6231/6231 [==============================] - 11s 2ms/step - loss: 4.7178e-04\n",
      "Epoch 6/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 4.0288e-04\n",
      "Epoch 7/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 8.5626e-04\n",
      "Epoch 8/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 6.8541e-04\n",
      "Epoch 9/100\n",
      "6231/6231 [==============================] - 10s 2ms/step - loss: 2.4937e-04\n",
      "Epoch 10/100\n",
      "6231/6231 [==============================] - 10s 2ms/step - loss: 3.4414e-04\n",
      "Epoch 11/100\n",
      "6231/6231 [==============================] - 7s 1ms/step - loss: 3.2225e-04\n",
      "Epoch 12/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 2.8696e-04\n",
      "Epoch 13/100\n",
      "6231/6231 [==============================] - 13s 2ms/step - loss: 5.1935e-04\n",
      "Epoch 14/100\n",
      "6231/6231 [==============================] - 13s 2ms/step - loss: 4.4151e-04\n",
      "Epoch 15/100\n",
      "6231/6231 [==============================] - 10s 2ms/step - loss: 4.2860e-04\n",
      "Epoch 16/100\n",
      "6231/6231 [==============================] - 7s 1ms/step - loss: 3.4788e-04\n",
      "Epoch 17/100\n",
      "6231/6231 [==============================] - 10s 2ms/step - loss: 2.5344e-04\n",
      "Epoch 18/100\n",
      "6231/6231 [==============================] - 7s 1ms/step - loss: 2.9312e-04\n",
      "Epoch 19/100\n",
      "6231/6231 [==============================] - 7s 1ms/step - loss: 3.9337e-04\n",
      "Epoch 20/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 2.3176e-04\n",
      "Epoch 21/100\n",
      "6231/6231 [==============================] - 12s 2ms/step - loss: 2.7586e-04\n",
      "Epoch 22/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 1.5286e-04\n",
      "Epoch 23/100\n",
      "6231/6231 [==============================] - 7s 1ms/step - loss: 2.3915e-04\n",
      "Epoch 24/100\n",
      "6231/6231 [==============================] - 7s 1ms/step - loss: 2.2885e-04\n",
      "Epoch 25/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 2.6113e-04\n",
      "time 243.6959137916565\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_dim=115, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "\n",
    "#compile and fit model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=15,callbacks=[es])\n",
    "\n",
    "end = time.time()\n",
    "print(\"time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9995292305058632\n",
      "Precision  0.999491998983998\n",
      "Recall 0.9995766299745978\n",
      "Confusion Matrix [[11550     6]\n",
      " [    5 11805]]\n"
     ]
    }
   ],
   "source": [
    "dnn_acc = accuracy_score(y_test, y_pred)\n",
    "dnn_precision = precision_score(y_test, y_pred)\n",
    "dnn_recall = recall_score(y_test, y_pred)\n",
    "dnn_cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy ',dnn_acc)\n",
    "print('Precision ',dnn_precision)\n",
    "print(\"Recall\",dnn_recall)\n",
    "print('Confusion Matrix',dnn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>CM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denoising Autoendoer</td>\n",
       "      <td>0.787277</td>\n",
       "      <td>0.701564</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>[[33568, 24846], [6, 58408]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep AutoEncoder</td>\n",
       "      <td>0.892603</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.785274</td>\n",
       "      <td>[[58410, 4], [12543, 45871]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variational AutoEncoder</td>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.995805</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>[[58168, 246], [17, 58397]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse AutoEncoder</td>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.995805</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>[[58168, 246], [17, 58397]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undercomplete Autoencoder</td>\n",
       "      <td>0.997766</td>\n",
       "      <td>0.995839</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>[[58170, 244], [17, 58397]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Precision    Recall  \\\n",
       "4       Denoising Autoendoer  0.787277   0.701564  0.999897   \n",
       "0           Deep AutoEncoder  0.892603   0.999913  0.785274   \n",
       "1    Variational AutoEncoder  0.997749   0.995805  0.999709   \n",
       "2         Sparse AutoEncoder  0.997749   0.995805  0.999709   \n",
       "3  Undercomplete Autoencoder  0.997766   0.995839  0.999709   \n",
       "\n",
       "                             CM  \n",
       "4  [[33568, 24846], [6, 58408]]  \n",
       "0  [[58410, 4], [12543, 45871]]  \n",
       "1   [[58168, 246], [17, 58397]]  \n",
       "2   [[58168, 246], [17, 58397]]  \n",
       "3   [[58170, 244], [17, 58397]]  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary = pd.DataFrame({'Model' :['Deep AutoEncoder',\"Variational AutoEncoder\",\"Sparse AutoEncoder\",\"Undercomplete Autoencoder\",\"Denoising Autoendoer\"],\n",
    "                             'Accuracy':[deep_acc,vae_acc,sparse_acc,uc_acc,denoise_acc],\n",
    "                             'Precision':[deep_precision,vae_precision,sparse_precision,uc_precision,denoise_precision],\n",
    "                             'Recall':[deep_recall,vae_recall,sparse_recall,uc_recall,denoise_recall],\n",
    "                             'CM':[deep_cm,vae_cm,sparse_cm,uc_cm, denoise_cm]})\n",
    "model_summary.sort_values(by='Accuracy', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
