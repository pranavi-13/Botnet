{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "from glob import iglob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, confusion_matrix, plot_confusion_matrix\n",
    "#import lime\n",
    "#import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign=pd.read_csv(\"BabyMonitor/benign_traffic.csv\")\n",
    "x_train, x_opt, x_test = np.split(benign.sample(frac=1, random_state=17), [int(1/3*len(benign)), int(2/3*len(benign))])\n",
    "\n",
    "df_mirai = pd.concat((pd.read_csv(f) for f in iglob('BabyMonitor/mirai/*.csv', recursive=False)), ignore_index=True)\n",
    "df_gafgyt = pd.concat((pd.read_csv(f) for f in iglob('BabyMonitor/gafgyt/*.csv', recursive=False)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 'malicious'\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 'benign'\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting samples of benign and malicious data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_n = 2000\n",
    "atk = df_attack.sample(n=plot_n, random_state=76)\n",
    "nrm = x_train.sample(n=plot_n, random_state=42)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(nrm['MI_dir_L0.1_weight'],nrm['MI_dir_L1_weight'],10,c='blue', label='normal',alpha=0.5)\n",
    "ax1.scatter(atk['MI_dir_L0.1_weight'],atk['MI_dir_L1_weight'],10,c='red',label='attack',alpha=0.5)\n",
    "\n",
    "plt.xlabel('MI_dir_L0.1_weight')\n",
    "plt.ylabel('MI_dir_L1_weight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'MI_dir_L0.1_weight', 'score': 1.2240810634300796},\n",
       " {'feature': 'H_L0.1_weight', 'score': 1.2240810502737431},\n",
       " {'feature': 'MI_dir_L1_weight', 'score': 1.2045402024555407},\n",
       " {'feature': 'H_L1_weight', 'score': 1.204540198657306},\n",
       " {'feature': 'MI_dir_L3_weight', 'score': 1.2042752745290892}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['benign','malicious']\n",
    "scored = []\n",
    "indices = {}\n",
    "shps = {}\n",
    "\n",
    "#classifying benign as true and attack as false\n",
    "for cl in classes:\n",
    "    indices[cl] = df_ben['class'] == cl    \n",
    "    shps[cl] =  df_ben[indices[cl]].shape[0]\n",
    "        \n",
    "for col in df_ben.columns:\n",
    "    if col == 'class':\n",
    "        continue\n",
    "    num = 0\n",
    "    den = 0\n",
    "    m = df_ben[col].mean()\n",
    "    \n",
    "    for cl in classes:\n",
    "        num += (shps[cl] / df_ben.shape[0]) * (m - df_ben[indices[cl]][col].mean())**2\n",
    "        den += (shps[cl] / df_ben.shape[0]) * df_ben[indices[cl]][col].var()\n",
    "    score = {'feature': col, 'score': num / den}\n",
    "    scored.append(score)\n",
    "    #print(score)\n",
    "scored.sort(key=lambda x: x['score'], reverse=True)\n",
    "scored[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyModel:\n",
    "    #initialize model\n",
    "    def __init__(self, model, threshold, scaler):\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "        self.scaler = scaler\n",
    "\n",
    "    #predict the outcome using treshold\n",
    "    def predict(self, x):\n",
    "        x_pred = self.model.predict(x)\n",
    "        mse = np.mean(np.power(x - x_pred, 2), axis=1)\n",
    "        y_pred = mse > self.threshold\n",
    "        return y_pred.astype(int)\n",
    "    \n",
    "    #scale the classes\n",
    "    def scale_predict_classes(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        y_pred = self.predict(x)\n",
    "        classes_arr = []\n",
    "        for e in y_pred:\n",
    "            el = [0,0]\n",
    "            el[e] = 1\n",
    "            classes_arr.append(el)\n",
    "        print(classes_arr)\n",
    "\n",
    "        return np.array(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation - Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_model(input_dim):\n",
    "    inp = Input(shape=(input_dim,))\n",
    "    encoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(inp)\n",
    "    encoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    encoder = Dense(int(math.ceil(0.25 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.5 * input_dim)), activation=\"tanh\")(encoder)\n",
    "    decoder = Dense(int(math.ceil(0.75 * input_dim)), activation=\"tanh\")(decoder)\n",
    "    decoder = Dense(input_dim)(decoder)\n",
    "    return Model(inp, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 9s 4ms/step - loss: 0.4509 - val_loss: 0.1836\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.1723 - val_loss: 0.1340\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.1268 - val_loss: 0.1067\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0949 - val_loss: 0.0761\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0756 - val_loss: 0.0795\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 8s 5ms/step - loss: 0.0709 - val_loss: 0.0641\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0581 - val_loss: 0.0590\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.0603 - val_loss: 0.0525\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0523 - val_loss: 0.0561\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0484 - val_loss: 0.0487\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.0474 - val_loss: 0.0479\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0463 - val_loss: 0.0485\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0504 - val_loss: 0.0516\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.0443 - val_loss: 0.0473\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.0436 - val_loss: 0.0566\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0472 - val_loss: 0.0496\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0433 - val_loss: 0.0436\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0421 - val_loss: 0.0413\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0364 - val_loss: 0.0459\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0379 - val_loss: 0.0404\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0384 - val_loss: 0.0385\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0366 - val_loss: 0.0407\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0373 - val_loss: 0.0396\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0372 - val_loss: 0.0385\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0340 - val_loss: 0.0462\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0387 - val_loss: 0.0399\n",
      "Epoch 27/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0362 - val_loss: 0.0449\n",
      "Epoch 28/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0379 - val_loss: 0.0367\n",
      "Epoch 29/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0348 - val_loss: 0.0402\n",
      "Epoch 30/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.0354 - val_loss: 0.0438\n",
      "Epoch 31/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.0353 - val_loss: 0.0377\n",
      "Epoch 32/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.0331 - val_loss: 0.0375\n",
      "Epoch 33/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.0337 - val_loss: 0.0406\n",
      "time: 207.9343237876892\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 87)                10092     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 58)                5104      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 29)                1711      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 58)                1740      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 87)                5133      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 115)               10120     \n",
      "=================================================================\n",
      "Total params: 33,900\n",
      "Trainable params: 33,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = deep_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly{top_n_features}.h5\",monitor='val_loss',save_best_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_opt, X_opt),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.8795901597247188\n",
      "Precision 0.9691506918877746\n",
      "Recall 0.7841405166658106\n",
      "Confusion Matrix [[56955  1458]\n",
      " [12609 45804]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.8845633677434818\n",
      "Precision 0.9812541508665938\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[57538   875]\n",
      " [12611 45802]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.887174087959872\n",
      "Precision 0.9877080997153455\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[57843   570]\n",
      " [12611 45802]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.888543646106175\n",
      "Precision 0.9911278455812343\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[58003   410]\n",
      " [12611 45802]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.8896649718384606\n",
      "Precision 0.9939454438922767\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[58134   279]\n",
      " [12611 45802]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.8901357574512523\n",
      "Precision 0.995133185590753\n",
      "Recall 0.7841062777121531\n",
      "Confusion Matrix [[58189   224]\n",
      " [12611 45802]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.8905466248951432\n",
      "Precision 0.9962368398155399\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58240   173]\n",
      " [12614 45799]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.8909403728622053\n",
      "Precision 0.9972346818795453\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58286   127]\n",
      " [12614 45799]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8911971650146372\n",
      "Precision 0.9978865260589158\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58316    97]\n",
      " [12614 45799]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.8914025987365826\n",
      "Precision 0.9984086152772933\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58340    73]\n",
      " [12614 45799]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8915053155975553\n",
      "Precision 0.9986698648059311\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58352    61]\n",
      " [12614 45799]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8915909129816992\n",
      "Precision 0.9988876772082879\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58362    51]\n",
      " [12614 45799]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8916593908890145\n",
      "Precision 0.9990619955499324\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58370    43]\n",
      " [12614 45799]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8917535480115728\n",
      "Precision 0.999301782636207\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58381    32]\n",
      " [12614 45799]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8918049064420591\n",
      "Precision 0.9994326241134752\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58387    26]\n",
      " [12614 45799]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8918220259188879\n",
      "Precision 0.999476245553543\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58389    24]\n",
      " [12614 45799]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8918477051341311\n",
      "Precision 0.9995416848537756\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58392    21]\n",
      " [12614 45799]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918648246109598\n",
      "Precision 0.9995853158147453\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58394    19]\n",
      " [12614 45799]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918733843493742\n",
      "Precision 0.9996071327236615\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58395    18]\n",
      " [12614 45799]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8919076233030319\n",
      "Precision 0.9996944098836574\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58399    14]\n",
      " [12614 45799]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8919076233030319\n",
      "Precision 0.9996944098836574\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58399    14]\n",
      " [12614 45799]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8919161830414463\n",
      "Precision 0.9997162315550511\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58400    13]\n",
      " [12614 45799]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8919161830414463\n",
      "Precision 0.9997162315550511\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58400    13]\n",
      " [12614 45799]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8919418622566895\n",
      "Precision 0.9997817022855771\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58403    10]\n",
      " [12614 45799]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8919589817335182\n",
      "Precision 0.999825354203506\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58405     8]\n",
      " [12614 45799]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8919589817335182\n",
      "Precision 0.999825354203506\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58405     8]\n",
      " [12614 45799]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8919589817335182\n",
      "Precision 0.999825354203506\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58405     8]\n",
      " [12614 45799]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8919846609487614\n",
      "Precision 0.999890839228015\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58408     5]\n",
      " [12614 45799]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8919846609487614\n",
      "Precision 0.999890839228015\n",
      "Recall 0.7840549192816667\n",
      "Confusion Matrix [[58408     5]\n",
      " [12614 45799]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        \n",
    "        #accs.append({'acc': acc, 'n': top_n_features, 'cm': confusion_matrix(Y_test, Y_pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 28\n",
      "Treshold  8.203981410665348\n",
      "Accuracy  0.892594241106584\n",
      "Precision  0.9997602859135286\n",
      "Recall 0.7853767932344986\n",
      "Confusion Matrix [[58403    11]\n",
      " [12537 45877]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "deep_tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "deep_acc = accuracy_score(Y_test, Y_pred)\n",
    "deep_precision = precision_score(Y_test, Y_pred)\n",
    "deep_recall = recall_score(Y_test, Y_pred)\n",
    "deep_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',deep_acc)\n",
    "print('Precision ',deep_precision)\n",
    "print(\"Recall\",deep_recall)\n",
    "print('Confusion Matrix',deep_cm)\n",
    "   \n",
    "#print(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_model(input_dim):\n",
    "    original_dim = input_dim\n",
    "    intermediate_dim = 64\n",
    "    latent_dim = 2\n",
    "\n",
    "    inputs = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_sigma = Dense(latent_dim)(h)\n",
    "    \n",
    "    from keras import backend as K\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "\n",
    "    # Create encoder\n",
    "    encoder = Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "    # Create decoder\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    return Model(inputs, outputs, name='vae_mlp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.9020 - val_loss: 0.8542\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8095 - val_loss: 0.8528\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8132 - val_loss: 0.8501\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8293 - val_loss: 0.8485\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8275 - val_loss: 0.8479\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7986 - val_loss: 0.8473\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8294 - val_loss: 0.8473\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7422 - val_loss: 0.8463\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7898 - val_loss: 0.8459- ETA: 0s - loss: 0.78\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7820 - val_loss: 0.8456\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8725 - val_loss: 0.8461\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 6s 4ms/step - loss: 0.8139 - val_loss: 0.8456\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8654 - val_loss: 0.8453\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8311 - val_loss: 0.8449\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 9s 5ms/step - loss: 0.7894 - val_loss: 0.8450\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.7876 - val_loss: 0.8446\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8281 - val_loss: 0.8446\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8717 - val_loss: 0.8445\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.7712 - val_loss: 0.8443\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8190 - val_loss: 0.8442\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8172 - val_loss: 0.8442\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7980 - val_loss: 0.8438\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.7943 - val_loss: 0.8440\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8106 - val_loss: 0.8442\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8210 - val_loss: 0.8439\n",
      "Epoch 26/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8206 - val_loss: 0.8436\n",
      "Epoch 27/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8411 - val_loss: 0.8435\n",
      "Epoch 28/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8004 - val_loss: 0.8437\n",
      "Epoch 29/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8612 - val_loss: 0.8439\n",
      "Epoch 30/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8030 - val_loss: 0.8441\n",
      "Epoch 31/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8270 - val_loss: 0.8437\n",
      "Epoch 32/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8452 - val_loss: 0.8440\n",
      "time: 191.79136490821838\n",
      "Model: \"vae_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         [(None, 2), (None, 2), (N 7684      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 115)               7667      \n",
      "=================================================================\n",
      "Total params: 15,351\n",
      "Trainable params: 15,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = vae_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_vae.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9882474791570369\n",
      "Precision 0.9771464899953155\n",
      "Recall 0.9998801636621985\n",
      "Confusion Matrix [[57047  1366]\n",
      " [    7 58406]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9914488213240203\n",
      "Precision 0.9833804809052333\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57426   987]\n",
      " [   12 58401]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9929382158081249\n",
      "Precision 0.9862701388185227\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57600   813]\n",
      " [   12 58401]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9943505726465\n",
      "Precision 0.9890426270597998\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57766   647]\n",
      " [   13 58400]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9957458100080462\n",
      "Precision 0.9917804496977107\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57929   484]\n",
      " [   13 58400]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9967045007104582\n",
      "Precision 0.9936704553188593\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58041   372]\n",
      " [   13 58400]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9969784123397188\n",
      "Precision 0.9942117807286347\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58073   340]\n",
      " [   13 58400]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9972780031842227\n",
      "Precision 0.9948045311302274\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58108   305]\n",
      " [   13 58400]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8897334497457757\n",
      "Precision 0.9943326167676373\n",
      "Recall 0.7839350829438653\n",
      "Confusion Matrix [[58152   261]\n",
      " [12621 45792]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.889913204252478\n",
      "Precision 0.9948077340864654\n",
      "Recall 0.7839179634670365\n",
      "Confusion Matrix [[58174   239]\n",
      " [12622 45791]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8903069522195401\n",
      "Precision 0.9958460200086995\n",
      "Recall 0.7838837245133788\n",
      "Confusion Matrix [[58222   191]\n",
      " [12624 45789]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8909061339085478\n",
      "Precision 0.9974077462641049\n",
      "Recall 0.7838494855597213\n",
      "Confusion Matrix [[58294   119]\n",
      " [12626 45787]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.891325561090853\n",
      "Precision 0.9985387450655384\n",
      "Recall 0.7837981271292349\n",
      "Confusion Matrix [[58346    67]\n",
      " [12629 45784]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8914881961207266\n",
      "Precision 0.9990398044692738\n",
      "Recall 0.7837296492219198\n",
      "Confusion Matrix [[58369    44]\n",
      " [12633 45780]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8915737935048705\n",
      "Precision 0.9992796647166681\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58380    33]\n",
      " [12634 45779]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8917107493195008\n",
      "Precision 0.9996287885404839\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58396    17]\n",
      " [12634 45779]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8917621077499872\n",
      "Precision 0.9997816021665065\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58403    10]\n",
      " [12635 45778]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918134661804735\n",
      "Precision 0.9999126294176751\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58409     4]\n",
      " [12635 45778]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918391453957167\n",
      "Precision 0.9999781559230215\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58412     1]\n",
      " [12635 45778]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8918134661804735\n",
      "Precision 1.0\n",
      "Recall 0.783626932360947\n",
      "Confusion Matrix [[58413     0]\n",
      " [12639 45774]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8917963467036447\n",
      "Precision 1.0\n",
      "Recall 0.7835926934072894\n",
      "Confusion Matrix [[58413     0]\n",
      " [12641 45772]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.891736428534744\n",
      "Precision 1.0\n",
      "Recall 0.783472857069488\n",
      "Confusion Matrix [[58413     0]\n",
      " [12648 45765]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8916593908890145\n",
      "Precision 1.0\n",
      "Recall 0.7833187817780288\n",
      "Confusion Matrix [[58413     0]\n",
      " [12657 45756]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8915053155975553\n",
      "Precision 1.0\n",
      "Recall 0.7830106311951107\n",
      "Confusion Matrix [[58413     0]\n",
      " [12675 45738]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8913854792597539\n",
      "Precision 1.0\n",
      "Recall 0.7827709585195076\n",
      "Confusion Matrix [[58413     0]\n",
      " [12689 45724]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8911886052762228\n",
      "Precision 1.0\n",
      "Recall 0.7823772105524455\n",
      "Confusion Matrix [[58413     0]\n",
      " [12712 45701]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.8910944481536645\n",
      "Precision 1.0\n",
      "Recall 0.7821888963073288\n",
      "Confusion Matrix [[58413     0]\n",
      " [12723 45690]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8910259702463492\n",
      "Precision 1.0\n",
      "Recall 0.7820519404926985\n",
      "Confusion Matrix [[58413     0]\n",
      " [12731 45682]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8909489326006197\n",
      "Precision 1.0\n",
      "Recall 0.7818978652012395\n",
      "Confusion Matrix [[58413     0]\n",
      " [12740 45673]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 8\n",
      "Treshold  48.64811228086002\n",
      "Accuracy  0.9972523710069504\n",
      "Precision  0.9948212125858162\n",
      "Recall 0.9997089738761256\n",
      "Confusion Matrix [[58110   304]\n",
      " [   17 58397]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "vae_acc = accuracy_score(Y_test, Y_pred)\n",
    "vae_precision = precision_score(Y_test, Y_pred)\n",
    "vae_recall = recall_score(Y_test, Y_pred)\n",
    "vae_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',vae_acc)\n",
    "print('Precision ',vae_precision)\n",
    "print(\"Recall\",vae_recall)\n",
    "print('Confusion Matrix',vae_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_model(input_dim):\n",
    "    hidden_size=90\n",
    "    code_size = 57\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "    code = Dense(code_size, activation='relu')(hidden_1)\n",
    "    hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "    output_img = Dense(input_dim, activation='sigmoid')(hidden_2)\n",
    "    sparse = Model(input_img, output_img)\n",
    "    return sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1826/1826 [==============================] - 10s 4ms/step - loss: 0.8977 - val_loss: 0.8378\n",
      "Epoch 2/100\n",
      "1826/1826 [==============================] - 8s 4ms/step - loss: 0.8173 - val_loss: 0.8348\n",
      "Epoch 3/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8364 - val_loss: 0.8337\n",
      "Epoch 4/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.7784 - val_loss: 0.8331\n",
      "Epoch 5/100\n",
      "1826/1826 [==============================] - 7s 4ms/step - loss: 0.8167 - val_loss: 0.8311\n",
      "Epoch 6/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8309 - val_loss: 0.8310\n",
      "Epoch 7/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8086 - val_loss: 0.8293\n",
      "Epoch 8/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8131 - val_loss: 0.8291\n",
      "Epoch 9/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8174 - val_loss: 0.8291\n",
      "Epoch 10/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8212 - val_loss: 0.8293\n",
      "Epoch 11/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8147 - val_loss: 0.8287 ETA: 0s - loss: 0\n",
      "Epoch 12/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8453 - val_loss: 0.8290\n",
      "Epoch 13/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8074 - val_loss: 0.8273\n",
      "Epoch 14/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7481 - val_loss: 0.8273\n",
      "Epoch 15/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7975 - val_loss: 0.8276\n",
      "Epoch 16/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8120 - val_loss: 0.8273\n",
      "Epoch 17/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8060 - val_loss: 0.8275\n",
      "Epoch 18/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8034 - val_loss: 0.8273\n",
      "Epoch 19/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7911 - val_loss: 0.8272\n",
      "Epoch 20/100\n",
      "1826/1826 [==============================] - 6s 3ms/step - loss: 0.8730 - val_loss: 0.8271\n",
      "Epoch 21/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8141 - val_loss: 0.8273\n",
      "Epoch 22/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.8429 - val_loss: 0.8274\n",
      "Epoch 23/100\n",
      "1826/1826 [==============================] - 14s 8ms/step - loss: 0.8070 - val_loss: 0.8273\n",
      "Epoch 24/100\n",
      "1826/1826 [==============================] - 4s 2ms/step - loss: 0.8071 - val_loss: 0.8274\n",
      "Epoch 25/100\n",
      "1826/1826 [==============================] - 5s 3ms/step - loss: 0.7667 - val_loss: 0.8272\n",
      "time: 160.9747178554535\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 115)]             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 90)                10440     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 57)                5187      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 90)                5220      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 115)               10465     \n",
      "=================================================================\n",
      "Total params: 31,312\n",
      "Trainable params: 31,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "top_n_features=115\n",
    "fs = [it['feature'] for it in scored[:top_n_features]]\n",
    "X_train = x_train[fs]\n",
    "X_opt = x_opt[fs]\n",
    "X_test = x_test[fs]\n",
    "    \n",
    "#standardize train and optimize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_opt = scaler.transform(X_opt)\n",
    "    \n",
    "#call function to create the model\n",
    "model = sparse_model(top_n_features)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "cp = ModelCheckpoint(filepath=f\"anomaly/anomaly_sparse.h5\",monitor='val_loss',\n",
    "                     save_best_only=True,save_weights_only=True,verbose=0)\n",
    "\n",
    "#Early Stopping function until val_loss is same for 5 epochs\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "    \n",
    "#fit on train dataset\n",
    "history = model.fit(X_train, X_train,\n",
    "                    epochs=epochs, validation_data=(X_opt, X_opt),\n",
    "                    verbose=1, callbacks=[cp, es])\n",
    "    \n",
    "end = time.time()\n",
    "print('time:', end - start)\n",
    "print(model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting n------------------\n",
      "For n 1\n",
      "Accuracy\n",
      "0.9884015544484961\n",
      "Precision 0.9774408407805335\n",
      "Recall 0.9998801636621985\n",
      "Confusion Matrix [[57065  1348]\n",
      " [    7 58406]]\n",
      "For n 2\n",
      "Accuracy\n",
      "0.9914916200160923\n",
      "Precision 0.9834632807369112\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57431   982]\n",
      " [   12 58401]]\n",
      "For n 3\n",
      "Accuracy\n",
      "0.9929467755465393\n",
      "Precision 0.986286795129448\n",
      "Recall 0.9997945662780545\n",
      "Confusion Matrix [[57601   812]\n",
      " [   12 58401]]\n",
      "For n 4\n",
      "Accuracy\n",
      "0.9943334531696711\n",
      "Precision 0.9890091280123288\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57764   649]\n",
      " [   13 58400]]\n",
      "For n 5\n",
      "Accuracy\n",
      "0.9957458100080462\n",
      "Precision 0.9917804496977107\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[57929   484]\n",
      " [   13 58400]]\n",
      "For n 6\n",
      "Accuracy\n",
      "0.9967130604488726\n",
      "Precision 0.9936873628149938\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58042   371]\n",
      " [   13 58400]]\n",
      "For n 7\n",
      "Accuracy\n",
      "0.9969784123397188\n",
      "Precision 0.9942117807286347\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58073   340]\n",
      " [   13 58400]]\n",
      "For n 8\n",
      "Accuracy\n",
      "0.9972780031842227\n",
      "Precision 0.9948045311302274\n",
      "Recall 0.9997774468012257\n",
      "Confusion Matrix [[58108   305]\n",
      " [   13 58400]]\n",
      "For n 9\n",
      "Accuracy\n",
      "0.8897420094841901\n",
      "Precision 0.9943542082862851\n",
      "Recall 0.7839350829438653\n",
      "Confusion Matrix [[58153   260]\n",
      " [12621 45792]]\n",
      "For n 10\n",
      "Accuracy\n",
      "0.889913204252478\n",
      "Precision 0.9948077340864654\n",
      "Recall 0.7839179634670365\n",
      "Confusion Matrix [[58174   239]\n",
      " [12622 45791]]\n",
      "For n 11\n",
      "Accuracy\n",
      "0.8902983924811257\n",
      "Precision 0.995824362236576\n",
      "Recall 0.7838837245133788\n",
      "Confusion Matrix [[58221   192]\n",
      " [12624 45789]]\n",
      "For n 12\n",
      "Accuracy\n",
      "0.8909146936469622\n",
      "Precision 0.997429473913517\n",
      "Recall 0.7838494855597213\n",
      "Confusion Matrix [[58295   118]\n",
      " [12626 45787]]\n",
      "For n 13\n",
      "Accuracy\n",
      "0.8912998818756099\n",
      "Precision 0.9985169029443839\n",
      "Recall 0.7837638881755774\n",
      "Confusion Matrix [[58345    68]\n",
      " [12631 45782]]\n",
      "For n 14\n",
      "Accuracy\n",
      "0.8914881961207266\n",
      "Precision 0.9990398044692738\n",
      "Recall 0.7837296492219198\n",
      "Confusion Matrix [[58369    44]\n",
      " [12633 45780]]\n",
      "For n 15\n",
      "Accuracy\n",
      "0.8915652337664561\n",
      "Precision 0.9992578525745968\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58379    34]\n",
      " [12634 45779]]\n",
      "For n 16\n",
      "Accuracy\n",
      "0.8917107493195008\n",
      "Precision 0.9996287885404839\n",
      "Recall 0.783712529745091\n",
      "Confusion Matrix [[58396    17]\n",
      " [12634 45779]]\n",
      "For n 17\n",
      "Accuracy\n",
      "0.8917706674884015\n",
      "Precision 0.9998034376569769\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58404     9]\n",
      " [12635 45778]]\n",
      "For n 18\n",
      "Accuracy\n",
      "0.8918134661804735\n",
      "Precision 0.9999126294176751\n",
      "Recall 0.7836954102682622\n",
      "Confusion Matrix [[58409     4]\n",
      " [12635 45778]]\n",
      "For n 19\n",
      "Accuracy\n",
      "0.8918220259188879\n",
      "Precision 0.9999781549686524\n",
      "Recall 0.7836611713146047\n",
      "Confusion Matrix [[58412     1]\n",
      " [12637 45776]]\n",
      "For n 20\n",
      "Accuracy\n",
      "0.8918134661804735\n",
      "Precision 1.0\n",
      "Recall 0.783626932360947\n",
      "Confusion Matrix [[58413     0]\n",
      " [12639 45774]]\n",
      "For n 21\n",
      "Accuracy\n",
      "0.8917877869652303\n",
      "Precision 1.0\n",
      "Recall 0.7835755739304607\n",
      "Confusion Matrix [[58413     0]\n",
      " [12642 45771]]\n",
      "For n 22\n",
      "Accuracy\n",
      "0.8917193090579152\n",
      "Precision 1.0\n",
      "Recall 0.7834386181158304\n",
      "Confusion Matrix [[58413     0]\n",
      " [12650 45763]]\n",
      "For n 23\n",
      "Accuracy\n",
      "0.8916337116737713\n",
      "Precision 1.0\n",
      "Recall 0.7832674233475425\n",
      "Confusion Matrix [[58413     0]\n",
      " [12660 45753]]\n",
      "For n 24\n",
      "Accuracy\n",
      "0.8914710766438978\n",
      "Precision 1.0\n",
      "Recall 0.7829421532877955\n",
      "Confusion Matrix [[58413     0]\n",
      " [12679 45734]]\n",
      "For n 25\n",
      "Accuracy\n",
      "0.8913512403060962\n",
      "Precision 1.0\n",
      "Recall 0.7827024806121925\n",
      "Confusion Matrix [[58413     0]\n",
      " [12693 45720]]\n",
      "For n 26\n",
      "Accuracy\n",
      "0.8911629260609796\n",
      "Precision 1.0\n",
      "Recall 0.7823258521219592\n",
      "Confusion Matrix [[58413     0]\n",
      " [12715 45698]]\n",
      "For n 27\n",
      "Accuracy\n",
      "0.89108588841525\n",
      "Precision 1.0\n",
      "Recall 0.7821717768305001\n",
      "Confusion Matrix [[58413     0]\n",
      " [12724 45689]]\n",
      "For n 28\n",
      "Accuracy\n",
      "0.8910174105079349\n",
      "Precision 1.0\n",
      "Recall 0.7820348210158697\n",
      "Confusion Matrix [[58413     0]\n",
      " [12732 45681]]\n",
      "For n 29\n",
      "Accuracy\n",
      "0.8909146936469622\n",
      "Precision 1.0\n",
      "Recall 0.7818293872939243\n",
      "Confusion Matrix [[58413     0]\n",
      " [12744 45669]]\n"
     ]
    }
   ],
   "source": [
    "#use optimization dataset to predict and find mse for anomaly detection\n",
    "x_opt_predictions = model.predict(X_opt)\n",
    "mse = np.mean(np.power(X_opt - x_opt_predictions, 2), axis=1)\n",
    "mean = mse.mean()\n",
    "std = mse.std()\n",
    "    \n",
    "#sampling a benign dataset and adding a class malicious with 0\n",
    "df_benign = pd.DataFrame(x_opt[fs], columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "    \n",
    "#sampling a malicious dataset and adding a class malicious with 1\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=39)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "    \n",
    "#combining benign and malicous dataset\n",
    "df_combo = df_benign.append(df_malicious)\n",
    "    \n",
    "#X_opt with feature values\n",
    "X_opt = df_combo.drop(columns=['malicious']).values\n",
    "X_opt_scaled = scaler.transform(X_opt)\n",
    "\n",
    "#Y_opt with target values\n",
    "Y_opt = df_combo['malicious']\n",
    "best_acc = 0\n",
    "best_n = 0\n",
    "#varying treshold and selecting the best model\n",
    "print('Selecting n------------------')\n",
    "for n in range(1,30):\n",
    "    tr = mean + n * std\n",
    "    m = AnomalyModel(model , tr, scaler)\n",
    "    Y_pred = m.predict(X_opt_scaled)\n",
    "    print(f'For n {n}')\n",
    "    print('Accuracy')\n",
    "    acc = accuracy_score(Y_opt, Y_pred)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc  #determining the best aaccuracy\n",
    "        best_n = n\n",
    "    print(acc)\n",
    "    print('Precision',precision_score(Y_opt, Y_pred))\n",
    "    print(\"Recall\",recall_score(Y_opt, Y_pred))\n",
    "    print('Confusion Matrix',confusion_matrix(Y_opt, Y_pred))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-----------------\n",
      "best n 8\n",
      "Treshold  48.49223472306697\n",
      "Accuracy  0.9972523710069504\n",
      "Precision  0.9948212125858162\n",
      "Recall 0.9997089738761256\n",
      "Confusion Matrix [[58110   304]\n",
      " [   17 58397]]\n"
     ]
    }
   ],
   "source": [
    "#Creating a test Data frame and training model with test data\n",
    "df_benign = pd.DataFrame(X_test, columns=fs)\n",
    "df_benign['malicious'] = 0\n",
    "df_malicious = df_attack.sample(n=df_benign.shape[0], random_state=17)[fs]\n",
    "df_malicious['malicious'] = 1\n",
    "df2 = df_benign.append(df_malicious)\n",
    "X_test = df2.drop(columns=['malicious']).values\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test = df2['malicious']\n",
    "    \n",
    "#using best n value for treshold determined using opotimization dataset\n",
    "tr = mean + best_n * std\n",
    "m = AnomalyModel(model , tr, scaler)\n",
    "Y_pred = m.predict(X_test_scaled)\n",
    "print('Test-----------------')\n",
    "print(f'best n {best_n}')\n",
    "print(\"Treshold \",tr)\n",
    "sparse_acc = accuracy_score(Y_test, Y_pred)\n",
    "sparse_precision = precision_score(Y_test, Y_pred)\n",
    "sparse_recall = recall_score(Y_test, Y_pred)\n",
    "sparse_cm = confusion_matrix(Y_test, Y_pred)\n",
    "print('Accuracy ',sparse_acc)\n",
    "print('Precision ',sparse_precision)\n",
    "print(\"Recall\",sparse_recall)\n",
    "print('Confusion Matrix',sparse_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model(inputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(115, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(80, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(10, input_dim=inputs, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.add(Dense(labels.shape[1],activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=1e-3, callbacks=[monitor], patience=5) \n",
    "    model.fit(x_train_st,y_train_st,validation_data=(x_test_st,y_test_st),\n",
    "          verbose=1,epochs=100, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = df_mirai.append(df_gafgyt)\n",
    "df_attack['class'] = 1\n",
    "\n",
    "df_ben = x_train.copy()\n",
    "df_ben['class'] = 0\n",
    "\n",
    "df_ben = df_ben.append(df_attack.sample(n=df_ben.shape[0], random_state=17))\n",
    "\n",
    "X = df_ben.drop(columns=['class'])\n",
    "y = df_ben['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=17)\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6231/6231 [==============================] - 10s 1ms/step - loss: 0.0034\n",
      "Epoch 2/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 8.6232e-04\n",
      "Epoch 3/100\n",
      "6231/6231 [==============================] - 11s 2ms/step - loss: 6.2325e-04\n",
      "Epoch 4/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 5.8806e-04A: 0s - loss: 5.8778e-\n",
      "Epoch 5/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 4.8684e-04\n",
      "Epoch 6/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 7.9359e-04\n",
      "Epoch 7/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 5.6941e-04A: 1s - loss: 5.9269 - E\n",
      "Epoch 8/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 5.1901e-04\n",
      "Epoch 9/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 4.4435e-04\n",
      "Epoch 10/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 3.5741e-04\n",
      "Epoch 11/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 5.9693e-04\n",
      "Epoch 12/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 3.5057e-04\n",
      "Epoch 13/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 5.0795e-04\n",
      "Epoch 14/100\n",
      "6231/6231 [==============================] - 8s 1ms/step - loss: 8.6944e-04\n",
      "Epoch 15/100\n",
      "6231/6231 [==============================] - 9s 1ms/step - loss: 0.0020\n",
      "time 130.40271997451782\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Dense(115, input_dim=115, activation='relu'))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "start = time.time()  #time function to determine time taken by model\n",
    "epochs = 100\n",
    "\n",
    "#compile and fit model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "model.fit(X_train,y_train,epochs=epochs,batch_size=15,callbacks=[es])\n",
    "\n",
    "end = time.time()\n",
    "print(\"time\",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9993580415989044\n",
      "Precision  0.9991536182818451\n",
      "Recall 0.9995766299745978\n",
      "Confusion Matrix [[11546    10]\n",
      " [    5 11805]]\n"
     ]
    }
   ],
   "source": [
    "dnn_acc = accuracy_score(y_test, y_pred)\n",
    "dnn_precision = precision_score(y_test, y_pred)\n",
    "dnn_recall = recall_score(y_test, y_pred)\n",
    "dnn_cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy ',dnn_acc)\n",
    "print('Precision ',dnn_precision)\n",
    "print(\"Recall\",dnn_recall)\n",
    "print('Confusion Matrix',dnn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>CM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep AutoEncoder</td>\n",
       "      <td>0.892594</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.785377</td>\n",
       "      <td>[[58403, 11], [12537, 45877]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Variational AutoEncoder</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.994821</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>[[58110, 304], [17, 58397]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse AutoEncoder</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.994821</td>\n",
       "      <td>0.999709</td>\n",
       "      <td>[[58110, 304], [17, 58397]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNN</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>0.999154</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>[[11546, 10], [5, 11805]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy  Precision    Recall  \\\n",
       "0         Deep AutoEncoder  0.892594   0.999760  0.785377   \n",
       "1  Variational AutoEncoder  0.997252   0.994821  0.999709   \n",
       "2       Sparse AutoEncoder  0.997252   0.994821  0.999709   \n",
       "3                      DNN  0.999358   0.999154  0.999577   \n",
       "\n",
       "                              CM  \n",
       "0  [[58403, 11], [12537, 45877]]  \n",
       "1    [[58110, 304], [17, 58397]]  \n",
       "2    [[58110, 304], [17, 58397]]  \n",
       "3      [[11546, 10], [5, 11805]]  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary = pd.DataFrame({'Model' :['Deep AutoEncoder',\"Variational AutoEncoder\",\"Sparse AutoEncoder\",\"DNN\"],\n",
    "                             'Accuracy':[deep_acc,vae_acc,sparse_acc,dnn_acc],\n",
    "                             'Precision':[deep_precision,vae_precision,sparse_precision,dnn_precision],\n",
    "                             'Recall':[deep_recall,vae_recall,sparse_recall,dnn_recall],\n",
    "                             'CM':[deep_cm,vae_cm,sparse_cm,dnn_cm]})\n",
    "model_summary.sort_values(by='Accuracy', ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
